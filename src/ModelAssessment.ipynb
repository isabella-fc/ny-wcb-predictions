{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, PredefinedSplit, KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, make_scorer, precision_score, recall_score\n",
    ")\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "import pickle\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from Preprocessing_functions import *\n",
    "\n",
    "import importlib\n",
    "imported_module = importlib.import_module(\"Preprocessing_functions\")\n",
    "importlib.reload(imported_module)\n",
    "\n",
    "# pandas max columns display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n",
    "test_data = pd.read_csv('test_data.csv', index_col='Claim Identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[~(train_data.drop(columns=['Assembly Date']).isna().all(axis=1) & train_data['Assembly Date'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['Claim Injury Type', 'WCB Decision', 'Agreement Reached','OIICS Nature of Injury Description'])\n",
    "y = train_data['Claim Injury Type']\n",
    "\n",
    "test_data = test_data.drop(columns=['OIICS Nature of Injury Description'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim Injury Type\n",
       "2. NON-COMP        50.708156\n",
       "4. TEMPORARY       25.871128\n",
       "3. MED ONLY        12.003986\n",
       "5. PPD SCH LOSS     8.410769\n",
       "1. CANCELLED        2.173595\n",
       "6. PPD NSL          0.733590\n",
       "8. DEATH            0.081878\n",
       "7. PTD              0.016898\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predifined_split_with_features(X, y, preprocess_steps,selected_features, n_splits = 5):\n",
    "    \"\"\"\n",
    "    Creates a PredefinedSplit object to be used in cross-validation, more specifically in GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Defines the number of splits\n",
    "    - Splits the data into training and validation sets\n",
    "    - Applies the preprocessing steps to the training and validation sets\n",
    "    - Returns the PredefinedSplit object and the preprocessed data\n",
    "    \"\"\"\n",
    "\n",
    "    X_combined_list = []\n",
    "    y_combined_list = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    test_data = np.zeros(len(X), dtype=int) - 1\n",
    "\n",
    "    for fold_idx, (_, test_idx) in enumerate(kf.split(X, y)):\n",
    "        test_data[test_idx] = fold_idx\n",
    "\n",
    "    ps = PredefinedSplit(test_fold=test_data)\n",
    "\n",
    "    for train_index, test_index in ps.split():\n",
    "\n",
    "        # Get fold\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Preprocess and encode data    \n",
    "        X_train, X_val = preprocess_steps(X_train, X_val)\n",
    "        y_train, y_val, le = encoding_label(y_train, y_val)\n",
    "\n",
    "        X_combined_list.append(X_train[selected_features])\n",
    "        y_combined_list.append(y_train)\n",
    "\n",
    "    X_combined = pd.concat(X_combined_list, axis=0)\n",
    "    y_combined = np.concatenate(y_combined_list, axis=0)\n",
    "\n",
    "    return ps, X_combined, y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predifined_split(X, y, preprocess_steps, n_splits = 5):\n",
    "    \"\"\"\n",
    "    Creates a PredefinedSplit object to be used in cross-validation, more specifically in GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Defines the number of splits\n",
    "    - Splits the data into training and validation sets\n",
    "    - Applies the preprocessing steps to the training and validation sets\n",
    "    - Returns the PredefinedSplit object and the preprocessed data\n",
    "    \"\"\"\n",
    "\n",
    "    X_combined_list = []\n",
    "    y_combined_list = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    test_data = np.zeros(len(X), dtype=int) - 1\n",
    "\n",
    "    for fold_idx, (_, test_idx) in enumerate(kf.split(X, y)):\n",
    "        test_data[test_idx] = fold_idx\n",
    "\n",
    "    ps = PredefinedSplit(test_fold=test_data)\n",
    "\n",
    "    for train_index, test_index in ps.split():\n",
    "\n",
    "        # Get fold\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Preprocess and encode data    \n",
    "        X_train, X_val = preprocess_steps(X_train, X_val)\n",
    "        y_train, y_val, le = encoding_label(y_train, y_val)\n",
    "\n",
    "        X_combined_list.append(X_train)\n",
    "        y_combined_list.append(y_train)\n",
    "\n",
    "    X_combined = pd.concat(X_combined_list, axis=0)\n",
    "    y_combined = np.concatenate(y_combined_list, axis=0)\n",
    "\n",
    "    return ps, X_combined, y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_chi2_across_folds_with_predefined_split(X, y, ps):\n",
    "    \"\"\"\n",
    "    Computes the average Chi-Squared score and p-value across folds using a PredefinedSplit.\n",
    "    \"\"\"\n",
    "    feature_scores = []\n",
    "\n",
    "    for train_idx, test_idx in ps.split():\n",
    "\n",
    "        X_train, y_train = X.iloc[train_idx], y[train_idx]\n",
    "        \n",
    "        chi2_scores, p_values = chi2(X_train, y_train)\n",
    "        \n",
    "        feature_scores.append((chi2_scores, p_values))\n",
    "\n",
    "    chi2_scores_all = np.array([scores[0] for scores in feature_scores])\n",
    "    p_values_all = np.array([scores[1] for scores in feature_scores])\n",
    "    \n",
    "    avg_chi2_scores = np.mean(chi2_scores_all, axis=0)\n",
    "    avg_p_values = np.mean(p_values_all, axis=0)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Average_Chi2_Score': avg_chi2_scores,\n",
    "        'Average_P_Value': avg_p_values\n",
    "    }).sort_values(by='Average_Chi2_Score', ascending=False)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_anova_across_folds_with_predefined_split(X, y, ps):\n",
    "    \"\"\"\n",
    "    Computes the average ANOVA F-test score and p-value across folds using a PredefinedSplit.\n",
    "    \"\"\"\n",
    "    feature_scores = []\n",
    "    \n",
    "    for train_idx, test_idx in ps.split():\n",
    "        X_train, y_train = X.iloc[train_idx], y[train_idx]\n",
    "        \n",
    "        f_scores, p_values = f_classif(X_train, y_train)\n",
    "        \n",
    "        feature_scores.append((f_scores, p_values))\n",
    "\n",
    "    f_scores_all = np.array([scores[0] for scores in feature_scores])\n",
    "    p_values_all = np.array([scores[1] for scores in feature_scores])\n",
    "    \n",
    "    avg_f_scores = np.mean(f_scores_all, axis=0)\n",
    "    avg_p_values = np.mean(p_values_all, axis=0)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Average_F_Score': avg_f_scores,\n",
    "        'Average_P_Value': avg_p_values\n",
    "    }).sort_values(by='Average_F_Score', ascending=False)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List creation for Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_COLUMNS = ['Industry Code', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']\n",
    "\n",
    "DESCRIPTION_COLUMNS = ['WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description','Industry Code Description']\n",
    "\n",
    "BOOLEAN_COLUMNS = ['Alternative Dispute Resolution', 'Attorney/Representative','COVID-19 Indicator']\n",
    "\n",
    "date_order = ['Accident Date', 'C-2 Date','C-3 Date','Assembly Date', 'First Hearing Date']\n",
    "\n",
    "numerical_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'C-2 Date', \n",
    "    'C-3 Date', \n",
    "    'First Hearing Date', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "outliers_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year',\n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "categorical_features = ['Alternative Dispute Resolution',\n",
    " 'Attorney/Representative',\n",
    " 'Carrier Name',\n",
    " 'Carrier Type',\n",
    " 'County of Injury',\n",
    " 'COVID-19 Indicator',\n",
    " 'District Name',\n",
    " 'Gender',\n",
    " 'Industry Code',\n",
    " 'Medical Fee Region',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'Zip Code']\n",
    "\n",
    "\n",
    "columns_to_scale = ['Accident Date',\n",
    "                'Assembly Date',\n",
    "                'Average Weekly Wage',\n",
    "                'Age at Injury',\n",
    "                'Birth Year', \n",
    "                'Number of Dependents',\n",
    "                'IME-4 Count']\n",
    "\n",
    "date_columns = ['Accident Date', 'Assembly Date']\n",
    "\n",
    "outliers_iqr_specific = ['Age at Injury', 'Birth Year']\n",
    "\n",
    "columns_to_drop = ['C-2 Date', 'C-3 Date', 'First Hearing Date']\n",
    "\n",
    "scaling_columns = ['Average Weekly Wage', 'Age at Injury', 'Birth Year', 'Number of Dependents', 'IME-4 Count', 'Days Between Accident Date and Assembly Date']\n",
    "\n",
    "new_date_features = ['Accident Date_Year', 'Accident Date_Month', 'Accident Date_Day', 'Accident Date_DayOfWeek',\n",
    "                'Assembly Date_Year', 'Assembly Date_Month', 'Assembly Date_Day', 'Assembly Date_DayOfWeek',\n",
    "                'C-2 Date_Year', 'C-2 Date_Month', 'C-2 Date_Day', 'C-2 Date_DayOfWeek',\n",
    "                'C-3 Date_Year', 'C-3 Date_Month', 'C-3 Date_Day', 'C-3 Date_DayOfWeek',\n",
    "                'First Hearing Date_Year', 'First Hearing Date_Month', 'First Hearing Date_Day', 'First Hearing Date_DayOfWeek']\n",
    "\n",
    "binning_columns = ['Age at Injury', 'Age at Injury', 'Birth Year', 'Average Weekly Wage', 'IME-4 Count']\n",
    "date_columns = ['Accident Date', 'Assembly Date']\n",
    "\n",
    "# Create feature lists\n",
    "date_features = ['Accident Date_Year', 'Accident Date_Month', 'Accident Date_Day', 'Accident Date_DayOfWeek',\n",
    "                'Assembly Date_Year', 'Assembly Date_Month', 'Assembly Date_Day', 'Assembly Date_DayOfWeek',\n",
    "                'C-2 Date_Year', 'C-2 Date_Month', 'C-2 Date_Day', 'C-2 Date_DayOfWeek']\n",
    "\n",
    "numeric_features = ['Age at Injury', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents']\n",
    "\n",
    "categorical_features_optimize = ['Alternative Dispute Resolution', 'Attorney/Representative', 'Carrier Type',\n",
    "                       'County of Injury', 'COVID-19 Indicator', 'District Name', 'Gender',\n",
    "                       'Industry Code', 'Medical Fee Region', 'WCIO Cause of Injury Code','WCIO Nature of Injury Code', \n",
    "                       'WCIO Part Of Body Code']\n",
    "\n",
    "dates_lowMissing = ['Accident Date', 'Assembly Date', 'C-2 Date']\n",
    "dates_highMissing = ['C-3 Date', 'First Hearing Date']\n",
    "newBinary = ['Has C-3 Date', 'Has First Hearing Date']\n",
    "\n",
    "frequency = ['Carrier Name', 'Zip Code']\n",
    "\n",
    "# Drop unnecessary columns and get features\n",
    "drop_cols = ['Accident Date', 'Assembly Date', 'C-2 Date', 'C-3 Date', 'First Hearing Date',\n",
    "            ]\n",
    "\n",
    "date_features = ['Accident Date_Year', 'Accident Date_Month', 'Accident Date_Day', 'Accident Date_DayOfWeek',\n",
    "                'Assembly Date_Year', 'Assembly Date_Month', 'Assembly Date_Day', 'Assembly Date_DayOfWeek',\n",
    "                'C-2 Date_Year', 'C-2 Date_Month', 'C-2 Date_Day', 'C-2 Date_DayOfWeek']\n",
    "\n",
    "\n",
    "\n",
    "low_cardinality_cols = [col for col in categorical_features if X[col].nunique() < 10]\n",
    "high_cardinality_cols = [col for col in categorical_features if X[col].nunique() > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_groupingFeatures(X_train, X_val):\n",
    "\n",
    "    X_train, X_val= newFeature_binnedGroups(X_train, X_val, binning_columns, 6)\n",
    "\n",
    "    X_train, X_val = newFeature_month(X_train, X_val, date_columns)\n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_val = newFeature_daysBetween(X_train, X_val, firstDate='Accident Date', secondDate='Assembly Date')\n",
    "    \n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocessing_scaling_encoding_dum(X_train, X_val):\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val,categorical_features)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, columns_to_scale)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_newDate_dum(X_train, X_val):\n",
    "\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val, categorical_features)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numeric_features)\n",
    "    X_train, X_val = impute_mode_categorical(X_train, X_val, categorical_features)\n",
    "\n",
    "    X_train, X_val = newFeature_hasIME4(X_train, X_val)\n",
    "    X_train, X_val= feature_creation_has_Date(X_train, X_val, dates_highMissing)\n",
    "    X_train, X_val = newFeatures_categoricalDates(X_train, X_val, dates_lowMissing)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, drop_cols)\n",
    "\n",
    "    X_train, X_val = scaling_standard(X_train, X_val, numeric_features)\n",
    "\n",
    "    for key in newBinary:\n",
    "        categorical_features.append(key)\n",
    "\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, categorical_features)\n",
    "    X_train, X_val = encoding_frequency2(X_train, X_val, frequency)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Pre-Processing Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_newFeatures_dum(X_train, X_val):\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val,categorical_features)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = convert_to_datetime(X_train, X_val, date_columns)\n",
    "    X_train, X_val= create_groupingFeatures(X_train, X_val)\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, scaling_columns)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, date_columns)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_scaling_encoding_advanced(X_train, X_val):\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val,categorical_features)\n",
    "    \n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    # Knowledge-based imputation of features\n",
    "    X_train, X_val = fill_missing_codes_description_based(X_train, X_val)\n",
    "    X_train, X_val = fillna_zip_code(X_train, X_val)\n",
    "    X_train, X_val = fillnan_accident_date(X_train, X_val)\n",
    "    X_train, X_val = fillnan_birth_year(X_train, X_val)\n",
    "    X_train, X_val = impute_weekly_wage_with_zipIndustryCode(X_train, X_val)\n",
    "    X_train, X_val = fillnan_IME4_count(X_train, X_val)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "\n",
    "    # Impute still missing values\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, columns_to_scale)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_newFeatures_advanced(X_train, X_val):\n",
    "\n",
    "    # Type conversion\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val, categorical_features)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "\n",
    "    \n",
    "\n",
    "    # Knowledge-based imputation of features\n",
    "    X_train, X_val = fill_missing_codes_description_based(X_train, X_val)\n",
    "    X_train, X_val = fillna_zip_code(X_train, X_val)\n",
    "    X_train, X_val = fillnan_accident_date(X_train, X_val)\n",
    "    X_train, X_val = fillnan_birth_year(X_train, X_val)\n",
    "    X_train, X_val = impute_weekly_wage_with_zipIndustryCode(X_train, X_val)\n",
    "    X_train, X_val = fillnan_IME4_count(X_train, X_val)\n",
    "\n",
    "    # Impute still missing values\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "\n",
    "    \n",
    "\n",
    "    # Feature creation\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = newFeature_hasIME4(X_train, X_val)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = convert_to_datetime(X_train, X_val, date_columns)\n",
    "\n",
    "    # Grouping features\n",
    "    X_train, X_val= create_groupingFeatures(X_train, X_val)\n",
    "\n",
    "    # Treating outliers\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "\n",
    "    # Scaling\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, scaling_columns)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, date_columns)\n",
    "\n",
    "    low_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() < 10]\n",
    "    high_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() > 10]\n",
    "\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing for optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_optimized(X_train, X_val):\n",
    "    \n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val, categorical_features_optimize)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = impute_mode_categorical(X_train, X_val, categorical_features_optimize)\n",
    "\n",
    "    X_train, X_val = newFeature_hasIME4(X_train, X_val)\n",
    "    X_train, X_val=  feature_creation_has_Date(X_train, X_val, dates_highMissing)\n",
    "    X_train, X_val = newFeatures_categoricalDates(X_train, X_val, dates_lowMissing)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, drop_cols)\n",
    "\n",
    "    X_train, X_val = scaling_standard(X_train, X_val, numeric_features)\n",
    "\n",
    "    for key in newBinary:\n",
    "        categorical_features_optimize.append(key)\n",
    "\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, categorical_features_optimize)\n",
    "    X_train, X_val = encoding_frequency2(X_train, X_val, frequency)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefined Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps, X_combined, y_combined = create_predifined_split(X, y, preprocessing_scaling_encoding_dum, n_splits=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi square and Anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to take out the colmns that were frequency encoded for this part of the analysis and really on other type of feature selection for those colmns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi square "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for categorigal features\n",
    "chi_features = [\n",
    "    'Has C-3 Date',\n",
    "    'Has C-2 Date',\n",
    "    'Has First Hearing Date',\n",
    "    'Alternative Dispute Resolution_False',\n",
    "    'Alternative Dispute Resolution_True',\n",
    "    'Alternative Dispute Resolution_nan',\n",
    "    'Attorney/Representative_False',\n",
    "    'Attorney/Representative_True',\n",
    "    'Carrier Type_1A. PRIVATE',\n",
    "    'Carrier Type_2A. SIF',\n",
    "    'Carrier Type_3A. SELF PUBLIC',\n",
    "    'Carrier Type_4A. SELF PRIVATE',\n",
    "    'Carrier Type_5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)',\n",
    "    'Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS',\n",
    "    'Carrier Type_5D. SPECIAL FUND - UNKNOWN',\n",
    "    'Carrier Type_UNKNOWN',\n",
    "    'COVID-19 Indicator_False',\n",
    "    'COVID-19 Indicator_True',\n",
    "    'District Name_NYC',\n",
    "    'District Name_BUFFALO',\n",
    "    'District Name_ALBANY',\n",
    "    'District Name_HAUPPAUGE',\n",
    "    'District Name_STATEWIDE',\n",
    "    'District Name_SYRACUSE',\n",
    "    'District Name_BINGHAMTON',\n",
    "    'District Name_ROCHESTER',\n",
    "    'Gender_F',\n",
    "    'Gender_M',\n",
    "    'Gender_U',\n",
    "    'Gender_X',\n",
    "    'Medical Fee Region_I',\n",
    "    'Medical Fee Region_II',\n",
    "    'Medical Fee Region_III',\n",
    "    'Medical Fee Region_IV',\n",
    "    'Medical Fee Region_UK',\n",
    "]\n",
    "chi2_results = average_chi2_across_folds_with_predefined_split(X_combined[chi_features], y_combined, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Average_Chi2_Score</th>\n",
       "      <th>Average_P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Attorney/Representative_True</td>\n",
       "      <td>1.184465e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Attorney/Representative_False</td>\n",
       "      <td>5.595382e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Carrier Type_3A. SELF PUBLIC</td>\n",
       "      <td>7.177575e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Carrier Type_2A. SIF</td>\n",
       "      <td>5.212932e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COVID-19 Indicator_True</td>\n",
       "      <td>4.274148e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carrier Type_1A. PRIVATE</td>\n",
       "      <td>2.726281e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gender_F</td>\n",
       "      <td>2.374563e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alternative Dispute Resolution_True</td>\n",
       "      <td>2.003355e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gender_M</td>\n",
       "      <td>1.813223e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Carrier Type_UNKNOWN</td>\n",
       "      <td>1.451044e+03</td>\n",
       "      <td>3.452917e-297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>District Name_HAUPPAUGE</td>\n",
       "      <td>1.079501e+03</td>\n",
       "      <td>5.445779e-220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Medical Fee Region_I</td>\n",
       "      <td>9.996782e+02</td>\n",
       "      <td>2.013900e-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Carrier Type_4A. SELF PRIVATE</td>\n",
       "      <td>9.873123e+02</td>\n",
       "      <td>4.118888e-206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>District Name_STATEWIDE</td>\n",
       "      <td>9.559498e+02</td>\n",
       "      <td>2.098072e-190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>District Name_NYC</td>\n",
       "      <td>9.069483e+02</td>\n",
       "      <td>1.782968e-188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Medical Fee Region_IV</td>\n",
       "      <td>9.054492e+02</td>\n",
       "      <td>1.736332e-187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>District Name_BINGHAMTON</td>\n",
       "      <td>8.861578e+02</td>\n",
       "      <td>9.785918e-184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>District Name_ROCHESTER</td>\n",
       "      <td>8.435294e+02</td>\n",
       "      <td>1.450554e-171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>District Name_ALBANY</td>\n",
       "      <td>5.610084e+02</td>\n",
       "      <td>3.621346e-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Medical Fee Region_UK</td>\n",
       "      <td>5.444010e+02</td>\n",
       "      <td>2.073096e-112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Medical Fee Region_II</td>\n",
       "      <td>4.599900e+02</td>\n",
       "      <td>6.905675e-94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gender_U</td>\n",
       "      <td>4.421933e+02</td>\n",
       "      <td>1.131455e-89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>District Name_SYRACUSE</td>\n",
       "      <td>2.528049e+02</td>\n",
       "      <td>1.106166e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>COVID-19 Indicator_False</td>\n",
       "      <td>2.337985e+02</td>\n",
       "      <td>1.105885e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>District Name_BUFFALO</td>\n",
       "      <td>1.899368e+02</td>\n",
       "      <td>2.156702e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Carrier Type_5D. SPECIAL FUND - UNKNOWN</td>\n",
       "      <td>1.410547e+02</td>\n",
       "      <td>2.025750e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Carrier Type_5A. SPECIAL FUND - CONS. COMM. (S...</td>\n",
       "      <td>6.952501e+01</td>\n",
       "      <td>1.373846e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Carrier Type_5C. SPECIAL FUND - POI CARRIER WC...</td>\n",
       "      <td>6.662003e+01</td>\n",
       "      <td>3.289411e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Medical Fee Region_III</td>\n",
       "      <td>6.440377e+01</td>\n",
       "      <td>4.639156e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Gender_X</td>\n",
       "      <td>4.748883e+01</td>\n",
       "      <td>1.664102e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alternative Dispute Resolution_False</td>\n",
       "      <td>9.310322e+00</td>\n",
       "      <td>2.313433e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alternative Dispute Resolution_nan</td>\n",
       "      <td>4.706254e+00</td>\n",
       "      <td>6.919186e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Has C-2 Date</td>\n",
       "      <td>3.324562e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Has First Hearing Date</td>\n",
       "      <td>3.324562e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has C-3 Date</td>\n",
       "      <td>3.324562e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Feature  Average_Chi2_Score  \\\n",
       "7                        Attorney/Representative_True        1.184465e+05   \n",
       "6                       Attorney/Representative_False        5.595382e+04   \n",
       "10                       Carrier Type_3A. SELF PUBLIC        7.177575e+03   \n",
       "9                                Carrier Type_2A. SIF        5.212932e+03   \n",
       "17                            COVID-19 Indicator_True        4.274148e+03   \n",
       "8                            Carrier Type_1A. PRIVATE        2.726281e+03   \n",
       "26                                           Gender_F        2.374563e+03   \n",
       "4                 Alternative Dispute Resolution_True        2.003355e+03   \n",
       "27                                           Gender_M        1.813223e+03   \n",
       "15                               Carrier Type_UNKNOWN        1.451044e+03   \n",
       "21                            District Name_HAUPPAUGE        1.079501e+03   \n",
       "30                               Medical Fee Region_I        9.996782e+02   \n",
       "11                      Carrier Type_4A. SELF PRIVATE        9.873123e+02   \n",
       "22                            District Name_STATEWIDE        9.559498e+02   \n",
       "18                                  District Name_NYC        9.069483e+02   \n",
       "33                              Medical Fee Region_IV        9.054492e+02   \n",
       "24                           District Name_BINGHAMTON        8.861578e+02   \n",
       "25                            District Name_ROCHESTER        8.435294e+02   \n",
       "20                               District Name_ALBANY        5.610084e+02   \n",
       "34                              Medical Fee Region_UK        5.444010e+02   \n",
       "31                              Medical Fee Region_II        4.599900e+02   \n",
       "28                                           Gender_U        4.421933e+02   \n",
       "23                             District Name_SYRACUSE        2.528049e+02   \n",
       "16                           COVID-19 Indicator_False        2.337985e+02   \n",
       "19                              District Name_BUFFALO        1.899368e+02   \n",
       "14            Carrier Type_5D. SPECIAL FUND - UNKNOWN        1.410547e+02   \n",
       "12  Carrier Type_5A. SPECIAL FUND - CONS. COMM. (S...        6.952501e+01   \n",
       "13  Carrier Type_5C. SPECIAL FUND - POI CARRIER WC...        6.662003e+01   \n",
       "32                             Medical Fee Region_III        6.440377e+01   \n",
       "29                                           Gender_X        4.748883e+01   \n",
       "3                Alternative Dispute Resolution_False        9.310322e+00   \n",
       "5                  Alternative Dispute Resolution_nan        4.706254e+00   \n",
       "1                                        Has C-2 Date        3.324562e-18   \n",
       "2                              Has First Hearing Date        3.324562e-18   \n",
       "0                                        Has C-3 Date        3.324562e-18   \n",
       "\n",
       "    Average_P_Value  \n",
       "7      0.000000e+00  \n",
       "6      0.000000e+00  \n",
       "10     0.000000e+00  \n",
       "9      0.000000e+00  \n",
       "17     0.000000e+00  \n",
       "8      0.000000e+00  \n",
       "26     0.000000e+00  \n",
       "4      0.000000e+00  \n",
       "27     0.000000e+00  \n",
       "15    3.452917e-297  \n",
       "21    5.445779e-220  \n",
       "30    2.013900e-208  \n",
       "11    4.118888e-206  \n",
       "22    2.098072e-190  \n",
       "18    1.782968e-188  \n",
       "33    1.736332e-187  \n",
       "24    9.785918e-184  \n",
       "25    1.450554e-171  \n",
       "20    3.621346e-111  \n",
       "34    2.073096e-112  \n",
       "31     6.905675e-94  \n",
       "28     1.131455e-89  \n",
       "23     1.106166e-47  \n",
       "16     1.105885e-45  \n",
       "19     2.156702e-35  \n",
       "14     2.025750e-19  \n",
       "12     1.373846e-04  \n",
       "13     3.289411e-08  \n",
       "32     4.639156e-09  \n",
       "29     1.664102e-06  \n",
       "3      2.313433e-01  \n",
       "5      6.919186e-01  \n",
       "1      1.000000e+00  \n",
       "2      1.000000e+00  \n",
       "0      1.000000e+00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Has C-3 Date, Has C-2 Date, Has First Hearing Date, Alternative Dispute Resolution_nan and Alternative Dispute Resolution_False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_features =[\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "anova_result = average_anova_across_folds_with_predefined_split(X_combined[anova_features], y_combined, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Average_F_Score</th>\n",
       "      <th>Average_P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Average Weekly Wage</td>\n",
       "      <td>174843.294364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IME-4 Count</td>\n",
       "      <td>2955.534057</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age at Injury</td>\n",
       "      <td>1041.869837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assembly Date</td>\n",
       "      <td>639.697662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accident Date</td>\n",
       "      <td>541.534905</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Birth Year</td>\n",
       "      <td>527.851524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Average_F_Score  Average_P_Value\n",
       "3  Average Weekly Wage    174843.294364              0.0\n",
       "5          IME-4 Count      2955.534057              0.0\n",
       "1        Age at Injury      1041.869837              0.0\n",
       "2        Assembly Date       639.697662              0.0\n",
       "0        Accident Date       541.534905              0.0\n",
       "4           Birth Year       527.851524              0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anova_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accident Date</th>\n",
       "      <th>Age at Injury</th>\n",
       "      <th>Assembly Date</th>\n",
       "      <th>Average Weekly Wage</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Carrier Name</th>\n",
       "      <th>IME-4 Count</th>\n",
       "      <th>Zip Code</th>\n",
       "      <th>Number of Dependents</th>\n",
       "      <th>Has Alternative Dispute Resolution</th>\n",
       "      <th>Has Attorney/Representative</th>\n",
       "      <th>Has COVID-19 Indicator</th>\n",
       "      <th>Has C-3 Date</th>\n",
       "      <th>Has C-2 Date</th>\n",
       "      <th>Has First Hearing Date</th>\n",
       "      <th>Alternative Dispute Resolution_N</th>\n",
       "      <th>Alternative Dispute Resolution_U</th>\n",
       "      <th>Alternative Dispute Resolution_Y</th>\n",
       "      <th>Attorney/Representative_N</th>\n",
       "      <th>Attorney/Representative_Y</th>\n",
       "      <th>Carrier Type_1A. PRIVATE</th>\n",
       "      <th>Carrier Type_2A. SIF</th>\n",
       "      <th>Carrier Type_3A. SELF PUBLIC</th>\n",
       "      <th>Carrier Type_4A. SELF PRIVATE</th>\n",
       "      <th>Carrier Type_5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)</th>\n",
       "      <th>Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS</th>\n",
       "      <th>Carrier Type_5D. SPECIAL FUND - UNKNOWN</th>\n",
       "      <th>Carrier Type_UNKNOWN</th>\n",
       "      <th>COVID-19 Indicator_N</th>\n",
       "      <th>COVID-19 Indicator_Y</th>\n",
       "      <th>District Name_ALBANY</th>\n",
       "      <th>District Name_BINGHAMTON</th>\n",
       "      <th>District Name_BUFFALO</th>\n",
       "      <th>District Name_HAUPPAUGE</th>\n",
       "      <th>District Name_NYC</th>\n",
       "      <th>District Name_ROCHESTER</th>\n",
       "      <th>District Name_STATEWIDE</th>\n",
       "      <th>District Name_SYRACUSE</th>\n",
       "      <th>Gender_F</th>\n",
       "      <th>Gender_M</th>\n",
       "      <th>Gender_U</th>\n",
       "      <th>Gender_X</th>\n",
       "      <th>Medical Fee Region_I</th>\n",
       "      <th>Medical Fee Region_II</th>\n",
       "      <th>Medical Fee Region_III</th>\n",
       "      <th>Medical Fee Region_IV</th>\n",
       "      <th>Medical Fee Region_UK</th>\n",
       "      <th>County of Injury</th>\n",
       "      <th>Industry Code</th>\n",
       "      <th>WCIO Cause of Injury Code</th>\n",
       "      <th>WCIO Nature of Injury Code</th>\n",
       "      <th>WCIO Part Of Body Code</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5393875</th>\n",
       "      <td>-0.984980</td>\n",
       "      <td>-0.478261</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.48</td>\n",
       "      <td>NEW HAMPSHIRE INSURANCE CO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13662</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005825</td>\n",
       "      <td>0.076072</td>\n",
       "      <td>0.017830</td>\n",
       "      <td>0.192838</td>\n",
       "      <td>0.001986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393091</th>\n",
       "      <td>-1.207101</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>1.117229</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>ZURICH AMERICAN INSURANCE CO</td>\n",
       "      <td>0.791516</td>\n",
       "      <td>14569</td>\n",
       "      <td>0.25</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001322</td>\n",
       "      <td>0.053698</td>\n",
       "      <td>0.020404</td>\n",
       "      <td>0.097254</td>\n",
       "      <td>0.065849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393889</th>\n",
       "      <td>-1.028675</td>\n",
       "      <td>-0.086957</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>1.087877</td>\n",
       "      <td>0.12</td>\n",
       "      <td>INDEMNITY INSURANCE CO OF</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12589</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.030317</td>\n",
       "      <td>0.036619</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.009551</td>\n",
       "      <td>0.013889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393887</th>\n",
       "      <td>-0.984980</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>0.929071</td>\n",
       "      <td>-0.72</td>\n",
       "      <td>STATE INSURANCE FUND</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12603</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020017</td>\n",
       "      <td>0.198926</td>\n",
       "      <td>0.017190</td>\n",
       "      <td>0.030240</td>\n",
       "      <td>0.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393848</th>\n",
       "      <td>-0.988621</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>-1.066667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>LM INSURANCE CORP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13029</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.027033</td>\n",
       "      <td>0.045963</td>\n",
       "      <td>0.025741</td>\n",
       "      <td>0.082126</td>\n",
       "      <td>0.063000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165240</th>\n",
       "      <td>1.001821</td>\n",
       "      <td>-0.478261</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.60</td>\n",
       "      <td>CATTARAUGUS COUNTY SI PLAN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14706</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005098</td>\n",
       "      <td>0.160792</td>\n",
       "      <td>0.046254</td>\n",
       "      <td>0.267133</td>\n",
       "      <td>0.090185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165331</th>\n",
       "      <td>1.007286</td>\n",
       "      <td>-0.565217</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.68</td>\n",
       "      <td>SAFETY NATIONAL CASUALTY CORP</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10453</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.068912</td>\n",
       "      <td>0.075841</td>\n",
       "      <td>0.025079</td>\n",
       "      <td>0.009013</td>\n",
       "      <td>0.054658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165285</th>\n",
       "      <td>0.983607</td>\n",
       "      <td>-0.391304</td>\n",
       "      <td>0.962894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.52</td>\n",
       "      <td>WESCO INSURANCE CO</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11590</td>\n",
       "      <td>0.75</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.075926</td>\n",
       "      <td>0.199259</td>\n",
       "      <td>0.064873</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>0.054658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165339</th>\n",
       "      <td>0.981785</td>\n",
       "      <td>-0.782609</td>\n",
       "      <td>0.962894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.88</td>\n",
       "      <td>TECHNOLOGY INSURANCE CO. INC.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10029</td>\n",
       "      <td>0.50</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052219</td>\n",
       "      <td>0.199259</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.062576</td>\n",
       "      <td>0.043508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165075</th>\n",
       "      <td>0.979964</td>\n",
       "      <td>1.304348</td>\n",
       "      <td>0.962894</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.04</td>\n",
       "      <td>TECHNOLOGY INSURANCE CO. INC.</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12779</td>\n",
       "      <td>0.00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.065073</td>\n",
       "      <td>0.020898</td>\n",
       "      <td>0.022253</td>\n",
       "      <td>0.073076</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2296104 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Accident Date  Age at Injury  Assembly Date  \\\n",
       "Claim Identifier                                                \n",
       "5393875               -0.984980      -0.478261      -1.066667   \n",
       "5393091               -1.207101       0.173913      -1.066667   \n",
       "5393889               -1.028675      -0.086957      -1.066667   \n",
       "5393887               -0.984980       0.826087      -1.066667   \n",
       "5393848               -0.988621       0.260870      -1.066667   \n",
       "...                         ...            ...            ...   \n",
       "6165240                1.001821      -0.478261       0.961039   \n",
       "6165331                1.007286      -0.565217       0.961039   \n",
       "6165285                0.983607      -0.391304       0.962894   \n",
       "6165339                0.981785      -0.782609       0.962894   \n",
       "6165075                0.979964       1.304348       0.962894   \n",
       "\n",
       "                  Average Weekly Wage  Birth Year  \\\n",
       "Claim Identifier                                    \n",
       "5393875                      0.000000        0.48   \n",
       "5393091                      1.117229       -0.12   \n",
       "5393889                      1.087877        0.12   \n",
       "5393887                      0.929071       -0.72   \n",
       "5393848                      0.000000       -0.20   \n",
       "...                               ...         ...   \n",
       "6165240                      0.000000        0.60   \n",
       "6165331                      0.000000       -1.68   \n",
       "6165285                      0.000000        0.52   \n",
       "6165339                      0.000000        0.88   \n",
       "6165075                      0.000000       -1.04   \n",
       "\n",
       "                                   Carrier Name  IME-4 Count Zip Code  \\\n",
       "Claim Identifier                                                        \n",
       "5393875              NEW HAMPSHIRE INSURANCE CO     0.000000    13662   \n",
       "5393091            ZURICH AMERICAN INSURANCE CO     0.791516    14569   \n",
       "5393889               INDEMNITY INSURANCE CO OF     0.000000    12589   \n",
       "5393887                    STATE INSURANCE FUND     0.000000    12603   \n",
       "5393848                       LM INSURANCE CORP     0.000000    13029   \n",
       "...                                         ...          ...      ...   \n",
       "6165240              CATTARAUGUS COUNTY SI PLAN     0.000000    14706   \n",
       "6165331           SAFETY NATIONAL CASUALTY CORP     0.000000    10453   \n",
       "6165285                      WESCO INSURANCE CO     0.000000    11590   \n",
       "6165339           TECHNOLOGY INSURANCE CO. INC.     0.000000    10029   \n",
       "6165075           TECHNOLOGY INSURANCE CO. INC.     0.000000    12779   \n",
       "\n",
       "                  Number of Dependents Has Alternative Dispute Resolution  \\\n",
       "Claim Identifier                                                            \n",
       "5393875                          -0.50                              False   \n",
       "5393091                           0.25                              False   \n",
       "5393889                           0.75                              False   \n",
       "5393887                          -0.50                              False   \n",
       "5393848                          -0.50                              False   \n",
       "...                                ...                                ...   \n",
       "6165240                           0.00                              False   \n",
       "6165331                          -0.50                              False   \n",
       "6165285                           0.75                              False   \n",
       "6165339                           0.50                              False   \n",
       "6165075                           0.00                              False   \n",
       "\n",
       "                  Has Attorney/Representative  Has COVID-19 Indicator  \\\n",
       "Claim Identifier                                                        \n",
       "5393875                                 False                   False   \n",
       "5393091                                  True                   False   \n",
       "5393889                                 False                   False   \n",
       "5393887                                 False                   False   \n",
       "5393848                                 False                   False   \n",
       "...                                       ...                     ...   \n",
       "6165240                                 False                   False   \n",
       "6165331                                 False                   False   \n",
       "6165285                                 False                   False   \n",
       "6165339                                 False                   False   \n",
       "6165075                                 False                   False   \n",
       "\n",
       "                  Has C-3 Date  Has C-2 Date  Has First Hearing Date  \\\n",
       "Claim Identifier                                                       \n",
       "5393875                      1             1                       1   \n",
       "5393091                      1             1                       1   \n",
       "5393889                      1             1                       1   \n",
       "5393887                      1             1                       1   \n",
       "5393848                      1             1                       1   \n",
       "...                        ...           ...                     ...   \n",
       "6165240                      1             1                       1   \n",
       "6165331                      1             1                       1   \n",
       "6165285                      1             1                       1   \n",
       "6165339                      1             1                       1   \n",
       "6165075                      1             1                       1   \n",
       "\n",
       "                  Alternative Dispute Resolution_N  \\\n",
       "Claim Identifier                                     \n",
       "5393875                                        1.0   \n",
       "5393091                                        1.0   \n",
       "5393889                                        1.0   \n",
       "5393887                                        1.0   \n",
       "5393848                                        1.0   \n",
       "...                                            ...   \n",
       "6165240                                        1.0   \n",
       "6165331                                        1.0   \n",
       "6165285                                        1.0   \n",
       "6165339                                        1.0   \n",
       "6165075                                        1.0   \n",
       "\n",
       "                  Alternative Dispute Resolution_U  \\\n",
       "Claim Identifier                                     \n",
       "5393875                                        0.0   \n",
       "5393091                                        0.0   \n",
       "5393889                                        0.0   \n",
       "5393887                                        0.0   \n",
       "5393848                                        0.0   \n",
       "...                                            ...   \n",
       "6165240                                        0.0   \n",
       "6165331                                        0.0   \n",
       "6165285                                        0.0   \n",
       "6165339                                        0.0   \n",
       "6165075                                        0.0   \n",
       "\n",
       "                  Alternative Dispute Resolution_Y  Attorney/Representative_N  \\\n",
       "Claim Identifier                                                                \n",
       "5393875                                        0.0                        1.0   \n",
       "5393091                                        0.0                        0.0   \n",
       "5393889                                        0.0                        1.0   \n",
       "5393887                                        0.0                        1.0   \n",
       "5393848                                        0.0                        1.0   \n",
       "...                                            ...                        ...   \n",
       "6165240                                        0.0                        1.0   \n",
       "6165331                                        0.0                        1.0   \n",
       "6165285                                        0.0                        1.0   \n",
       "6165339                                        0.0                        1.0   \n",
       "6165075                                        0.0                        1.0   \n",
       "\n",
       "                  Attorney/Representative_Y  Carrier Type_1A. PRIVATE  \\\n",
       "Claim Identifier                                                        \n",
       "5393875                                 0.0                       1.0   \n",
       "5393091                                 1.0                       1.0   \n",
       "5393889                                 0.0                       1.0   \n",
       "5393887                                 0.0                       0.0   \n",
       "5393848                                 0.0                       1.0   \n",
       "...                                     ...                       ...   \n",
       "6165240                                 0.0                       0.0   \n",
       "6165331                                 0.0                       1.0   \n",
       "6165285                                 0.0                       1.0   \n",
       "6165339                                 0.0                       1.0   \n",
       "6165075                                 0.0                       1.0   \n",
       "\n",
       "                  Carrier Type_2A. SIF  Carrier Type_3A. SELF PUBLIC  \\\n",
       "Claim Identifier                                                       \n",
       "5393875                            0.0                           0.0   \n",
       "5393091                            0.0                           0.0   \n",
       "5393889                            0.0                           0.0   \n",
       "5393887                            1.0                           0.0   \n",
       "5393848                            0.0                           0.0   \n",
       "...                                ...                           ...   \n",
       "6165240                            0.0                           1.0   \n",
       "6165331                            0.0                           0.0   \n",
       "6165285                            0.0                           0.0   \n",
       "6165339                            0.0                           0.0   \n",
       "6165075                            0.0                           0.0   \n",
       "\n",
       "                  Carrier Type_4A. SELF PRIVATE  \\\n",
       "Claim Identifier                                  \n",
       "5393875                                     0.0   \n",
       "5393091                                     0.0   \n",
       "5393889                                     0.0   \n",
       "5393887                                     0.0   \n",
       "5393848                                     0.0   \n",
       "...                                         ...   \n",
       "6165240                                     0.0   \n",
       "6165331                                     0.0   \n",
       "6165285                                     0.0   \n",
       "6165339                                     0.0   \n",
       "6165075                                     0.0   \n",
       "\n",
       "                  Carrier Type_5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)  \\\n",
       "Claim Identifier                                                             \n",
       "5393875                                                         0.0          \n",
       "5393091                                                         0.0          \n",
       "5393889                                                         0.0          \n",
       "5393887                                                         0.0          \n",
       "5393848                                                         0.0          \n",
       "...                                                             ...          \n",
       "6165240                                                         0.0          \n",
       "6165331                                                         0.0          \n",
       "6165285                                                         0.0          \n",
       "6165339                                                         0.0          \n",
       "6165075                                                         0.0          \n",
       "\n",
       "                  Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS  \\\n",
       "Claim Identifier                                                            \n",
       "5393875                                                         0.0         \n",
       "5393091                                                         0.0         \n",
       "5393889                                                         0.0         \n",
       "5393887                                                         0.0         \n",
       "5393848                                                         0.0         \n",
       "...                                                             ...         \n",
       "6165240                                                         0.0         \n",
       "6165331                                                         0.0         \n",
       "6165285                                                         0.0         \n",
       "6165339                                                         0.0         \n",
       "6165075                                                         0.0         \n",
       "\n",
       "                  Carrier Type_5D. SPECIAL FUND - UNKNOWN  \\\n",
       "Claim Identifier                                            \n",
       "5393875                                               0.0   \n",
       "5393091                                               0.0   \n",
       "5393889                                               0.0   \n",
       "5393887                                               0.0   \n",
       "5393848                                               0.0   \n",
       "...                                                   ...   \n",
       "6165240                                               0.0   \n",
       "6165331                                               0.0   \n",
       "6165285                                               0.0   \n",
       "6165339                                               0.0   \n",
       "6165075                                               0.0   \n",
       "\n",
       "                  Carrier Type_UNKNOWN  COVID-19 Indicator_N  \\\n",
       "Claim Identifier                                               \n",
       "5393875                            0.0                   1.0   \n",
       "5393091                            0.0                   1.0   \n",
       "5393889                            0.0                   1.0   \n",
       "5393887                            0.0                   1.0   \n",
       "5393848                            0.0                   1.0   \n",
       "...                                ...                   ...   \n",
       "6165240                            0.0                   1.0   \n",
       "6165331                            0.0                   1.0   \n",
       "6165285                            0.0                   1.0   \n",
       "6165339                            0.0                   1.0   \n",
       "6165075                            0.0                   1.0   \n",
       "\n",
       "                  COVID-19 Indicator_Y  District Name_ALBANY  \\\n",
       "Claim Identifier                                               \n",
       "5393875                            0.0                   0.0   \n",
       "5393091                            0.0                   0.0   \n",
       "5393889                            0.0                   1.0   \n",
       "5393887                            0.0                   1.0   \n",
       "5393848                            0.0                   0.0   \n",
       "...                                ...                   ...   \n",
       "6165240                            0.0                   0.0   \n",
       "6165331                            0.0                   0.0   \n",
       "6165285                            0.0                   0.0   \n",
       "6165339                            0.0                   0.0   \n",
       "6165075                            0.0                   0.0   \n",
       "\n",
       "                  District Name_BINGHAMTON  District Name_BUFFALO  \\\n",
       "Claim Identifier                                                    \n",
       "5393875                                0.0                    0.0   \n",
       "5393091                                0.0                    0.0   \n",
       "5393889                                0.0                    0.0   \n",
       "5393887                                0.0                    0.0   \n",
       "5393848                                0.0                    0.0   \n",
       "...                                    ...                    ...   \n",
       "6165240                                0.0                    1.0   \n",
       "6165331                                0.0                    0.0   \n",
       "6165285                                0.0                    0.0   \n",
       "6165339                                0.0                    0.0   \n",
       "6165075                                1.0                    0.0   \n",
       "\n",
       "                  District Name_HAUPPAUGE  District Name_NYC  \\\n",
       "Claim Identifier                                               \n",
       "5393875                               0.0                0.0   \n",
       "5393091                               0.0                0.0   \n",
       "5393889                               0.0                0.0   \n",
       "5393887                               0.0                0.0   \n",
       "5393848                               0.0                0.0   \n",
       "...                                   ...                ...   \n",
       "6165240                               0.0                0.0   \n",
       "6165331                               0.0                1.0   \n",
       "6165285                               0.0                1.0   \n",
       "6165339                               0.0                1.0   \n",
       "6165075                               0.0                0.0   \n",
       "\n",
       "                  District Name_ROCHESTER  District Name_STATEWIDE  \\\n",
       "Claim Identifier                                                     \n",
       "5393875                               0.0                      0.0   \n",
       "5393091                               1.0                      0.0   \n",
       "5393889                               0.0                      0.0   \n",
       "5393887                               0.0                      0.0   \n",
       "5393848                               0.0                      0.0   \n",
       "...                                   ...                      ...   \n",
       "6165240                               0.0                      0.0   \n",
       "6165331                               0.0                      0.0   \n",
       "6165285                               0.0                      0.0   \n",
       "6165339                               0.0                      0.0   \n",
       "6165075                               0.0                      0.0   \n",
       "\n",
       "                  District Name_SYRACUSE  Gender_F  Gender_M  Gender_U  \\\n",
       "Claim Identifier                                                         \n",
       "5393875                              1.0       0.0       1.0       0.0   \n",
       "5393091                              0.0       1.0       0.0       0.0   \n",
       "5393889                              0.0       0.0       1.0       0.0   \n",
       "5393887                              0.0       0.0       1.0       0.0   \n",
       "5393848                              1.0       0.0       1.0       0.0   \n",
       "...                                  ...       ...       ...       ...   \n",
       "6165240                              0.0       1.0       0.0       0.0   \n",
       "6165331                              0.0       0.0       1.0       0.0   \n",
       "6165285                              0.0       0.0       1.0       0.0   \n",
       "6165339                              0.0       1.0       0.0       0.0   \n",
       "6165075                              0.0       1.0       0.0       0.0   \n",
       "\n",
       "                  Gender_X  Medical Fee Region_I  Medical Fee Region_II  \\\n",
       "Claim Identifier                                                          \n",
       "5393875                0.0                   1.0                    0.0   \n",
       "5393091                0.0                   1.0                    0.0   \n",
       "5393889                0.0                   0.0                    1.0   \n",
       "5393887                0.0                   0.0                    1.0   \n",
       "5393848                0.0                   1.0                    0.0   \n",
       "...                    ...                   ...                    ...   \n",
       "6165240                0.0                   1.0                    0.0   \n",
       "6165331                0.0                   0.0                    0.0   \n",
       "6165285                0.0                   0.0                    0.0   \n",
       "6165339                0.0                   0.0                    0.0   \n",
       "6165075                0.0                   1.0                    0.0   \n",
       "\n",
       "                  Medical Fee Region_III  Medical Fee Region_IV  \\\n",
       "Claim Identifier                                                  \n",
       "5393875                              0.0                    0.0   \n",
       "5393091                              0.0                    0.0   \n",
       "5393889                              0.0                    0.0   \n",
       "5393887                              0.0                    0.0   \n",
       "5393848                              0.0                    0.0   \n",
       "...                                  ...                    ...   \n",
       "6165240                              0.0                    0.0   \n",
       "6165331                              0.0                    1.0   \n",
       "6165285                              0.0                    1.0   \n",
       "6165339                              0.0                    1.0   \n",
       "6165075                              0.0                    0.0   \n",
       "\n",
       "                  Medical Fee Region_UK  County of Injury  Industry Code  \\\n",
       "Claim Identifier                                                           \n",
       "5393875                             0.0          0.005825       0.076072   \n",
       "5393091                             0.0          0.001322       0.053698   \n",
       "5393889                             0.0          0.030317       0.036619   \n",
       "5393887                             0.0          0.020017       0.198926   \n",
       "5393848                             0.0          0.027033       0.045963   \n",
       "...                                 ...               ...            ...   \n",
       "6165240                             0.0          0.005098       0.160792   \n",
       "6165331                             0.0          0.068912       0.075841   \n",
       "6165285                             0.0          0.075926       0.199259   \n",
       "6165339                             0.0          0.052219       0.199259   \n",
       "6165075                             0.0          0.005032       0.065073   \n",
       "\n",
       "                  WCIO Cause of Injury Code  WCIO Nature of Injury Code  \\\n",
       "Claim Identifier                                                          \n",
       "5393875                            0.017830                    0.192838   \n",
       "5393091                            0.020404                    0.097254   \n",
       "5393889                            0.021558                    0.009551   \n",
       "5393887                            0.017190                    0.030240   \n",
       "5393848                            0.025741                    0.082126   \n",
       "...                                     ...                         ...   \n",
       "6165240                            0.046254                    0.267133   \n",
       "6165331                            0.025079                    0.009013   \n",
       "6165285                            0.064873                    0.021656   \n",
       "6165339                            0.005087                    0.062576   \n",
       "6165075                            0.020898                    0.022253   \n",
       "\n",
       "                  WCIO Part Of Body Code  \n",
       "Claim Identifier                          \n",
       "5393875                         0.001986  \n",
       "5393091                         0.065849  \n",
       "5393889                         0.013889  \n",
       "5393887                         0.063000  \n",
       "5393848                         0.063000  \n",
       "...                                  ...  \n",
       "6165240                         0.090185  \n",
       "6165331                         0.054658  \n",
       "6165285                         0.054658  \n",
       "6165339                         0.043508  \n",
       "6165075                         0.073076  \n",
       "\n",
       "[2296104 rows x 52 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'NEW HAMPSHIRE INSURANCE CO'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m\n\u001b[1;32m      1\u001b[0m logreg_cv \u001b[38;5;241m=\u001b[39m LogisticRegressionCV(\n\u001b[1;32m      2\u001b[0m     penalty\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msaga\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;66;03m# Use SAGA solver for large datasets \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2000\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[0;32m---> 12\u001b[0m \u001b[43mlogreg_cv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Identify selected and unselected features\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(logreg_cv\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:1868\u001b[0m, in \u001b[0;36mLogisticRegressionCV.fit\u001b[0;34m(self, X, y, sample_weight, **params)\u001b[0m\n\u001b[1;32m   1861\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1862\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ml1_ratios parameter is only used when penalty \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1863\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124melasticnet\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Got (penalty=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpenalty)\n\u001b[1;32m   1864\u001b[0m         )\n\u001b[1;32m   1866\u001b[0m     l1_ratios_ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m-> 1868\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1869\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1870\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1872\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1873\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1874\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mliblinear\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msag\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1875\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1876\u001b[0m check_classification_targets(y)\n\u001b[1;32m   1878\u001b[0m class_weight \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_weight\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/sklearn/base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/sklearn/utils/validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[1;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1299\u001b[0m     )\n\u001b[0;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1315\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1316\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[1;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/sklearn/utils/validation.py:929\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pandas_requires_conversion:\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;66;03m# pandas dataframe requires conversion earlier to handle extension dtypes with\u001b[39;00m\n\u001b[1;32m    926\u001b[0m     \u001b[38;5;66;03m# nans\u001b[39;00m\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;66;03m# Use the original dtype for conversion if dtype is None\u001b[39;00m\n\u001b[1;32m    928\u001b[0m     new_dtype \u001b[38;5;241m=\u001b[39m dtype_orig \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m dtype\n\u001b[0;32m--> 929\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;66;03m# Since we converted here, we do not need to convert again later\u001b[39;00m\n\u001b[1;32m    931\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/pandas/core/generic.py:6643\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6637\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6638\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6639\u001b[0m     ]\n\u001b[1;32m   6641\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6643\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6644\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6645\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'NEW HAMPSHIRE INSURANCE CO'"
     ]
    }
   ],
   "source": [
    "logreg_cv = LogisticRegressionCV(\n",
    "    penalty='l1',\n",
    "    solver='saga', # Use SAGA solver for large datasets \n",
    "    Cs=5,\n",
    "    cv=ps,\n",
    "    random_state=42,\n",
    "    class_weight='balanced', # Balance class weights\n",
    "    n_jobs=-1,\n",
    "    scoring='f1_macro', # Use macro F1 score as scoring metric\n",
    "    max_iter=2000\n",
    ")\n",
    "logreg_cv.fit(X_combined, y_combined)\n",
    "\n",
    "# Identify selected and unselected features\n",
    "if len(logreg_cv.coef_.shape) > 1:\n",
    "    coefs = np.abs(logreg_cv.coef_).mean(axis=0)\n",
    "else:\n",
    "    coefs = logreg_cv.coef_.flatten()\n",
    "\n",
    "selected_features = X_combined.columns[coefs != 0].tolist()\n",
    "unselected_features = X_combined.columns[coefs == 0].tolist()\n",
    "\n",
    "sorted_idx = np.argsort(np.abs(coefs))\n",
    "sorted_features = X_combined.columns[sorted_idx]\n",
    "sorted_coefs = coefs[sorted_idx]\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.barh(sorted_features, sorted_coefs)\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance via Logistic Regression with L1 Penalty (Sorted)\")\n",
    "plt.axvline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Unselected Features:\", unselected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put features together with there coefficients\n",
    "feature_importance = pd.DataFrame({'Feature': sorted_features, 'Coefficient': sorted_coefs})\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                                | Coefficient |\n",
    "|----------------------------------------|-------------|\n",
    "| Alternative Dispute Resolution_nan     | 0.091208    |\n",
    "| Medical Fee Region_III                 | 0.104723    |\n",
    "| Accident Date                          | 0.156352    |\n",
    "| Birth Year                             | 0.161018    |\n",
    "| Number of Dependents                   | 0.162521    |\n",
    "| Medical Fee Region_UK                  | 0.199784    |\n",
    "| Medical Fee Region_I                   | 0.211184    |\n",
    "| Medical Fee Region_II                  | 0.218863    |\n",
    "| Medical Fee Region_IV                  | 0.251852    |\n",
    "| Has C-3 Date                           | 0.339323    |\n",
    "| Has C-2 Date                           | 0.339323    |\n",
    "| Has First Hearing Date                 | 0.339323    |\n",
    "| Attorney/Representative_True           | 0.344442    |\n",
    "| Carrier Type_5A. SPECIAL FUND - CONS. COMM. (S... | 0.354133    |\n",
    "| Carrier Type_4A. SELF PRIVATE          | 0.426216    |\n",
    "| Carrier Type_3A. SELF PUBLIC           | 0.427759    |\n",
    "| Age at Injury                          | 0.448413    |\n",
    "| Gender_X                               | 0.459640    |\n",
    "| COVID-19 Indicator_False               | 0.469610    |\n",
    "| Carrier Type_1A. PRIVATE               | 0.495387    |\n",
    "| Carrier Type_5C. SPECIAL FUND - POI CARRIER WC... | 0.506768    |\n",
    "| Assembly Date                          | 0.543958    |\n",
    "| District Name_HAUPPAUGE               | 0.592683    |\n",
    "| IME-4 Count                            | 0.615296    |\n",
    "| District Name_BUFFALO                 | 0.658296    |\n",
    "| District Name_SYRACUSE                | 0.679366    |\n",
    "| District Name_NYC                     | 0.706079    |\n",
    "| District Name_ALBANY                  | 0.709348    |\n",
    "| Carrier Type_5D. SPECIAL FUND - UNKNOWN | 0.721796    |\n",
    "| District Name_BINGHAMTON              | 0.733356    |\n",
    "| District Name_STATEWIDE               | 0.814429    |\n",
    "| Alternative Dispute Resolution_False  | 0.955822    |\n",
    "| Gender_F                               | 1.027072    |\n",
    "| County of Injury                       | 1.331568    |\n",
    "| Alternative Dispute Resolution_True   | 1.348975    |\n",
    "| COVID-19 Indicator_True               | 1.349827    |\n",
    "| Gender_M                               | 1.498185    |\n",
    "| Attorney/Representative_False         | 1.740615    |\n",
    "| Carrier Type_2A. SIF                  | 2.027552    |\n",
    "| Industry Code                          | 2.075674    |\n",
    "| Carrier Type_UNKNOWN                  | 2.330205    |\n",
    "| Gender_U                               | 2.846922    |\n",
    "| Average Weekly Wage                    | 3.204603    |\n",
    "| Zip Code                               | 3.625286    |\n",
    "| WCIO Nature of Injury Code            | 4.186389    |\n",
    "| District Name_ROCHESTER               | 4.952202    |\n",
    "| WCIO Cause of Injury Code             | 6.970056    |\n",
    "| WCIO Part Of Body Code                | 8.713728    |\n",
    "| Carrier Name                           | 9.174048    |\n",
    "\n",
    "All feature are selected by using this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV with preprocessing_scaling_encoding_dum (All features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize RandomForest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,            # Number of trees\n",
    "    max_depth=15,                # Limit tree depth\n",
    "    min_samples_split=50,        # Minimum samples for a split\n",
    "    min_samples_leaf=20,         # Minimum samples per leaf\n",
    "    max_features='sqrt',         # Features to consider per split\n",
    "    class_weight='balanced',     # Handle class imbalance\n",
    "    bootstrap=True,              # Use bootstrapping\n",
    "    random_state=42,             # Ensure reproducibility\n",
    "    n_jobs=-1                    # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Set up RFECV with RandomForest and cross-validation\n",
    "rfecv = RFECV(estimator=rf_model, step=1, cv=ps, scoring='f1_macro') \n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_combined, y_combined)\n",
    "\n",
    "#Get the selected features\n",
    "selected_features_RFE_basic = X_combined.columns[rfecv.support_].tolist()\n",
    "optimal_num_features = rfecv.n_features_\n",
    "feature_ranking = rfecv.ranking_\n",
    "\n",
    "print(\"Optimal number of features:\", optimal_num_features)\n",
    "print(\"Selected Features:\", selected_features_RFE_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking = pd.DataFrame({'Feature': X_combined.columns, 'Ranking': feature_ranking})\n",
    "Optimal_number_of_features = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal number of features: 26\n",
    "Selected Features: ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_NYC', 'Gender_F', 'Gender_M', 'Medical Fee Region_I', 'Medical Fee Region_IV', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_RFE_basic = ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Has Attorney/Representative', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'Has COVID-19 Indicator', 'District Name_NYC', 'Gender_F', 'Gender_M', 'Medical Fee Region_I', 'Medical Fee Region_IV', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection report (simple preprocesing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                                      | Lasso       | RFE | Chi-Square AND Anova |\n",
    "|----------------------------------------------|-------------|-----|----------------------|\n",
    "| Accident Date                                | 0.156352    | 1   | Yes                  |\n",
    "| Age at Injury                                | 0.448413    | 1   | Yes                  |\n",
    "| Assembly Date                                | 0.543958    | 1   | Yes                  |\n",
    "| Average Weekly Wage                          | 3.204603    | 1   | Yes                  |\n",
    "| Birth Year                                   | 0.161018    | 1   | Yes                  |\n",
    "| IME-4 Count                                  | 0.615296    | 1   | Yes                  |\n",
    "| Number of Dependents                         | 0.162521    | 1   | Yes                  |\n",
    "| Attorney/Representative_False               | 1.740615    | 1   | Yes                  |\n",
    "| Attorney/Representative_True                | 0.344442    | 1   | Yes                  |\n",
    "| Carrier Type_1A. PRIVATE                     | 0.495387    | 1   | Yes                  |\n",
    "| Carrier Type_2A. SIF                         | 2.027552    | 1   | Yes                  |\n",
    "| Carrier Type_3A. SELF PUBLIC                 | 0.427759    | 1   | Yes                  |\n",
    "| COVID-19 Indicator_False                     | 0.469610    | 1   | Yes                  |\n",
    "| COVID-19 Indicator_True                      | 1.349827    | 1   | Yes                  |\n",
    "| District Name_NYC                            | 0.706079    | 1   | Yes                  |\n",
    "| Gender_F                                     | 1.027072    | 1   | Yes                  |\n",
    "| Gender_M                                     | 1.498185    | 1   | Yes                  |\n",
    "| Medical Fee Region_I                         | 0.211184    | 1   | Yes                  |\n",
    "| Medical Fee Region_IV                        | 0.251852    | 1   | Yes                  |\n",
    "| Carrier Name                                 | 9.174048    | 1   | NAN                  |\n",
    "| County of Injury                             | 1.331568    | 1   | NAN                  |\n",
    "| Industry Code                                | 2.075674    | 1   | NAN                  |\n",
    "| WCIO Cause of Injury Code                    | 6.970056    | 1   | NAN                  |\n",
    "| WCIO Nature of Injury Code                   | 4.186389    | 1   | NAN                  |\n",
    "| WCIO Part Of Body Code                       | 8.713728    | 1   | NAN                  |\n",
    "| Zip Code                                     | 3.625286    | 1   | NAN                   |\n",
    "| District Name_BUFFALO                        | 0.658296    | 2   | Yes                  |\n",
    "| Medical Fee Region_II                        | 0.218863    | 3   | Yes                  |\n",
    "| District Name_ALBANY                         | 0.709348    | 4   | Yes                  |\n",
    "| District Name_HAUPPAUGE                      | 0.592683    | 5   | Yes                  |\n",
    "| Medical Fee Region_UK                        | 0.199784    | 6   | Yes                  |\n",
    "| Medical Fee Region_III                       | 0.104723    | 7   | Yes                  |\n",
    "| District Name_STATEWIDE                      | 0.814429    | 8   | Yes                  |\n",
    "| District Name_SYRACUSE                       | 0.679366    | 9  | Yes                  |\n",
    "| Carrier Type_4A. SELF PRIVATE                | 0.426216    | 10  | Yes                  |\n",
    "| Alternative Dispute Resolution_False         | 0.955822    | 11  | No                   |\n",
    "| District Name_BINGHAMTON                     | 0.733356    | 12  | Yes                  |\n",
    "| District Name_ROCHESTER                      | 4.952202    | 13  | Yes                  |\n",
    "| Alternative Dispute Resolution_True          | 1.348975    | 14  | Yes                  |\n",
    "| Carrier Type_5D. SPECIAL FUND - UNKNOWN      | 0.721796    | 15  | Yes                  |\n",
    "| Carrier Type_UNKNOWN                         | 2.330205    | 16  | Yes                  |\n",
    "| Gender_U                                     | 2.846922    | 17  | Yes                  |\n",
    "| Carrier Type_5A. SPECIAL FUND - CONS. COMM...| 0.354133    | 18  | Yes                  |\n",
    "| Has C-2 Date                                 | 0.339323    | 19  | No                  |\n",
    "| Carrier Type_5C. SPECIAL FUND - POI CARRIE...| 0.506768    | 20  | Yes                  |\n",
    "| Has First Hearing Date                       | 0.339323    | 21  | No                  |\n",
    "| Has C-3 Date                                 | 0.339323    | 22  | No                  |\n",
    "| Alternative Dispute Resolution_nan           | 0.091208    | 23  | No                   |\n",
    "| Gender_X                                     | 0.459640    | 24  | Yes                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are tuning the hyperparameter for all models using GridSearch\n",
    "- All models get the same pre-processed data set across the same folds (PredefinedSplit)\n",
    "- The feature selected are the one selected with the RFECV (preprocessing_scaling_encoding_dum)<br>\n",
    "\n",
    "Afterwards all tuned models get evaluted based on their performance for predictions on train and val across all folds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create PredefinedSplit with selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps, X_combined, y_combined = create_predifined_split_with_features(X, y, preprocessing_scaling_encoding_dum,selected_features_RFE_basic, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(X, y, model, param_grid, ps, n_splits=5):\n",
    "    \"\"\"\n",
    "    Finds the best hyperparameters for a given model using GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Creates a PredefinedSplit object\n",
    "    - Creates a GridSearchCV object\n",
    "    - Fits the GridSearchCV object\n",
    "    - Returns the best hyperparameters and the best score\n",
    "    \"\"\"\n",
    "\n",
    "    scoring = make_scorer(f1_score, average='macro')\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=ps,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_combined, y_combined)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best F1-macro Score:\", grid_search.best_score_)\n",
    "\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2', 'elasticnet'],         \n",
    "    'C': [0.01, 0.1, 1, 10],              \n",
    "    'solver': ['lbfgs', 'saga'],            \n",
    "    'class_weight': ['balanced', None],      \n",
    "    'l1_ratio': [0.5]                   \n",
    "}\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 160 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n96 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 929, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'NEW HAMPSHIRE INSURANCE CO'\n\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 929, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'ZURICH AMERICAN INSURANCE CO'\n\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[230], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m logisticregression_best_param, logisticregression_best_score \u001b[38;5;241m=\u001b[39m \u001b[43mget_best_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam_grid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[228], line 23\u001b[0m, in \u001b[0;36mget_best_parameters\u001b[1;34m(X, y, model, param_grid, ps, n_splits)\u001b[0m\n\u001b[0;32m     12\u001b[0m scoring \u001b[38;5;241m=\u001b[39m make_scorer(f1_score, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(\n\u001b[0;32m     15\u001b[0m     model,\n\u001b[0;32m     16\u001b[0m     param_grid,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     20\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     21\u001b[0m )\n\u001b[1;32m---> 23\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_combined\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_combined\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest Parameters:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_params_)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBest F1-macro Score:\u001b[39m\u001b[38;5;124m\"\u001b[39m, grid_search\u001b[38;5;241m.\u001b[39mbest_score_)\n",
      "File \u001b[1;32mc:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m   1013\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m   1015\u001b[0m     )\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m-> 1019\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1021\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1571\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1572\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1573\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:996\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    989\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    990\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    991\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    992\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    993\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    994\u001b[0m     )\n\u001b[1;32m--> 996\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    998\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    999\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m   1000\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m   1001\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m   1002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32mc:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:529\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    522\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    523\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    524\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    526\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    527\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    528\u001b[0m     )\n\u001b[1;32m--> 529\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    532\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    538\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    539\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 160 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n96 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 929, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'NEW HAMPSHIRE INSURANCE CO'\n\n--------------------------------------------------------------------------------\n24 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1223, in fit\n    X, y = self._validate_data(\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 650, in _validate_data\n    X, y = check_X_y(X, y, **check_params)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 1301, in check_X_y\n    X = check_array(\n        ^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\utils\\validation.py\", line 929, in check_array\n    array = array.astype(new_dtype)\n            ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\generic.py\", line 6643, in astype\n    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 430, in astype\n    return self.apply(\n           ^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 363, in apply\n    applied = getattr(b, f)(**kwargs)\n              ^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py\", line 758, in astype\n    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 237, in astype_array_safe\n    new_values = astype_array(values, dtype, copy=copy)\n                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 182, in astype_array\n    values = _astype_nansafe(values, dtype, copy=copy)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py\", line 133, in _astype_nansafe\n    return arr.astype(dtype, copy=True)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nValueError: could not convert string to float: 'ZURICH AMERICAN INSURANCE CO'\n\n--------------------------------------------------------------------------------\n40 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\base.py\", line 1473, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1194, in fit\n    solver = _check_solver(self.solver, self.penalty, self.dual)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\timst\\anaconda3\\envs\\DM2425\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 67, in _check_solver\n    raise ValueError(\nValueError: Solver lbfgs supports only 'l2' or None penalties, got elasticnet penalty.\n"
     ]
    }
   ],
   "source": [
    "logisticregression_best_param, logisticregression_best_score = get_best_parameters(X, y, model, param_grid, ps, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: \n",
    "- 'penalty': l2\n",
    "- 'C': 10\n",
    "- 'solver': 'lbfgs'\n",
    "- 'class_weight': 'balanced' \n",
    "- 'l1_ratio': 0.5 <br>\n",
    "\n",
    "Best F1-macro Score: 0.29291927882029445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "model=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier_best_param, RandomForestClassifier_best_score = get_best_parameters(X, y, model, param_grid, ps, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RandomForestClassifier_best_param, RandomForestClassifier_best_score = get_best_parameters(X, y, model, param_grid, ps, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: \n",
    "- 'bootstrap': False\n",
    "- 'max_depth': None\n",
    "- 'max_features': 'sqrt'\n",
    "- 'min_samples_leaf': 1\n",
    "- 'min_samples_split': 2\n",
    "-  'n_estimators': 200 <br>\n",
    "\n",
    "Best_NN F1-macro Score: 0.3706281959869002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (int(0.75 * len(selected_features)), int(0.5 * len(selected_features))),  # Original configuration\n",
    "        (int(0.5 * len(selected_features)), int(0.25 * len(selected_features)), int(0.125 * len(selected_features))),  # Three layers\n",
    "    ],\n",
    "    'learning_rate_init': [0.01, 0.1],  # Test lower and higher learning rates\n",
    "    'activation': ['relu', 'tanh'],  # Compare relu and tanh\n",
    "    'alpha': [0.001, 0.01],  # Regularization strength\n",
    "    'batch_size': ['auto', 64, 128],  # Test different batch sizes\n",
    "}\n",
    "model = MLPClassifier(solver='adam',max_iter=1000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nnGS_best_params, nnGS_best_score = get_best_parameters(X, y, model, param_grid, ps, selected_features, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters:\n",
    "- 'activation': 'tanh'\n",
    "- 'alpha': 0.001\n",
    "- 'batch_size': 'auto' \n",
    "- 'hidden_layer_sizes': (34, 23)\n",
    "- 'learning_rate_init': 0.01<br>\n",
    "\n",
    "Best_NN F1-macro Score: 0.30394956984435917"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.01, 0.3],\n",
    "    'gamma': [0, 2],\n",
    "    'reg_alpha': [0, 5],\n",
    "    'reg_lambda': [1, 10],\n",
    "    'min_child_weight': [1, 5] \n",
    "}\n",
    "model=XGBClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb_best_params, xgb_best_score = get_best_parameters(X, y, model, param_grid, ps, selected_features, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: \n",
    "- 'gamma': 0\n",
    "- 'learning_rate': 0.3\n",
    "- 'max_depth': 6\n",
    "-  'min_child_weight': 1\n",
    "-  'n_estimators': 100\n",
    "-  'reg_alpha': 0\n",
    "-  'reg_lambda': 1<br>\n",
    "\n",
    "Best_Xgboost F1-macro Score: 0.44258821978115226<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### kNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform'], # Weight function\n",
    "    'metric': ['minkowski'],\n",
    "    'p': [1, 2], # Power parameter for Minkowski distance\n",
    "    'algorithm': ['auto', 'ball_tree'],  # Algorithm for nearest neighbor search\n",
    "    'leaf_size': [20, 30, 40, 50] \n",
    "}\n",
    "\n",
    "model=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_best_param, knn_best_score = get_best_parameters(X, y, model, param_grid, ps, selected_features, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knn_best_parameter:\n",
    "- 'algorithm': 'auto'\n",
    "- 'leaf_size': 20\n",
    "- 'metric': 'minkowski'\n",
    "- 'n_neighbors': 5\n",
    "- 'p': 1\n",
    "- 'weights': 'uniform' <br>\n",
    "\n",
    "Knn_Best F1-macro Score:: 0.3001599658723925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_with_overfitting_check(X, y, predefined_split, selected_features, models):\n",
    "    \"\"\"\n",
    "    Evaluates multiple models on a dataset with a predefined split and calculates train-test metric differences.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): Feature dataset.\n",
    "    - y (pd.Series or np.array): Target variable.\n",
    "    - predefined_split (PredefinedSplit): Predefined split object for cross-validation.\n",
    "    - models (dict): Dictionary of models, where keys are model names and values are model instances.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Summary table with mean, variance, and train-test differences for evaluation metrics.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        fold_metrics = {\n",
    "            'accuracy_train': [],\n",
    "            'accuracy_test': [],\n",
    "            'precision_macro_train': [],\n",
    "            'precision_macro_test': [],\n",
    "            'recall_macro_train': [],\n",
    "            'recall_macro_test': [],\n",
    "            'f1_macro_train': [],\n",
    "            'f1_macro_test': []\n",
    "        }\n",
    "        \n",
    "        # Loop through predefined splits\n",
    "        for train_idx, test_idx in predefined_split.split():\n",
    "            # Split data\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train[selected_features], y_train)\n",
    "            \n",
    "            # Predict on train and test data\n",
    "            y_train_pred = model.predict(X_train[selected_features])\n",
    "            y_test_pred = model.predict(X_test[selected_features])\n",
    "            \n",
    "            # Calculate metrics for train and test data\n",
    "            fold_metrics['accuracy_train'].append(accuracy_score(y_train, y_train_pred))\n",
    "            fold_metrics['accuracy_test'].append(accuracy_score(y_test, y_test_pred))\n",
    "            fold_metrics['precision_macro_train'].append(precision_score(y_train, y_train_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['precision_macro_test'].append(precision_score(y_test, y_test_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['recall_macro_train'].append(recall_score(y_train, y_train_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['recall_macro_test'].append(recall_score(y_test, y_test_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['f1_macro_train'].append(f1_score(y_train, y_train_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['f1_macro_test'].append(f1_score(y_test, y_test_pred, average='macro', zero_division=0))\n",
    "        \n",
    "        # Calculate mean, variance, and train-test differences for each metric\n",
    "        for metric_name in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
    "            train_metric = np.array(fold_metrics[f'{metric_name}_train'])\n",
    "            test_metric = np.array(fold_metrics[f'{metric_name}_test'])\n",
    "            \n",
    "            mean_train = np.mean(train_metric)\n",
    "            mean_test = np.mean(test_metric)\n",
    "            variance_train = np.var(train_metric)\n",
    "            variance_test = np.var(test_metric)\n",
    "            mean_difference = mean_train - mean_test\n",
    "            \n",
    "            results.append({\n",
    "                'Model': model_name,\n",
    "                'Metric': metric_name,\n",
    "                'Mean_Train': mean_train,\n",
    "                'Mean_Test': mean_test,\n",
    "                'Variance_Train': variance_train,\n",
    "                'Variance_Test': variance_test,\n",
    "                'Train-Test_Difference': mean_difference\n",
    "            })\n",
    "        \n",
    "        print(results)\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(penalty='l2', C=10, solver='lbfgs', class_weight='balanced', l1_ratio=0.5, max_iter=1000, n_jobs=-1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=3, weights='uniform', metric='minkowski', p=1, algorithm='auto', leaf_size=20, n_jobs=-1),\n",
    "    'MLP': MLPClassifier( solver='adam', max_iter=1000, random_state=42, activation='tanh', alpha=0.001, batch_size='auto', hidden_layer_sizes=(int(0.75 * len(selected_features_RFE_basic)), int(0.5 * len(selected_features_RFE_basic))), learning_rate_init=0.01),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', bootstrap=False, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(gamma = 0, learning_rate = 0.3, max_depth = 6, min_child_weight = 1, n_estimators = 200, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}, {'Model': 'MLP', 'Metric': 'accuracy', 'Mean_Train': 0.7648826001526843, 'Mean_Test': 0.7642615526308056, 'Variance_Train': 4.956358065795995e-06, 'Variance_Test': 2.358998292495016e-06, 'Train-Test_Difference': 0.0006210475218786371}, {'Model': 'MLP', 'Metric': 'precision_macro', 'Mean_Train': 0.4002431610909952, 'Mean_Test': 0.4109170247531673, 'Variance_Train': 7.107619724525379e-05, 'Variance_Test': 0.0010936824097936206, 'Train-Test_Difference': -0.0106738636621721}, {'Model': 'MLP', 'Metric': 'recall_macro', 'Mean_Train': 0.30991650365407225, 'Mean_Test': 0.3096918087272804, 'Variance_Train': 0.0001660723266943243, 'Variance_Test': 0.0001557380275599381, 'Train-Test_Difference': 0.00022469492679183523}, {'Model': 'MLP', 'Metric': 'f1_macro', 'Mean_Train': 0.3065260622049793, 'Mean_Test': 0.30640756645758416, 'Variance_Train': 0.0002847270361951682, 'Variance_Test': 0.00025894250509786025, 'Train-Test_Difference': 0.00011849574739514201}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}, {'Model': 'MLP', 'Metric': 'accuracy', 'Mean_Train': 0.7648826001526843, 'Mean_Test': 0.7642615526308056, 'Variance_Train': 4.956358065795995e-06, 'Variance_Test': 2.358998292495016e-06, 'Train-Test_Difference': 0.0006210475218786371}, {'Model': 'MLP', 'Metric': 'precision_macro', 'Mean_Train': 0.4002431610909952, 'Mean_Test': 0.4109170247531673, 'Variance_Train': 7.107619724525379e-05, 'Variance_Test': 0.0010936824097936206, 'Train-Test_Difference': -0.0106738636621721}, {'Model': 'MLP', 'Metric': 'recall_macro', 'Mean_Train': 0.30991650365407225, 'Mean_Test': 0.3096918087272804, 'Variance_Train': 0.0001660723266943243, 'Variance_Test': 0.0001557380275599381, 'Train-Test_Difference': 0.00022469492679183523}, {'Model': 'MLP', 'Metric': 'f1_macro', 'Mean_Train': 0.3065260622049793, 'Mean_Test': 0.30640756645758416, 'Variance_Train': 0.0002847270361951682, 'Variance_Test': 0.00025894250509786025, 'Train-Test_Difference': 0.00011849574739514201}, {'Model': 'Decision Tree', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.7200457776280091, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 7.2965412683838725e-06, 'Train-Test_Difference': 0.2799503026896688}, {'Model': 'Decision Tree', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.4615245572698397, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 0.000127724245376472, 'Train-Test_Difference': 0.538452836673462}, {'Model': 'Decision Tree', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.4765612104519021, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00020845492031301236, 'Train-Test_Difference': 0.523437819183959}, {'Model': 'Decision Tree', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.4682465894888965, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0001473811563851997, 'Train-Test_Difference': 0.531741621097205}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}, {'Model': 'MLP', 'Metric': 'accuracy', 'Mean_Train': 0.7648826001526843, 'Mean_Test': 0.7642615526308056, 'Variance_Train': 4.956358065795995e-06, 'Variance_Test': 2.358998292495016e-06, 'Train-Test_Difference': 0.0006210475218786371}, {'Model': 'MLP', 'Metric': 'precision_macro', 'Mean_Train': 0.4002431610909952, 'Mean_Test': 0.4109170247531673, 'Variance_Train': 7.107619724525379e-05, 'Variance_Test': 0.0010936824097936206, 'Train-Test_Difference': -0.0106738636621721}, {'Model': 'MLP', 'Metric': 'recall_macro', 'Mean_Train': 0.30991650365407225, 'Mean_Test': 0.3096918087272804, 'Variance_Train': 0.0001660723266943243, 'Variance_Test': 0.0001557380275599381, 'Train-Test_Difference': 0.00022469492679183523}, {'Model': 'MLP', 'Metric': 'f1_macro', 'Mean_Train': 0.3065260622049793, 'Mean_Test': 0.30640756645758416, 'Variance_Train': 0.0002847270361951682, 'Variance_Test': 0.00025894250509786025, 'Train-Test_Difference': 0.00011849574739514201}, {'Model': 'Decision Tree', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.7200457776280091, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 7.2965412683838725e-06, 'Train-Test_Difference': 0.2799503026896688}, {'Model': 'Decision Tree', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.4615245572698397, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 0.000127724245376472, 'Train-Test_Difference': 0.538452836673462}, {'Model': 'Decision Tree', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.4765612104519021, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00020845492031301236, 'Train-Test_Difference': 0.523437819183959}, {'Model': 'Decision Tree', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.4682465894888965, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0001473811563851997, 'Train-Test_Difference': 0.531741621097205}, {'Model': 'Random Forest', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.8349046898795723, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 1.4609380649261503e-06, 'Train-Test_Difference': 0.1650913904381056}, {'Model': 'Random Forest', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.8718160636000647, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 5.639710050607065e-05, 'Train-Test_Difference': 0.12816133034323707}, {'Model': 'Random Forest', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.5489090744724608, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00025384904196707944, 'Train-Test_Difference': 0.4510899551634002}, {'Model': 'Random Forest', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.6287462535413679, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0003302599950561454, 'Train-Test_Difference': 0.3712419570447336}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}, {'Model': 'MLP', 'Metric': 'accuracy', 'Mean_Train': 0.7648826001526843, 'Mean_Test': 0.7642615526308056, 'Variance_Train': 4.956358065795995e-06, 'Variance_Test': 2.358998292495016e-06, 'Train-Test_Difference': 0.0006210475218786371}, {'Model': 'MLP', 'Metric': 'precision_macro', 'Mean_Train': 0.4002431610909952, 'Mean_Test': 0.4109170247531673, 'Variance_Train': 7.107619724525379e-05, 'Variance_Test': 0.0010936824097936206, 'Train-Test_Difference': -0.0106738636621721}, {'Model': 'MLP', 'Metric': 'recall_macro', 'Mean_Train': 0.30991650365407225, 'Mean_Test': 0.3096918087272804, 'Variance_Train': 0.0001660723266943243, 'Variance_Test': 0.0001557380275599381, 'Train-Test_Difference': 0.00022469492679183523}, {'Model': 'MLP', 'Metric': 'f1_macro', 'Mean_Train': 0.3065260622049793, 'Mean_Test': 0.30640756645758416, 'Variance_Train': 0.0002847270361951682, 'Variance_Test': 0.00025894250509786025, 'Train-Test_Difference': 0.00011849574739514201}, {'Model': 'Decision Tree', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.7200457776280091, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 7.2965412683838725e-06, 'Train-Test_Difference': 0.2799503026896688}, {'Model': 'Decision Tree', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.4615245572698397, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 0.000127724245376472, 'Train-Test_Difference': 0.538452836673462}, {'Model': 'Decision Tree', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.4765612104519021, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00020845492031301236, 'Train-Test_Difference': 0.523437819183959}, {'Model': 'Decision Tree', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.4682465894888965, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0001473811563851997, 'Train-Test_Difference': 0.531741621097205}, {'Model': 'Random Forest', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.8349046898795723, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 1.4609380649261503e-06, 'Train-Test_Difference': 0.1650913904381056}, {'Model': 'Random Forest', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.8718160636000647, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 5.639710050607065e-05, 'Train-Test_Difference': 0.12816133034323707}, {'Model': 'Random Forest', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.5489090744724608, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00025384904196707944, 'Train-Test_Difference': 0.4510899551634002}, {'Model': 'Random Forest', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.6287462535413679, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0003302599950561454, 'Train-Test_Difference': 0.3712419570447336}, {'Model': 'XGBoost', 'Metric': 'accuracy', 'Mean_Train': 0.8191453871807308, 'Mean_Test': 0.79444310934698, 'Variance_Train': 1.2222486025748864e-07, 'Variance_Test': 8.284927068121797e-07, 'Train-Test_Difference': 0.024702277833750785}, {'Model': 'XGBoost', 'Metric': 'precision_macro', 'Mean_Train': 0.865285079747261, 'Mean_Test': 0.7572305265678835, 'Variance_Train': 2.881964700788584e-07, 'Variance_Test': 1.7124830365727337e-05, 'Train-Test_Difference': 0.10805455317937751}, {'Model': 'XGBoost', 'Metric': 'recall_macro', 'Mean_Train': 0.6934437071428775, 'Mean_Test': 0.46091863984035364, 'Variance_Train': 2.1266742727174523e-06, 'Variance_Test': 0.00014882553499047884, 'Train-Test_Difference': 0.23252506730252387}, {'Model': 'XGBoost', 'Metric': 'f1_macro', 'Mean_Train': 0.7206959213073542, 'Mean_Test': 0.5048867328424411, 'Variance_Train': 2.1608910001337583e-06, 'Variance_Test': 0.000274272978841161, 'Train-Test_Difference': 0.21580918846491304}]\n"
     ]
    }
   ],
   "source": [
    "performance_results = evaluate_models_with_overfitting_check(X_combined, y_combined, ps, selected_features_RFE_basic, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean_Train</th>\n",
       "      <th>Mean_Test</th>\n",
       "      <th>Variance_Train</th>\n",
       "      <th>Variance_Test</th>\n",
       "      <th>Train-Test_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.564886</td>\n",
       "      <td>0.564436</td>\n",
       "      <td>7.678480e-07</td>\n",
       "      <td>2.207548e-06</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.309134</td>\n",
       "      <td>0.308626</td>\n",
       "      <td>8.193642e-08</td>\n",
       "      <td>6.239134e-07</td>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.521869</td>\n",
       "      <td>0.507157</td>\n",
       "      <td>3.274189e-06</td>\n",
       "      <td>7.775047e-05</td>\n",
       "      <td>0.014713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.293681</td>\n",
       "      <td>0.292995</td>\n",
       "      <td>2.041098e-07</td>\n",
       "      <td>1.228930e-06</td>\n",
       "      <td>0.000686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.845277</td>\n",
       "      <td>0.696979</td>\n",
       "      <td>1.107867e-07</td>\n",
       "      <td>1.082934e-06</td>\n",
       "      <td>0.148298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.775405</td>\n",
       "      <td>0.363293</td>\n",
       "      <td>3.003487e-05</td>\n",
       "      <td>3.064116e-04</td>\n",
       "      <td>0.412112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.596921</td>\n",
       "      <td>0.325319</td>\n",
       "      <td>7.665585e-05</td>\n",
       "      <td>3.474565e-05</td>\n",
       "      <td>0.271602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.655521</td>\n",
       "      <td>0.334690</td>\n",
       "      <td>6.426812e-05</td>\n",
       "      <td>7.090789e-05</td>\n",
       "      <td>0.320831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLP</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.764883</td>\n",
       "      <td>0.764262</td>\n",
       "      <td>4.956358e-06</td>\n",
       "      <td>2.358998e-06</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.400243</td>\n",
       "      <td>0.410917</td>\n",
       "      <td>7.107620e-05</td>\n",
       "      <td>1.093682e-03</td>\n",
       "      <td>-0.010674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.309692</td>\n",
       "      <td>1.660723e-04</td>\n",
       "      <td>1.557380e-04</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.306526</td>\n",
       "      <td>0.306408</td>\n",
       "      <td>2.847270e-04</td>\n",
       "      <td>2.589425e-04</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.720046</td>\n",
       "      <td>2.655486e-12</td>\n",
       "      <td>7.296541e-06</td>\n",
       "      <td>0.279950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.461525</td>\n",
       "      <td>8.953026e-11</td>\n",
       "      <td>1.277242e-04</td>\n",
       "      <td>0.538453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.476561</td>\n",
       "      <td>1.625216e-13</td>\n",
       "      <td>2.084549e-04</td>\n",
       "      <td>0.523438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.468247</td>\n",
       "      <td>2.433948e-11</td>\n",
       "      <td>1.473812e-04</td>\n",
       "      <td>0.531742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.834905</td>\n",
       "      <td>2.655486e-12</td>\n",
       "      <td>1.460938e-06</td>\n",
       "      <td>0.165091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.871816</td>\n",
       "      <td>8.953026e-11</td>\n",
       "      <td>5.639710e-05</td>\n",
       "      <td>0.128161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.548909</td>\n",
       "      <td>1.625216e-13</td>\n",
       "      <td>2.538490e-04</td>\n",
       "      <td>0.451090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.628746</td>\n",
       "      <td>2.433948e-11</td>\n",
       "      <td>3.302600e-04</td>\n",
       "      <td>0.371242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.819145</td>\n",
       "      <td>0.794443</td>\n",
       "      <td>1.222249e-07</td>\n",
       "      <td>8.284927e-07</td>\n",
       "      <td>0.024702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.865285</td>\n",
       "      <td>0.757231</td>\n",
       "      <td>2.881965e-07</td>\n",
       "      <td>1.712483e-05</td>\n",
       "      <td>0.108055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.693444</td>\n",
       "      <td>0.460919</td>\n",
       "      <td>2.126674e-06</td>\n",
       "      <td>1.488255e-04</td>\n",
       "      <td>0.232525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.720696</td>\n",
       "      <td>0.504887</td>\n",
       "      <td>2.160891e-06</td>\n",
       "      <td>2.742730e-04</td>\n",
       "      <td>0.215809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model           Metric  Mean_Train  Mean_Test  \\\n",
       "0   Logistic Regression         accuracy    0.564886   0.564436   \n",
       "1   Logistic Regression  precision_macro    0.309134   0.308626   \n",
       "2   Logistic Regression     recall_macro    0.521869   0.507157   \n",
       "3   Logistic Regression         f1_macro    0.293681   0.292995   \n",
       "4                   KNN         accuracy    0.845277   0.696979   \n",
       "5                   KNN  precision_macro    0.775405   0.363293   \n",
       "6                   KNN     recall_macro    0.596921   0.325319   \n",
       "7                   KNN         f1_macro    0.655521   0.334690   \n",
       "8                   MLP         accuracy    0.764883   0.764262   \n",
       "9                   MLP  precision_macro    0.400243   0.410917   \n",
       "10                  MLP     recall_macro    0.309917   0.309692   \n",
       "11                  MLP         f1_macro    0.306526   0.306408   \n",
       "12        Decision Tree         accuracy    0.999996   0.720046   \n",
       "13        Decision Tree  precision_macro    0.999977   0.461525   \n",
       "14        Decision Tree     recall_macro    0.999999   0.476561   \n",
       "15        Decision Tree         f1_macro    0.999988   0.468247   \n",
       "16        Random Forest         accuracy    0.999996   0.834905   \n",
       "17        Random Forest  precision_macro    0.999977   0.871816   \n",
       "18        Random Forest     recall_macro    0.999999   0.548909   \n",
       "19        Random Forest         f1_macro    0.999988   0.628746   \n",
       "20              XGBoost         accuracy    0.819145   0.794443   \n",
       "21              XGBoost  precision_macro    0.865285   0.757231   \n",
       "22              XGBoost     recall_macro    0.693444   0.460919   \n",
       "23              XGBoost         f1_macro    0.720696   0.504887   \n",
       "\n",
       "    Variance_Train  Variance_Test  Train-Test_Difference  \n",
       "0     7.678480e-07   2.207548e-06               0.000450  \n",
       "1     8.193642e-08   6.239134e-07               0.000509  \n",
       "2     3.274189e-06   7.775047e-05               0.014713  \n",
       "3     2.041098e-07   1.228930e-06               0.000686  \n",
       "4     1.107867e-07   1.082934e-06               0.148298  \n",
       "5     3.003487e-05   3.064116e-04               0.412112  \n",
       "6     7.665585e-05   3.474565e-05               0.271602  \n",
       "7     6.426812e-05   7.090789e-05               0.320831  \n",
       "8     4.956358e-06   2.358998e-06               0.000621  \n",
       "9     7.107620e-05   1.093682e-03              -0.010674  \n",
       "10    1.660723e-04   1.557380e-04               0.000225  \n",
       "11    2.847270e-04   2.589425e-04               0.000118  \n",
       "12    2.655486e-12   7.296541e-06               0.279950  \n",
       "13    8.953026e-11   1.277242e-04               0.538453  \n",
       "14    1.625216e-13   2.084549e-04               0.523438  \n",
       "15    2.433948e-11   1.473812e-04               0.531742  \n",
       "16    2.655486e-12   1.460938e-06               0.165091  \n",
       "17    8.953026e-11   5.639710e-05               0.128161  \n",
       "18    1.625216e-13   2.538490e-04               0.451090  \n",
       "19    2.433948e-11   3.302600e-04               0.371242  \n",
       "20    1.222249e-07   8.284927e-07               0.024702  \n",
       "21    2.881965e-07   1.712483e-05               0.108055  \n",
       "22    2.126674e-06   1.488255e-04               0.232525  \n",
       "23    2.160891e-06   2.742730e-04               0.215809  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_results.to_csv('performance_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFECV with preprocessing_newFeatures_advanced (All features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_adv, X_combined, y_combined = create_predifined_split(X, y, preprocessing_newFeatures_advanced, n_splits=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 49\n",
      "Feature Ranking: [ 1  1  1  1  1  1  1 13 18 17 20  4  1  1  1  1  1  1  1  1  1  3  5  1\n",
      "  1  1  1  1 24 26 28 31 30 29 27 14 21 23 22 32 34 36 38 40 42 44 43 41\n",
      " 39 37 35 33 12  6  8 25  1  1  1  1  1  1 19 15  9 11  1  1  1  7  1  1\n",
      "  1  2  1  1  1  1 10 16  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      "Selected Features: ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Age at Injury 1', 'Age at Injury 2', 'Age at Injury 3', 'Age at Injury 4', 'Age at Injury 5', 'Birth Year 0', 'Birth Year 1', 'Birth Year 2', 'Birth Year 3', 'Average Weekly Wage 0', 'Average Weekly Wage 1', 'Average Weekly Wage 2', 'IME-4 Count 0', 'IME-4 Count 1', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'Carrier Type_4A. SELF PRIVATE', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_ALBANY', 'District Name_BUFFALO', 'District Name_HAUPPAUGE', 'District Name_NYC', 'District Name_STATEWIDE', 'District Name_SYRACUSE', 'Gender_F', 'Gender_M', 'Medical Fee Region_I', 'Medical Fee Region_II', 'Medical Fee Region_III', 'Medical Fee Region_IV', 'Medical Fee Region_UK', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']\n"
     ]
    }
   ],
   "source": [
    " # Initialize RandomForest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,            # Number of trees\n",
    "    max_depth=15,                # Limit tree depth\n",
    "    min_samples_split=50,        # Minimum samples for a split\n",
    "    min_samples_leaf=20,         # Minimum samples per leaf\n",
    "    max_features='sqrt',         # Features to consider per split\n",
    "    class_weight='balanced',     # Handle class imbalance\n",
    "    bootstrap=True,              # Use bootstrapping\n",
    "    random_state=42,             # Ensure reproducibility\n",
    "    n_jobs=-1                    # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Set up RFECV with RandomForest and cross-validation\n",
    "rfecv = RFECV(estimator=rf_model, step=1, cv=ps_adv, scoring='f1_macro', n_jobs=-1) \n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_combined, y_combined)\n",
    "\n",
    "#Get the selected features\n",
    "selected_features_RFE_advanced = X_combined.columns[rfecv.support_].tolist()\n",
    "feature_ranking = rfecv.ranking_\n",
    "optimal_num_features = rfecv.n_features_\n",
    "\n",
    "print(\"Optimal number of features:\", optimal_num_features)\n",
    "print(\"Feature Ranking:\", feature_ranking)\n",
    "print(\"Selected Features:\", selected_features_RFE_advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal number of features: 49 <br>\n",
    "Selected Features: <br>['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Age at Injury 1', 'Age at Injury 2', 'Age at Injury 3', 'Age at Injury 4', 'Age at Injury 5', 'Birth Year 0', 'Birth Year 1', 'Birth Year 2', 'Birth Year 3', 'Average Weekly Wage 0', 'Average Weekly Wage 1', 'Average Weekly Wage 2', 'IME-4 Count 0', 'IME-4 Count 1', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'Carrier Type_4A. SELF PRIVATE', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_ALBANY', 'District Name_BUFFALO', 'District Name_HAUPPAUGE', 'District Name_NYC', 'District Name_STATEWIDE', 'District Name_SYRACUSE', 'Gender_F', 'Gender_M', 'Medical Fee Region_I', 'Medical Fee Region_II', 'Medical Fee Region_III', 'Medical Fee Region_IV', 'Medical Fee Region_UK', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_RFE_advanced = ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'IME-4 Count 1', 'Attorney/Representative_False', 'Attorney/Representative_True', 'COVID-19 Indicator_True', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stacking_with_predefined_split(X, y, predefined_split, base_model, meta_model):\n",
    "    \"\"\"\n",
    "    Creates and evaluates a stacking ensemble with one base model and a meta model using a predefined split.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): Feature dataset.\n",
    "    - y (pd.Series or np.array): Target variable.\n",
    "    - predefined_split (PredefinedSplit): Predefined split object for cross-validation.\n",
    "    - base_model: Base model instance (e.g., XGBoost, Random Forest).\n",
    "    - meta_model: Meta-model instance (e.g., Logistic Regression).\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Summary table with mean, variance, and train-test differences for evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Initialize storage for predictions and metrics\n",
    "    base_predictions = np.zeros((len(y),))  # For storing base model predictions\n",
    "    fold_metrics = {\n",
    "        'accuracy_train': [],\n",
    "        'accuracy_test': [],\n",
    "        'precision_macro_train': [],\n",
    "        'precision_macro_test': [],\n",
    "        'recall_macro_train': [],\n",
    "        'recall_macro_test': [],\n",
    "        'f1_macro_train': [],\n",
    "        'f1_macro_test': []\n",
    "    }\n",
    "    \n",
    "    # Split data based on predefined split\n",
    "    for train_idx, test_idx in predefined_split.split():\n",
    "        # Split into train and test\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the base model on training data\n",
    "        base_model.fit(X_train, y_train)\n",
    "        # Make predictions with the base model on training data\n",
    "        base_train_pred = base_model.predict(X_train)\n",
    "        base_test_pred = base_model.predict(X_test)\n",
    "        \n",
    "        # Store base model predictions as features for the meta model\n",
    "        base_predictions[train_idx] = base_train_pred  # Predictions on training set only\n",
    "        \n",
    "        # Train the meta-model on the stacked features\n",
    "        meta_model.fit(base_predictions[train_idx].reshape(-1, 1), y_train)\n",
    "        \n",
    "        # Meta-model predictions on training and test sets\n",
    "        meta_train_pred = meta_model.predict(base_predictions[train_idx].reshape(-1, 1))\n",
    "        meta_test_pred = meta_model.predict(base_test_pred.reshape(-1, 1))\n",
    "        \n",
    "        # Evaluate metrics on both training and test sets\n",
    "        fold_metrics['accuracy_train'].append(accuracy_score(y_train, meta_train_pred))\n",
    "        fold_metrics['accuracy_test'].append(accuracy_score(y_test, meta_test_pred))\n",
    "        fold_metrics['precision_macro_train'].append(precision_score(y_train, meta_train_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['precision_macro_test'].append(precision_score(y_test, meta_test_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['recall_macro_train'].append(recall_score(y_train, meta_train_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['recall_macro_test'].append(recall_score(y_test, meta_test_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['f1_macro_train'].append(f1_score(y_train, meta_train_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['f1_macro_test'].append(f1_score(y_test, meta_test_pred, average='macro', zero_division=0))\n",
    "    \n",
    "    # Compute mean, variance, and train-test differences\n",
    "    results = []\n",
    "    for metric_name in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
    "        train_metric = np.array(fold_metrics[f'{metric_name}_train'])\n",
    "        test_metric = np.array(fold_metrics[f'{metric_name}_test'])\n",
    "        \n",
    "        mean_train = np.mean(train_metric)\n",
    "        mean_test = np.mean(test_metric)\n",
    "        variance_train = np.var(train_metric)\n",
    "        variance_test = np.var(test_metric)\n",
    "        mean_difference = mean_train - mean_test\n",
    "        \n",
    "        results.append({\n",
    "            'Metric': metric_name,\n",
    "            'Mean_Train': mean_train,\n",
    "            'Mean_Test': mean_test,\n",
    "            'Variance_Train': variance_train,\n",
    "            'Variance_Test': variance_test,\n",
    "            'Train-Test_Difference': mean_difference\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = XGBClassifier(gamma = 0, learning_rate = 0.3, max_depth = 6, min_child_weight = 1, n_estimators = 200, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)\n",
    "meta_model = LogisticRegression(penalty='l2', C=10, solver='lbfgs', class_weight='balanced', l1_ratio=0.5, max_iter=2000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = XGBClassifier(gamma = 0, learning_rate = 0.3, max_depth = 6, min_child_weight = 1, n_estimators = 200, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)\n",
    "meta_model = LogisticRegression(penalty='l2', C=10, solver='lbfgs', class_weight='balanced', l1_ratio=0.5, max_iter=2000, n_jobs=-1),\n",
    "\n",
    "stacking_results = evaluate_stacking_with_predefined_split(X_combined, y_combined, ps, base_model, meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean_Train</th>\n",
       "      <th>Mean_Test</th>\n",
       "      <th>Variance_Train</th>\n",
       "      <th>Variance_Test</th>\n",
       "      <th>Train-Test_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.818854</td>\n",
       "      <td>0.794342</td>\n",
       "      <td>2.091752e-07</td>\n",
       "      <td>5.559157e-07</td>\n",
       "      <td>0.024512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.863878</td>\n",
       "      <td>0.756329</td>\n",
       "      <td>9.650562e-07</td>\n",
       "      <td>1.466552e-04</td>\n",
       "      <td>0.107549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.694795</td>\n",
       "      <td>0.459673</td>\n",
       "      <td>2.481437e-06</td>\n",
       "      <td>1.284234e-04</td>\n",
       "      <td>0.235122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.721205</td>\n",
       "      <td>0.502512</td>\n",
       "      <td>3.229257e-06</td>\n",
       "      <td>2.470566e-04</td>\n",
       "      <td>0.218693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric  Mean_Train  Mean_Test  Variance_Train  Variance_Test  \\\n",
       "0         accuracy    0.818854   0.794342    2.091752e-07   5.559157e-07   \n",
       "1  precision_macro    0.863878   0.756329    9.650562e-07   1.466552e-04   \n",
       "2     recall_macro    0.694795   0.459673    2.481437e-06   1.284234e-04   \n",
       "3         f1_macro    0.721205   0.502512    3.229257e-06   2.470566e-04   \n",
       "\n",
       "   Train-Test_Difference  \n",
       "0               0.024512  \n",
       "1               0.107549  \n",
       "2               0.235122  \n",
       "3               0.218693  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_stacking_multiclass(train_X, train_y, test_X, base_model, meta_model, selected_features):\n",
    "    \"\"\"\n",
    "    Fits a stacking ensemble for multiclass classification using XGBoost as the base model\n",
    "    and Logistic Regression as the meta-model.\n",
    "\n",
    "    Parameters:\n",
    "    - train_X (pd.DataFrame): Training features.\n",
    "    - train_y (pd.Series or np.array): Training labels (multiclass).\n",
    "    - test_X (pd.DataFrame): Test features.\n",
    "    - base_model: Base model instance (XGBoost).\n",
    "    - meta_model: Meta-model instance (Logistic Regression).\n",
    "    - selected_features (list): List of feature names to use for training.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Predicted labels for the test data.\n",
    "    \"\"\"\n",
    "    # Step 1: Train the base model on the training data\n",
    "    base_model.fit(train_X[selected_features], train_y)\n",
    "\n",
    "    # Step 2: Generate base model predictions for train and test sets (probabilities for all classes)\n",
    "    base_train_predictions = base_model.predict_proba(train_X[selected_features])  # Probabilities for all classes\n",
    "    base_test_predictions = base_model.predict_proba(test_X[selected_features])\n",
    "\n",
    "    # Step 3: Train the meta-model on the base model's train predictions\n",
    "    meta_model.fit(base_train_predictions, train_y)\n",
    "\n",
    "    # Step 4: Use the meta-model to predict test labels based on base model's test predictions\n",
    "    meta_test_predictions = meta_model.predict(base_test_predictions)\n",
    "\n",
    "    return meta_test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_X = preprocessing_newFeatures_advanced(X, test_data)\n",
    "le  = LabelEncoder()\n",
    "train_y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we try to optimise the performance of our chosen model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Evaluation of perfromance on different pre-processings pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_newF_dum, X_combined2, y_combined2 = create_predifined_split_with_features(X, y, preprocessing_newFeatures_dum, selected_features_RFE_advanced, n_splits=5)\n",
    "ps_adv, X_combined3, y_combined3 = create_predifined_split_with_features(X, y, preprocessing_scaling_encoding_advanced, selected_features_RFE_basic, n_splits=5)\n",
    "ps_newF_adv, X_combined4, y_combined4 = create_predifined_split_with_features(X, y, preprocessing_newFeatures_advanced, selected_features_RFE_advanced, n_splits=5)\n",
    "ps_dum, X_combined1, y_combined1 = create_predifined_split_with_features(X, y, preprocessing_scaling_encoding_dum, selected_features_RFE_basic, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_multiple_splits(splits_data, selected_features, model):\n",
    "    \"\"\"\n",
    "    Evaluates a model on multiple predefined splits and stores performance metrics, \n",
    "    predictions on train/validation, and train-validation differences.\n",
    "\n",
    "    Parameters:\n",
    "    - splits_data (dict): Dictionary where each key is the split name, and the value is a dictionary with:\n",
    "                          'predefined_split': PredefinedSplit object,\n",
    "                          'X': Feature dataset (pd.DataFrame),\n",
    "                          'y': Target variable (pd.Series or np.array).\n",
    "    - model: Machine learning model instance (e.g., XGBClassifier, RandomForestClassifier).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with mean accuracy, F1 scores, and train-validation differences for each split.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for split_name, split_info in splits_data.items():\n",
    "        print(f\"Evaluating model on split: {split_name}\")\n",
    "\n",
    "        predefined_split = split_info['predefined_split']\n",
    "        X = split_info['X']\n",
    "        y = split_info['y']\n",
    "\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_f1_scores = []\n",
    "        val_f1_scores = []\n",
    "\n",
    "        # Iterate through each fold in the predefined split\n",
    "        for train_idx, test_idx in predefined_split.split():\n",
    "            # Split data into train and validation sets\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_val = y[train_idx], y[test_idx]\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train[selected_features], y_train)\n",
    "\n",
    "            # Predictions and evaluation\n",
    "            y_train_pred = model.predict(X_train[selected_features])\n",
    "            y_val_pred = model.predict(X_val[selected_features])\n",
    "\n",
    "            # Calculate performance metrics\n",
    "            train_accuracies.append(accuracy_score(y_train, y_train_pred))\n",
    "            val_accuracies.append(accuracy_score(y_val, y_val_pred))\n",
    "            train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "            val_f1_scores.append(f1_score(y_val, y_val_pred, average='macro'))\n",
    "\n",
    "        # Compute mean accuracy and F1 score for training and validation\n",
    "        mean_train_accuracy = np.mean(train_accuracies)\n",
    "        mean_val_accuracy = np.mean(val_accuracies)\n",
    "        mean_train_f1 = np.mean(train_f1_scores)\n",
    "        mean_val_f1 = np.mean(val_f1_scores)\n",
    "\n",
    "        # Calculate train-validation differences\n",
    "        accuracy_difference = mean_train_accuracy - mean_val_accuracy\n",
    "        f1_difference = mean_train_f1 - mean_val_f1\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Split': split_name,\n",
    "            'Mean_Train_Accuracy': mean_train_accuracy,\n",
    "            'Mean_Val_Accuracy': mean_val_accuracy,\n",
    "            'Accuracy_Difference': accuracy_difference,\n",
    "            'Mean_Train_F1_Macro': mean_train_f1,\n",
    "            'Mean_Val_F1_Macro': mean_val_f1,\n",
    "            'F1_Difference': f1_difference\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame with split names as index\n",
    "    results_df = pd.DataFrame(results).set_index('Split')\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_data = {\n",
    "    'Split_dum': {\n",
    "        'predefined_split': ps_dum,\n",
    "        'X': X_combined1,\n",
    "        'y': y_combined1\n",
    "    },\n",
    "    'Split_newF_dum': {\n",
    "        'predefined_split': ps_newF_dum,\n",
    "        'X': X_combined2,\n",
    "        'y': y_combined2\n",
    "    },\n",
    "    'Split_adv': {\n",
    "        'predefined_split': ps_adv,\n",
    "        'X': X_combined3,\n",
    "        'y': y_combined3\n",
    "    },\n",
    "    'Split_newF_adv': {\n",
    "        'predefined_split': ps_newF_adv,\n",
    "        'X': X_combined4,\n",
    "        'y': y_combined4\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on split: Split_dum\n",
      "Evaluating model on split: Split_newF_dum\n",
      "Evaluating model on split: Split_adv\n",
      "Evaluating model on split: Split_newF_adv\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(gamma = 0, learning_rate = 0.3, max_depth = 6, min_child_weight = 1, n_estimators = 200, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)\n",
    "results_optimized_xgb = evaluate_model_with_multiple_splits(splits_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Train_Accuracy</th>\n",
       "      <th>Mean_Val_Accuracy</th>\n",
       "      <th>Accuracy_Difference</th>\n",
       "      <th>Mean_Train_F1_Macro</th>\n",
       "      <th>Mean_Val_F1_Macro</th>\n",
       "      <th>F1_Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Split_dum</th>\n",
       "      <td>0.861293</td>\n",
       "      <td>0.785060</td>\n",
       "      <td>0.076232</td>\n",
       "      <td>0.856758</td>\n",
       "      <td>0.505903</td>\n",
       "      <td>0.350855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_newF_dum</th>\n",
       "      <td>0.853341</td>\n",
       "      <td>0.783344</td>\n",
       "      <td>0.069996</td>\n",
       "      <td>0.848500</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_adv</th>\n",
       "      <td>0.857559</td>\n",
       "      <td>0.775956</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.853279</td>\n",
       "      <td>0.499664</td>\n",
       "      <td>0.353615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_newF_adv</th>\n",
       "      <td>0.849146</td>\n",
       "      <td>0.774186</td>\n",
       "      <td>0.074960</td>\n",
       "      <td>0.844596</td>\n",
       "      <td>0.480692</td>\n",
       "      <td>0.363904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Mean_Train_Accuracy  Mean_Val_Accuracy  Accuracy_Difference  \\\n",
       "Split                                                                         \n",
       "Split_dum                  0.861293           0.785060             0.076232   \n",
       "Split_newF_dum             0.853341           0.783344             0.069996   \n",
       "Split_adv                  0.857559           0.775956             0.081603   \n",
       "Split_newF_adv             0.849146           0.774186             0.074960   \n",
       "\n",
       "                Mean_Train_F1_Macro  Mean_Val_F1_Macro  F1_Difference  \n",
       "Split                                                                  \n",
       "Split_dum                  0.856758           0.505903       0.350855  \n",
       "Split_newF_dum             0.848500           0.476951       0.371550  \n",
       "Split_adv                  0.853279           0.499664       0.353615  \n",
       "Split_newF_adv             0.844596           0.480692       0.363904  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_optimized_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Optimized Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_optimized, X_combined5, y_combined5 = create_predifined_split(X, y, preprocessing_optimized, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_data = {\n",
    "    'XGBoost (Optimized)': {\n",
    "        'predefined_split': ps_optimized,\n",
    "        'X': X_combined5,\n",
    "        'y': y_combined5\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on split: Split_newD_dum\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(gamma = 0, learning_rate = 0.05, max_depth = 6, min_child_weight = 1, n_estimators = 500, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)\n",
    "results_optimized_xgb = evaluate_model_with_multiple_splits(splits_data, X_combined5.columns, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Train_Accuracy</th>\n",
       "      <th>Mean_Val_Accuracy</th>\n",
       "      <th>Accuracy_Difference</th>\n",
       "      <th>Mean_Train_F1_Macro</th>\n",
       "      <th>Mean_Val_F1_Macro</th>\n",
       "      <th>F1_Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Split_newD_dum</th>\n",
       "      <td>0.804279</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.007742</td>\n",
       "      <td>0.614881</td>\n",
       "      <td>0.505971</td>\n",
       "      <td>0.10891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Mean_Train_Accuracy  Mean_Val_Accuracy  Accuracy_Difference  \\\n",
       "Split                                                                         \n",
       "Split_newD_dum             0.804279           0.796537             0.007742   \n",
       "\n",
       "                Mean_Train_F1_Macro  Mean_Val_F1_Macro  F1_Difference  \n",
       "Split                                                                  \n",
       "Split_newD_dum             0.614881           0.505971        0.10891  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_optimized_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!Warning heavy RAM usage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(X, y, model, param_grid, ps, n_splits=5):\n",
    "    \"\"\"\n",
    "    Finds the best hyperparameters for a given model using GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Creates a PredefinedSplit object\n",
    "    - Creates a GridSearchCV object\n",
    "    - Fits the GridSearchCV object\n",
    "    - Returns the best hyperparameters and the best score\n",
    "    \"\"\"\n",
    "\n",
    "    scoring = make_scorer(f1_score, average='macro')\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=ps,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        return_train_score=True,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X, y)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best F1-macro Score:\", grid_search.best_score_)\n",
    "\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_grid, X_grid, y_grid = create_predifined_split(X, y, preprocessing_optimized, ps_optimized, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'scale_pos_weight': [25, 75],\n",
    "    'max_delta_step': [5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(gamma = 0, min_child_weight = 1, max_depth=6, n_estimators = 100, reg_alpha = 0, reg_lambda = 1, random_state=42, objective='multi:softprob', n_jobs=-1)\n",
    "xgb_best_params, xgb_best_score = get_best_parameters(X_grid, y_grid, model, param_grid, ps_grid, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Optimized Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        scale_pos_weight = 100,  \n",
    "        max_delta_step = 10,     \n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='multi:softprob',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on split: XGBoost (Optimized)\n"
     ]
    }
   ],
   "source": [
    "results_optimized_xgb = evaluate_model_with_multiple_splits(splits_data, X_combined5.columns, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Train_Accuracy</th>\n",
       "      <th>Mean_Val_Accuracy</th>\n",
       "      <th>Accuracy_Difference</th>\n",
       "      <th>Mean_Train_F1_Macro</th>\n",
       "      <th>Mean_Val_F1_Macro</th>\n",
       "      <th>F1_Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>XGBoost (Optimized)</th>\n",
       "      <td>0.805867</td>\n",
       "      <td>0.797439</td>\n",
       "      <td>0.008427</td>\n",
       "      <td>0.636029</td>\n",
       "      <td>0.51433</td>\n",
       "      <td>0.121699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Mean_Train_Accuracy  Mean_Val_Accuracy  \\\n",
       "Split                                                         \n",
       "XGBoost (Optimized)             0.805867           0.797439   \n",
       "\n",
       "                     Accuracy_Difference  Mean_Train_F1_Macro  \\\n",
       "Split                                                           \n",
       "XGBoost (Optimized)             0.008427             0.636029   \n",
       "\n",
       "                     Mean_Val_F1_Macro  F1_Difference  \n",
       "Split                                                  \n",
       "XGBoost (Optimized)            0.51433       0.121699  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_optimized_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final Model: <br>\n",
    "XGBClassifier(n_estimators=500,<br>\n",
    "                scale_pos_weight = 100, \n",
    "                max_delta_step = 10,   \n",
    "                learning_rate=0.05,<br>\n",
    "                max_depth=6,<br>\n",
    "                min_child_weight=1,<br>\n",
    "                gamma=0,<br>\n",
    "                subsample=0.8,<br>\n",
    "                colsample_bytree=0.8,<br>\n",
    "                objective='multi:softprob',<br>\n",
    "                random_state=42,<br>\n",
    "                n_jobs=-1<br>\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_preprocessed, test_preprocessed = preprocessing_optimized(X, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le = le.fit(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export of pickle files for Open Ended Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "        pickle.dump(le, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_frequencyEncoding = pd.DataFrame({\n",
    "    'ZipCode': X['Zip Code'],\n",
    "    'ZipCode_Frequency': train_preprocessed['Zip Code'],\n",
    "    'CarrierName': X['Carrier Name'],\n",
    "    'CarrierName_Frequency': train_preprocessed['Carrier Name']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_frequencyEncoding.to_csv('frequency_encoding.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ZipCode</th>\n",
       "      <th>ZipCode_Frequency</th>\n",
       "      <th>CarrierName</th>\n",
       "      <th>CarrierName_Frequency</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Claim Identifier</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5393875</th>\n",
       "      <td>13662</td>\n",
       "      <td>0.000941</td>\n",
       "      <td>NEW HAMPSHIRE INSURANCE CO</td>\n",
       "      <td>0.022187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393091</th>\n",
       "      <td>14569</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>ZURICH AMERICAN INSURANCE CO</td>\n",
       "      <td>0.004986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393889</th>\n",
       "      <td>12589</td>\n",
       "      <td>0.000899</td>\n",
       "      <td>INDEMNITY INSURANCE CO OF</td>\n",
       "      <td>0.015898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393887</th>\n",
       "      <td>12603</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>STATE INSURANCE FUND</td>\n",
       "      <td>0.193622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5393863</th>\n",
       "      <td>11772</td>\n",
       "      <td>0.003228</td>\n",
       "      <td>INDEMNITY INS. OF N AMERICA</td>\n",
       "      <td>0.025027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165265</th>\n",
       "      <td>10467</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>STATE INSURANCE FUND</td>\n",
       "      <td>0.193622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165285</th>\n",
       "      <td>11590</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>WESCO INSURANCE CO</td>\n",
       "      <td>0.004061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165506</th>\n",
       "      <td>14227</td>\n",
       "      <td>0.001530</td>\n",
       "      <td>SECURITY NATIONAL INSURANCE CO</td>\n",
       "      <td>0.005139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165339</th>\n",
       "      <td>10029</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>TECHNOLOGY INSURANCE CO. INC.</td>\n",
       "      <td>0.004380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6165075</th>\n",
       "      <td>12779</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>TECHNOLOGY INSURANCE CO. INC.</td>\n",
       "      <td>0.004380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>574026 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 ZipCode  ZipCode_Frequency                     CarrierName  \\\n",
       "Claim Identifier                                                              \n",
       "5393875            13662           0.000941      NEW HAMPSHIRE INSURANCE CO   \n",
       "5393091            14569           0.000354    ZURICH AMERICAN INSURANCE CO   \n",
       "5393889            12589           0.000899       INDEMNITY INSURANCE CO OF   \n",
       "5393887            12603           0.003075            STATE INSURANCE FUND   \n",
       "5393863            11772           0.003228     INDEMNITY INS. OF N AMERICA   \n",
       "...                  ...                ...                             ...   \n",
       "6165265            10467           0.004127            STATE INSURANCE FUND   \n",
       "6165285            11590           0.002604              WESCO INSURANCE CO   \n",
       "6165506            14227           0.001530  SECURITY NATIONAL INSURANCE CO   \n",
       "6165339            10029           0.002648   TECHNOLOGY INSURANCE CO. INC.   \n",
       "6165075            12779           0.000155   TECHNOLOGY INSURANCE CO. INC.   \n",
       "\n",
       "                  CarrierName_Frequency  \n",
       "Claim Identifier                         \n",
       "5393875                        0.022187  \n",
       "5393091                        0.004986  \n",
       "5393889                        0.015898  \n",
       "5393887                        0.193622  \n",
       "5393863                        0.025027  \n",
       "...                                 ...  \n",
       "6165265                        0.193622  \n",
       "6165285                        0.004061  \n",
       "6165506                        0.005139  \n",
       "6165339                        0.004380  \n",
       "6165075                        0.004380  \n",
       "\n",
       "[574026 rows x 4 columns]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_frequencyEncoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = le.transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(\n",
    "        n_estimators=500,\n",
    "        scale_pos_weight = 100,  \n",
    "        max_delta_step = 10,     \n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_child_weight=1,\n",
    "        gamma=0,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        objective='multi:softprob',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "model.fit(train_preprocessed, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_optimized_xgb = model.predict(test_preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim Injury Type\n",
       "2. NON-COMP          77.471744\n",
       "3. MED ONLY          10.178233\n",
       "4. TEMPORARY         10.021264\n",
       "1. CANCELLED          1.573555\n",
       "5. PPD SCH LOSS       0.746182\n",
       "8. DEATH              0.009021\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions_optimized_xgb = le.inverse_transform(predictions_optimized_xgb)\n",
    "predictions_optimized_xgb = pd.DataFrame(predictions_optimized_xgb, columns=['Claim Injury Type'], index=test_data.index)\n",
    "predictions_optimized_xgb.to_csv('Group36_Version52.csv')\n",
    "predictions_optimized_xgb.value_counts(normalize=True) * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
