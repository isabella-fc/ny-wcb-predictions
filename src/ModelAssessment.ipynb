{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\timst\\anaconda3\\envs\\dm2425_20241209\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\timst\\anaconda3\\envs\\dm2425_20241209\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\timst\\anaconda3\\envs\\dm2425_20241209\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\timst\\anaconda3\\envs\\dm2425_20241209\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\timst\\anaconda3\\envs\\dm2425_20241209\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\timst\\anaconda3\\envs\\dm2425_20241209\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import (\n",
    "    GridSearchCV, PredefinedSplit, KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    ")\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report, make_scorer, precision_score, recall_score\n",
    ")\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from Preprocessing_functions import *\n",
    "\n",
    "import importlib\n",
    "imported_module = importlib.import_module(\"Preprocessing_functions\")\n",
    "importlib.reload(imported_module)\n",
    "\n",
    "# pandas max columns display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\timst\\AppData\\Local\\Temp\\ipykernel_28180\\3470921380.py:1: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n",
    "test_data = pd.read_csv('test_data.csv', index_col='Claim Identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[~(train_data.drop(columns=['Assembly Date']).isna().all(axis=1) & train_data['Assembly Date'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['Claim Injury Type', 'WCB Decision', 'Agreement Reached','OIICS Nature of Injury Description'])\n",
    "y = train_data['Claim Injury Type']\n",
    "\n",
    "test_data = test_data.drop(columns=['OIICS Nature of Injury Description'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predifined_split_with_features(X, y, preprocess_steps,selected_features, n_splits = 5):\n",
    "    \"\"\"\n",
    "    Creates a PredefinedSplit object to be used in cross-validation, more specifically in GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Defines the number of splits\n",
    "    - Splits the data into training and validation sets\n",
    "    - Applies the preprocessing steps to the training and validation sets\n",
    "    - Returns the PredefinedSplit object and the preprocessed data\n",
    "    \"\"\"\n",
    "\n",
    "    X_combined_list = []\n",
    "    y_combined_list = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    test_data = np.zeros(len(X), dtype=int) - 1\n",
    "\n",
    "    for fold_idx, (_, test_idx) in enumerate(kf.split(X, y)):\n",
    "        test_data[test_idx] = fold_idx\n",
    "\n",
    "    ps = PredefinedSplit(test_fold=test_data)\n",
    "\n",
    "    for train_index, test_index in ps.split():\n",
    "\n",
    "        # Get fold\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Preprocess and encode data    \n",
    "        X_train, X_val = preprocess_steps(X_train, X_val)\n",
    "        y_train, y_val, le = encoding_label(y_train, y_val)\n",
    "\n",
    "        X_combined_list.append(X_train[selected_features])\n",
    "        y_combined_list.append(y_train)\n",
    "\n",
    "    X_combined = pd.concat(X_combined_list, axis=0)\n",
    "    y_combined = np.concatenate(y_combined_list, axis=0)\n",
    "\n",
    "    return ps, X_combined, y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predifined_split(X, y, preprocess_steps, n_splits = 5):\n",
    "    \"\"\"\n",
    "    Creates a PredefinedSplit object to be used in cross-validation, more specifically in GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Defines the number of splits\n",
    "    - Splits the data into training and validation sets\n",
    "    - Applies the preprocessing steps to the training and validation sets\n",
    "    - Returns the PredefinedSplit object and the preprocessed data\n",
    "    \"\"\"\n",
    "\n",
    "    X_combined_list = []\n",
    "    y_combined_list = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    test_data = np.zeros(len(X), dtype=int) - 1\n",
    "\n",
    "    for fold_idx, (_, test_idx) in enumerate(kf.split(X, y)):\n",
    "        test_data[test_idx] = fold_idx\n",
    "\n",
    "    ps = PredefinedSplit(test_fold=test_data)\n",
    "\n",
    "    for train_index, test_index in ps.split():\n",
    "\n",
    "        # Get fold\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Preprocess and encode data    \n",
    "        X_train, X_val = preprocess_steps(X_train, X_val)\n",
    "        y_train, y_val, le = encoding_label(y_train, y_val)\n",
    "\n",
    "        X_combined_list.append(X_train)\n",
    "        y_combined_list.append(y_train)\n",
    "\n",
    "    X_combined = pd.concat(X_combined_list, axis=0)\n",
    "    y_combined = np.concatenate(y_combined_list, axis=0)\n",
    "\n",
    "    return ps, X_combined, y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_chi2_across_folds_with_predefined_split(X, y, ps):\n",
    "    \"\"\"\n",
    "    Computes the average Chi-Squared score and p-value across folds using a PredefinedSplit.\n",
    "    \"\"\"\n",
    "    feature_scores = []\n",
    "\n",
    "    for train_idx, test_idx in ps.split():\n",
    "\n",
    "        X_train, y_train = X.iloc[train_idx], y[train_idx]\n",
    "        \n",
    "        chi2_scores, p_values = chi2(X_train, y_train)\n",
    "        \n",
    "        feature_scores.append((chi2_scores, p_values))\n",
    "\n",
    "    chi2_scores_all = np.array([scores[0] for scores in feature_scores])\n",
    "    p_values_all = np.array([scores[1] for scores in feature_scores])\n",
    "    \n",
    "    avg_chi2_scores = np.mean(chi2_scores_all, axis=0)\n",
    "    avg_p_values = np.mean(p_values_all, axis=0)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Average_Chi2_Score': avg_chi2_scores,\n",
    "        'Average_P_Value': avg_p_values\n",
    "    }).sort_values(by='Average_Chi2_Score', ascending=False)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_anova_across_folds_with_predefined_split(X, y, ps):\n",
    "    \"\"\"\n",
    "    Computes the average ANOVA F-test score and p-value across folds using a PredefinedSplit.\n",
    "    \"\"\"\n",
    "    feature_scores = []\n",
    "    \n",
    "    for train_idx, test_idx in ps.split():\n",
    "        X_train, y_train = X.iloc[train_idx], y[train_idx]\n",
    "        \n",
    "        f_scores, p_values = f_classif(X_train, y_train)\n",
    "        \n",
    "        feature_scores.append((f_scores, p_values))\n",
    "\n",
    "    f_scores_all = np.array([scores[0] for scores in feature_scores])\n",
    "    p_values_all = np.array([scores[1] for scores in feature_scores])\n",
    "    \n",
    "    avg_f_scores = np.mean(f_scores_all, axis=0)\n",
    "    avg_p_values = np.mean(p_values_all, axis=0)\n",
    "    \n",
    "    results = pd.DataFrame({\n",
    "        'Feature': X.columns,\n",
    "        'Average_F_Score': avg_f_scores,\n",
    "        'Average_P_Value': avg_p_values\n",
    "    }).sort_values(by='Average_F_Score', ascending=False)\n",
    "    \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List creation for preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_COLUMNS = ['Industry Code', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']\n",
    "\n",
    "DESCRIPTION_COLUMNS = ['WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description','Industry Code Description']\n",
    "\n",
    "BOOLEAN_COLUMNS = ['Alternative Dispute Resolution', 'Attorney/Representative','COVID-19 Indicator']\n",
    "\n",
    "date_order = ['Accident Date', 'C-2 Date','C-3 Date','Assembly Date', 'First Hearing Date']\n",
    "\n",
    "numerical_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'C-2 Date', \n",
    "    'C-3 Date', \n",
    "    'First Hearing Date', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "outliers_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year',\n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "categorical_features = ['Alternative Dispute Resolution',\n",
    " 'Attorney/Representative',\n",
    " 'Carrier Name',\n",
    " 'Carrier Type',\n",
    " 'County of Injury',\n",
    " 'COVID-19 Indicator',\n",
    " 'District Name',\n",
    " 'Gender',\n",
    " 'Industry Code',\n",
    " 'Medical Fee Region',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'Zip Code']\n",
    "\n",
    "\n",
    "columns_to_scale = ['Accident Date',\n",
    "                'Assembly Date',\n",
    "                'Average Weekly Wage',\n",
    "                'Age at Injury',\n",
    "                'Birth Year', \n",
    "                'Number of Dependents',\n",
    "                'IME-4 Count']\n",
    "\n",
    "date_columns = ['Accident Date', 'Assembly Date']\n",
    "\n",
    "outliers_iqr_specific = ['Age at Injury', 'Birth Year']\n",
    "\n",
    "columns_to_drop = ['C-2 Date', 'C-3 Date', 'First Hearing Date']\n",
    "\n",
    "scaling_columns = ['Average Weekly Wage', 'Age at Injury', 'Birth Year', 'Number of Dependents', 'IME-4 Count', 'Days Between Accident Date and Assembly Date']\n",
    "\n",
    "new_date_features = ['Accident Date_Year', 'Accident Date_Month', 'Accident Date_Day', 'Accident Date_DayOfWeek',\n",
    "                'Assembly Date_Year', 'Assembly Date_Month', 'Assembly Date_Day', 'Assembly Date_DayOfWeek',\n",
    "                'C-2 Date_Year', 'C-2 Date_Month', 'C-2 Date_Day', 'C-2 Date_DayOfWeek',\n",
    "                'C-3 Date_Year', 'C-3 Date_Month', 'C-3 Date_Day', 'C-3 Date_DayOfWeek',\n",
    "                'First Hearing Date_Year', 'First Hearing Date_Month', 'First Hearing Date_Day', 'First Hearing Date_DayOfWeek']\n",
    "\n",
    "low_cardinality_cols = [col for col in categorical_features if X[col].nunique() < 10]\n",
    "high_cardinality_cols = [col for col in categorical_features if X[col].nunique() > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "binning_columns = ['Age at Injury', 'Age at Injury', 'Birth Year', 'Average Weekly Wage', 'IME-4 Count']\n",
    "date_columns = ['Accident Date', 'Assembly Date']\n",
    "\n",
    "def create_groupingFeatures(X_train, X_val):\n",
    "\n",
    "    X_train, X_val= newFeature_binnedGroups(X_train, X_val, binning_columns, 6)\n",
    "\n",
    "    X_train, X_val = newFeature_month(X_train, X_val, date_columns)\n",
    "\n",
    "\n",
    "\n",
    "    X_train, X_val = newFeature_daysBetween(X_train, X_val, firstDate='Accident Date', secondDate='Assembly Date')\n",
    "    \n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocessing_scaling_encoding_dum(X_train, X_val):\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val,categorical_features)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, columns_to_scale)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocessing_newFeatures_dum(X_train, X_val):\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val,categorical_features)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = convert_to_datetime(X_train, X_val, date_columns)\n",
    "    X_train, X_val= create_groupingFeatures(X_train, X_val)\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, scaling_columns)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, date_columns)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocessing_scaling_encoding_advanced(X_train, X_val):\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val,categorical_features)\n",
    "    \n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    # Knowledge-based imputation of features\n",
    "    X_train, X_val = fill_missing_codes_description_based(X_train, X_val)\n",
    "    X_train, X_val = fillna_zip_code(X_train, X_val)\n",
    "    X_train, X_val = fillnan_accident_date(X_train, X_val)\n",
    "    X_train, X_val = fillnan_birth_year(X_train, X_val)\n",
    "    X_train, X_val = impute_weekly_wage_with_zipIndustryCode(X_train, X_val)\n",
    "    X_train, X_val = fillnan_IME4_count(X_train, X_val)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "\n",
    "    # Impute still missing values\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, columns_to_scale)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_newFeatures_advanced(X_train, X_val):\n",
    "\n",
    "    # Type conversion\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val, categorical_features)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "\n",
    "    \n",
    "\n",
    "    # Knowledge-based imputation of features\n",
    "    X_train, X_val = fill_missing_codes_description_based(X_train, X_val)\n",
    "    X_train, X_val = fillna_zip_code(X_train, X_val)\n",
    "    X_train, X_val = fillnan_accident_date(X_train, X_val)\n",
    "    X_train, X_val = fillnan_birth_year(X_train, X_val)\n",
    "    X_train, X_val = impute_weekly_wage_with_zipIndustryCode(X_train, X_val)\n",
    "    X_train, X_val = fillnan_IME4_count(X_train, X_val)\n",
    "\n",
    "    # Impute still missing values\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "\n",
    "    \n",
    "\n",
    "    # Feature creation\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = newFeature_hasIME4(X_train, X_val)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = convert_to_datetime(X_train, X_val, date_columns)\n",
    "\n",
    "    # Grouping features\n",
    "    X_train, X_val= create_groupingFeatures(X_train, X_val)\n",
    "\n",
    "    # Treating outliers\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "\n",
    "    # Scaling\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, scaling_columns)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, date_columns)\n",
    "\n",
    "    low_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() < 10]\n",
    "    high_cardinality_cols = [col for col in categorical_features if X_train[col].nunique() > 10]\n",
    "\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_newDate_dum(X_train, X_val):\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val, categorical_features)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = convert_to_datetime(X_train, X_val, date_columns)\n",
    "    X_train, X_val= create_groupingFeatures(X_train, X_val)\n",
    "    X_train, X_val = log_transform(X_train, X_val)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[0], 14)\n",
    "    X_train, X_val = outliers_specific2(X_train, X_val, outliers_iqr_specific[1], 1934)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, scaling_columns)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, date_columns)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefined Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps, X_combined, y_combined = create_predifined_split(X, y, preprocessing_scaling_encoding_dum, n_splits=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chi square and Anova"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We decided to take out the colmns that were frequency encoded for this part of the analysis and really on other type of feature selection for those colmns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi square "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for categorigal features\n",
    "chi_features = [\n",
    "    'Has C-3 Date',\n",
    "    'Has C-2 Date',\n",
    "    'Has First Hearing Date',\n",
    "    'Alternative Dispute Resolution_False',\n",
    "    'Alternative Dispute Resolution_True',\n",
    "    'Alternative Dispute Resolution_nan',\n",
    "    'Attorney/Representative_False',\n",
    "    'Attorney/Representative_True',\n",
    "    'Carrier Type_1A. PRIVATE',\n",
    "    'Carrier Type_2A. SIF',\n",
    "    'Carrier Type_3A. SELF PUBLIC',\n",
    "    'Carrier Type_4A. SELF PRIVATE',\n",
    "    'Carrier Type_5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)',\n",
    "    'Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS',\n",
    "    'Carrier Type_5D. SPECIAL FUND - UNKNOWN',\n",
    "    'Carrier Type_UNKNOWN',\n",
    "    'COVID-19 Indicator_False',\n",
    "    'COVID-19 Indicator_True',\n",
    "    'District Name_NYC',\n",
    "    'District Name_BUFFALO',\n",
    "    'District Name_ALBANY',\n",
    "    'District Name_HAUPPAUGE',\n",
    "    'District Name_STATEWIDE',\n",
    "    'District Name_SYRACUSE',\n",
    "    'District Name_BINGHAMTON',\n",
    "    'District Name_ROCHESTER',\n",
    "    'Gender_F',\n",
    "    'Gender_M',\n",
    "    'Gender_U',\n",
    "    'Gender_X',\n",
    "    'Medical Fee Region_I',\n",
    "    'Medical Fee Region_II',\n",
    "    'Medical Fee Region_III',\n",
    "    'Medical Fee Region_IV',\n",
    "    'Medical Fee Region_UK',\n",
    "]\n",
    "chi2_results = average_chi2_across_folds_with_predefined_split(X_combined[chi_features], y_combined, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Average_Chi2_Score</th>\n",
       "      <th>Average_P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Attorney/Representative_True</td>\n",
       "      <td>1.184465e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Attorney/Representative_False</td>\n",
       "      <td>5.595382e+04</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Carrier Type_3A. SELF PUBLIC</td>\n",
       "      <td>7.177575e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Carrier Type_2A. SIF</td>\n",
       "      <td>5.212932e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>COVID-19 Indicator_True</td>\n",
       "      <td>4.274148e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Carrier Type_1A. PRIVATE</td>\n",
       "      <td>2.726281e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Gender_F</td>\n",
       "      <td>2.374563e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alternative Dispute Resolution_True</td>\n",
       "      <td>2.003355e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Gender_M</td>\n",
       "      <td>1.813223e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Carrier Type_UNKNOWN</td>\n",
       "      <td>1.451044e+03</td>\n",
       "      <td>3.452917e-297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>District Name_HAUPPAUGE</td>\n",
       "      <td>1.079501e+03</td>\n",
       "      <td>5.445779e-220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Medical Fee Region_I</td>\n",
       "      <td>9.996782e+02</td>\n",
       "      <td>2.013900e-208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Carrier Type_4A. SELF PRIVATE</td>\n",
       "      <td>9.873123e+02</td>\n",
       "      <td>4.118888e-206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>District Name_STATEWIDE</td>\n",
       "      <td>9.559498e+02</td>\n",
       "      <td>2.098072e-190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>District Name_NYC</td>\n",
       "      <td>9.069483e+02</td>\n",
       "      <td>1.782968e-188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Medical Fee Region_IV</td>\n",
       "      <td>9.054492e+02</td>\n",
       "      <td>1.736332e-187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>District Name_BINGHAMTON</td>\n",
       "      <td>8.861578e+02</td>\n",
       "      <td>9.785918e-184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>District Name_ROCHESTER</td>\n",
       "      <td>8.435294e+02</td>\n",
       "      <td>1.450554e-171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>District Name_ALBANY</td>\n",
       "      <td>5.610084e+02</td>\n",
       "      <td>3.621346e-111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Medical Fee Region_UK</td>\n",
       "      <td>5.444010e+02</td>\n",
       "      <td>2.073096e-112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Medical Fee Region_II</td>\n",
       "      <td>4.599900e+02</td>\n",
       "      <td>6.905675e-94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Gender_U</td>\n",
       "      <td>4.421933e+02</td>\n",
       "      <td>1.131455e-89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>District Name_SYRACUSE</td>\n",
       "      <td>2.528049e+02</td>\n",
       "      <td>1.106166e-47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>COVID-19 Indicator_False</td>\n",
       "      <td>2.337985e+02</td>\n",
       "      <td>1.105885e-45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>District Name_BUFFALO</td>\n",
       "      <td>1.899368e+02</td>\n",
       "      <td>2.156702e-35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Carrier Type_5D. SPECIAL FUND - UNKNOWN</td>\n",
       "      <td>1.410547e+02</td>\n",
       "      <td>2.025750e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Carrier Type_5A. SPECIAL FUND - CONS. COMM. (S...</td>\n",
       "      <td>6.952501e+01</td>\n",
       "      <td>1.373846e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Carrier Type_5C. SPECIAL FUND - POI CARRIER WC...</td>\n",
       "      <td>6.662003e+01</td>\n",
       "      <td>3.289411e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Medical Fee Region_III</td>\n",
       "      <td>6.440377e+01</td>\n",
       "      <td>4.639156e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Gender_X</td>\n",
       "      <td>4.748883e+01</td>\n",
       "      <td>1.664102e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alternative Dispute Resolution_False</td>\n",
       "      <td>9.310322e+00</td>\n",
       "      <td>2.313433e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alternative Dispute Resolution_nan</td>\n",
       "      <td>4.706254e+00</td>\n",
       "      <td>6.919186e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Has C-2 Date</td>\n",
       "      <td>3.324562e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Has First Hearing Date</td>\n",
       "      <td>3.324562e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Has C-3 Date</td>\n",
       "      <td>3.324562e-18</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Feature  Average_Chi2_Score  \\\n",
       "7                        Attorney/Representative_True        1.184465e+05   \n",
       "6                       Attorney/Representative_False        5.595382e+04   \n",
       "10                       Carrier Type_3A. SELF PUBLIC        7.177575e+03   \n",
       "9                                Carrier Type_2A. SIF        5.212932e+03   \n",
       "17                            COVID-19 Indicator_True        4.274148e+03   \n",
       "8                            Carrier Type_1A. PRIVATE        2.726281e+03   \n",
       "26                                           Gender_F        2.374563e+03   \n",
       "4                 Alternative Dispute Resolution_True        2.003355e+03   \n",
       "27                                           Gender_M        1.813223e+03   \n",
       "15                               Carrier Type_UNKNOWN        1.451044e+03   \n",
       "21                            District Name_HAUPPAUGE        1.079501e+03   \n",
       "30                               Medical Fee Region_I        9.996782e+02   \n",
       "11                      Carrier Type_4A. SELF PRIVATE        9.873123e+02   \n",
       "22                            District Name_STATEWIDE        9.559498e+02   \n",
       "18                                  District Name_NYC        9.069483e+02   \n",
       "33                              Medical Fee Region_IV        9.054492e+02   \n",
       "24                           District Name_BINGHAMTON        8.861578e+02   \n",
       "25                            District Name_ROCHESTER        8.435294e+02   \n",
       "20                               District Name_ALBANY        5.610084e+02   \n",
       "34                              Medical Fee Region_UK        5.444010e+02   \n",
       "31                              Medical Fee Region_II        4.599900e+02   \n",
       "28                                           Gender_U        4.421933e+02   \n",
       "23                             District Name_SYRACUSE        2.528049e+02   \n",
       "16                           COVID-19 Indicator_False        2.337985e+02   \n",
       "19                              District Name_BUFFALO        1.899368e+02   \n",
       "14            Carrier Type_5D. SPECIAL FUND - UNKNOWN        1.410547e+02   \n",
       "12  Carrier Type_5A. SPECIAL FUND - CONS. COMM. (S...        6.952501e+01   \n",
       "13  Carrier Type_5C. SPECIAL FUND - POI CARRIER WC...        6.662003e+01   \n",
       "32                             Medical Fee Region_III        6.440377e+01   \n",
       "29                                           Gender_X        4.748883e+01   \n",
       "3                Alternative Dispute Resolution_False        9.310322e+00   \n",
       "5                  Alternative Dispute Resolution_nan        4.706254e+00   \n",
       "1                                        Has C-2 Date        3.324562e-18   \n",
       "2                              Has First Hearing Date        3.324562e-18   \n",
       "0                                        Has C-3 Date        3.324562e-18   \n",
       "\n",
       "    Average_P_Value  \n",
       "7      0.000000e+00  \n",
       "6      0.000000e+00  \n",
       "10     0.000000e+00  \n",
       "9      0.000000e+00  \n",
       "17     0.000000e+00  \n",
       "8      0.000000e+00  \n",
       "26     0.000000e+00  \n",
       "4      0.000000e+00  \n",
       "27     0.000000e+00  \n",
       "15    3.452917e-297  \n",
       "21    5.445779e-220  \n",
       "30    2.013900e-208  \n",
       "11    4.118888e-206  \n",
       "22    2.098072e-190  \n",
       "18    1.782968e-188  \n",
       "33    1.736332e-187  \n",
       "24    9.785918e-184  \n",
       "25    1.450554e-171  \n",
       "20    3.621346e-111  \n",
       "34    2.073096e-112  \n",
       "31     6.905675e-94  \n",
       "28     1.131455e-89  \n",
       "23     1.106166e-47  \n",
       "16     1.105885e-45  \n",
       "19     2.156702e-35  \n",
       "14     2.025750e-19  \n",
       "12     1.373846e-04  \n",
       "13     3.289411e-08  \n",
       "32     4.639156e-09  \n",
       "29     1.664102e-06  \n",
       "3      2.313433e-01  \n",
       "5      6.919186e-01  \n",
       "1      1.000000e+00  \n",
       "2      1.000000e+00  \n",
       "0      1.000000e+00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature ID | Feature Name                                     | Average F-Score     | Average P-Value     |\n",
    "|------------|--------------------------------------------------|---------------------|---------------------|\n",
    "| 7          | Attorney/Representative_True                    | 1.184465e+05        | 0.000000e+00        |\n",
    "| 6          | Attorney/Representative_False                   | 5.595382e+04        | 0.000000e+00        |\n",
    "| 10         | Carrier Type_3A. SELF PUBLIC                    | 7.177575e+03        | 0.000000e+00        |\n",
    "| 9          | Carrier Type_2A. SIF                            | 5.212932e+03        | 0.000000e+00        |\n",
    "| 17         | COVID-19 Indicator_True                         | 4.274148e+03        | 0.000000e+00        |\n",
    "| 8          | Carrier Type_1A. PRIVATE                        | 2.726281e+03        | 0.000000e+00        |\n",
    "| 26         | Gender_F                                        | 2.374563e+03        | 0.000000e+00        |\n",
    "| 4          | Alternative Dispute Resolution_True             | 2.003355e+03        | 0.000000e+00        |\n",
    "| 27         | Gender_M                                        | 1.813223e+03        | 0.000000e+00        |\n",
    "| 15         | Carrier Type_UNKNOWN                            | 1.451044e+03        | 3.452917e-297       |\n",
    "| 21         | District Name_HAUPPAUGE                         | 1.079501e+03        | 5.445779e-220       |\n",
    "| 30         | Medical Fee Region_I                            | 9.996782e+02        | 2.013900e-208       |\n",
    "| 11         | Carrier Type_4A. SELF PRIVATE                   | 9.873123e+02        | 4.118888e-206       |\n",
    "| 22         | District Name_STATEWIDE                         | 9.559498e+02        | 2.098072e-190       |\n",
    "| 18         | District Name_NYC                               | 9.069483e+02        | 1.782968e-188       |\n",
    "| 33         | Medical Fee Region_IV                           | 9.054492e+02        | 1.736332e-187       |\n",
    "| 24         | District Name_BINGHAMTON                        | 8.861578e+02        | 9.785918e-184       |\n",
    "| 25         | District Name_ROCHESTER                         | 8.435294e+02        | 1.450554e-171       |\n",
    "| 20         | District Name_ALBANY                            | 5.610084e+02        | 3.621346e-111       |\n",
    "| 34         | Medical Fee Region_UK                           | 5.444010e+02        | 2.073096e-112       |\n",
    "| 31         | Medical Fee Region_II                           | 4.599900e+02        | 6.905675e-94        |\n",
    "| 28         | Gender_U                                        | 4.421933e+02        | 1.131455e-89        |\n",
    "| 23         | District Name_SYRACUSE                          | 2.528049e+02        | 1.106166e-47        |\n",
    "| 16         | COVID-19 Indicator_False                        | 2.337985e+02        | 1.105885e-45        |\n",
    "| 19         | District Name_BUFFALO                           | 1.899368e+02        | 2.156702e-35        |\n",
    "| 14         | Carrier Type_5D. SPECIAL FUND - UNKNOWN         | 1.410547e+02        | 2.025750e-19        |\n",
    "| 12         | Carrier Type_5A. SPECIAL FUND - CONS. COMM.     | 6.952501e+01        | 1.373846e-04        |\n",
    "| 13         | Carrier Type_5C. SPECIAL FUND - POI CARRIER WC  | 6.662003e+01        | 3.289411e-08        |\n",
    "| 32         | Medical Fee Region_III                          | 6.440377e+01        | 4.639156e-09        |\n",
    "| 29         | Gender_X                                        | 4.748883e+01        | 1.664102e-06        |\n",
    "| 3          | Alternative Dispute Resolution_False            | 9.310322e+00        | 2.313433e-01        |\n",
    "| 5          | Alternative Dispute Resolution_nan              | 4.706254e+00        | 6.919186e-01        |\n",
    "| 1          | Has C-2 Date                                    | 3.324562e-18        | 1.000000e+00        |\n",
    "| 2          | Has First Hearing Date                         | 3.324562e-18        | 1.000000e+00        |\n",
    "| 0          | Has C-3 Date                                    | 3.324562e-18        | 1.000000e+00        |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Has C-3 Date, Has C-2 Date, Has First Hearing Date, Alternative Dispute Resolution_nan and Alternative Dispute Resolution_False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova_features =[\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "anova_result = average_anova_across_folds_with_predefined_split(X_combined[anova_features], y_combined, ps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Average_F_Score</th>\n",
       "      <th>Average_P_Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Average Weekly Wage</td>\n",
       "      <td>174843.294364</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>IME-4 Count</td>\n",
       "      <td>2955.534057</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age at Injury</td>\n",
       "      <td>1041.869837</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Assembly Date</td>\n",
       "      <td>639.697662</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accident Date</td>\n",
       "      <td>541.534905</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Birth Year</td>\n",
       "      <td>527.851524</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Average_F_Score  Average_P_Value\n",
       "3  Average Weekly Wage    174843.294364              0.0\n",
       "5          IME-4 Count      2955.534057              0.0\n",
       "1        Age at Injury      1041.869837              0.0\n",
       "2        Assembly Date       639.697662              0.0\n",
       "0        Accident Date       541.534905              0.0\n",
       "4           Birth Year       527.851524              0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anova_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature ID | Feature Name         | Average F-Score   | Average P-Value |\n",
    "|------------|----------------------|-------------------|-----------------|\n",
    "| 3          | Average Weekly Wage | 174843.294364     | 0.0             |\n",
    "| 5          | IME-4 Count         | 2955.534057       | 0.0             |\n",
    "| 1          | Age at Injury       | 1041.869837       | 0.0             |\n",
    "| 2          | Assembly Date       | 639.697662        | 0.0             |\n",
    "| 0          | Accident Date       | 541.534905        | 0.0             |\n",
    "| 4          | Birth Year          | 527.851524        | 0.0             |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_cv = LogisticRegressionCV(\n",
    "    penalty='l1',\n",
    "    solver='saga', # Use SAGA solver for large datasets \n",
    "    Cs=5,\n",
    "    cv=ps,\n",
    "    random_state=42,\n",
    "    class_weight='balanced', # Balance class weights\n",
    "    n_jobs=-1,\n",
    "    scoring='f1_macro', # Use macro F1 score as scoring metric\n",
    "    max_iter=2000\n",
    ")\n",
    "logreg_cv.fit(X_combined, y_combined)\n",
    "\n",
    "# Identify selected and unselected features\n",
    "if len(logreg_cv.coef_.shape) > 1:\n",
    "    coefs = np.abs(logreg_cv.coef_).mean(axis=0)\n",
    "else:\n",
    "    coefs = logreg_cv.coef_.flatten()\n",
    "\n",
    "selected_features = X_combined.columns[coefs != 0].tolist()\n",
    "unselected_features = X_combined.columns[coefs == 0].tolist()\n",
    "\n",
    "sorted_idx = np.argsort(np.abs(coefs))\n",
    "sorted_features = X_combined.columns[sorted_idx]\n",
    "sorted_coefs = coefs[sorted_idx]\n",
    "\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.barh(sorted_features, sorted_coefs)\n",
    "plt.xlabel(\"Coefficient Value\")\n",
    "plt.ylabel(\"Features\")\n",
    "plt.title(\"Feature Importance via Logistic Regression with L1 Penalty (Sorted)\")\n",
    "plt.axvline(0, color=\"black\", linewidth=0.8, linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Unselected Features:\", unselected_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put features together with there coefficients\n",
    "feature_importance = pd.DataFrame({'Feature': sorted_features, 'Coefficient': sorted_coefs})\n",
    "feature_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                                | Coefficient |\n",
    "|----------------------------------------|-------------|\n",
    "| Alternative Dispute Resolution_nan     | 0.091208    |\n",
    "| Medical Fee Region_III                 | 0.104723    |\n",
    "| Accident Date                          | 0.156352    |\n",
    "| Birth Year                             | 0.161018    |\n",
    "| Number of Dependents                   | 0.162521    |\n",
    "| Medical Fee Region_UK                  | 0.199784    |\n",
    "| Medical Fee Region_I                   | 0.211184    |\n",
    "| Medical Fee Region_II                  | 0.218863    |\n",
    "| Medical Fee Region_IV                  | 0.251852    |\n",
    "| Has C-3 Date                           | 0.339323    |\n",
    "| Has C-2 Date                           | 0.339323    |\n",
    "| Has First Hearing Date                 | 0.339323    |\n",
    "| Attorney/Representative_True           | 0.344442    |\n",
    "| Carrier Type_5A. SPECIAL FUND - CONS. COMM. (S... | 0.354133    |\n",
    "| Carrier Type_4A. SELF PRIVATE          | 0.426216    |\n",
    "| Carrier Type_3A. SELF PUBLIC           | 0.427759    |\n",
    "| Age at Injury                          | 0.448413    |\n",
    "| Gender_X                               | 0.459640    |\n",
    "| COVID-19 Indicator_False               | 0.469610    |\n",
    "| Carrier Type_1A. PRIVATE               | 0.495387    |\n",
    "| Carrier Type_5C. SPECIAL FUND - POI CARRIER WC... | 0.506768    |\n",
    "| Assembly Date                          | 0.543958    |\n",
    "| District Name_HAUPPAUGE               | 0.592683    |\n",
    "| IME-4 Count                            | 0.615296    |\n",
    "| District Name_BUFFALO                 | 0.658296    |\n",
    "| District Name_SYRACUSE                | 0.679366    |\n",
    "| District Name_NYC                     | 0.706079    |\n",
    "| District Name_ALBANY                  | 0.709348    |\n",
    "| Carrier Type_5D. SPECIAL FUND - UNKNOWN | 0.721796    |\n",
    "| District Name_BINGHAMTON              | 0.733356    |\n",
    "| District Name_STATEWIDE               | 0.814429    |\n",
    "| Alternative Dispute Resolution_False  | 0.955822    |\n",
    "| Gender_F                               | 1.027072    |\n",
    "| County of Injury                       | 1.331568    |\n",
    "| Alternative Dispute Resolution_True   | 1.348975    |\n",
    "| COVID-19 Indicator_True               | 1.349827    |\n",
    "| Gender_M                               | 1.498185    |\n",
    "| Attorney/Representative_False         | 1.740615    |\n",
    "| Carrier Type_2A. SIF                  | 2.027552    |\n",
    "| Industry Code                          | 2.075674    |\n",
    "| Carrier Type_UNKNOWN                  | 2.330205    |\n",
    "| Gender_U                               | 2.846922    |\n",
    "| Average Weekly Wage                    | 3.204603    |\n",
    "| Zip Code                               | 3.625286    |\n",
    "| WCIO Nature of Injury Code            | 4.186389    |\n",
    "| District Name_ROCHESTER               | 4.952202    |\n",
    "| WCIO Cause of Injury Code             | 6.970056    |\n",
    "| WCIO Part Of Body Code                | 8.713728    |\n",
    "| Carrier Name                           | 9.174048    |\n",
    "\n",
    "All feature are selected by using this method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV with preprocessing_scaling_encoding_dum (All features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize RandomForest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,            # Number of trees\n",
    "    max_depth=15,                # Limit tree depth\n",
    "    min_samples_split=50,        # Minimum samples for a split\n",
    "    min_samples_leaf=20,         # Minimum samples per leaf\n",
    "    max_features='sqrt',         # Features to consider per split\n",
    "    class_weight='balanced',     # Handle class imbalance\n",
    "    bootstrap=True,              # Use bootstrapping\n",
    "    random_state=42,             # Ensure reproducibility\n",
    "    n_jobs=-1                    # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Set up RFECV with RandomForest and cross-validation\n",
    "rfecv = RFECV(estimator=rf_model, step=1, cv=ps, scoring='f1_macro') \n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_combined, y_combined)\n",
    "\n",
    "#Get the selected features\n",
    "selected_features_RFE_basic = X_combined.columns[rfecv.support_].tolist()\n",
    "optimal_num_features = rfecv.n_features_\n",
    "feature_ranking = rfecv.ranking_\n",
    "\n",
    "print(\"Optimal number of features:\", optimal_num_features)\n",
    "print(\"Selected Features:\", selected_features_RFE_basic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_ranking = pd.DataFrame({'Feature': X_combined.columns, 'Ranking': feature_ranking})\n",
    "Optimal_number_of_features = 26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal number of features: 26\n",
    "Selected Features: ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_NYC', 'Gender_F', 'Gender_M', 'Medical Fee Region_I', 'Medical Fee Region_IV', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_RFE_basic = ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_NYC', 'Gender_F', 'Gender_M', 'Medical Fee Region_I', 'Medical Fee Region_IV', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                                      | Ranking |\n",
    "|----------------------------------------------|---------|\n",
    "| Accident Date                                | 1       |\n",
    "| Age at Injury                                | 1       |\n",
    "| Assembly Date                                | 1       |\n",
    "| Average Weekly Wage                          | 1       |\n",
    "| Birth Year                                   | 1       |\n",
    "| IME-4 Count                                  | 1       |\n",
    "| Number of Dependents                         | 1       |\n",
    "| Attorney/Representative_False               | 1       |\n",
    "| Attorney/Representative_True                | 1       |\n",
    "| Carrier Type_1A. PRIVATE                     | 1       |\n",
    "| Carrier Type_2A. SIF                         | 1       |\n",
    "| Carrier Type_3A. SELF PUBLIC                 | 1       |\n",
    "| COVID-19 Indicator_False                     | 1       |\n",
    "| COVID-19 Indicator_True                      | 1       |\n",
    "| District Name_NYC                            | 1       |\n",
    "| Gender_F                                     | 1       |\n",
    "| Gender_M                                     | 1       |\n",
    "| Medical Fee Region_IV                        | 1       |\n",
    "| Carrier Name                                 | 1       |\n",
    "| County of Injury                             | 1       |\n",
    "| Industry Code                                | 1       |\n",
    "| WCIO Cause of Injury Code                    | 1       |\n",
    "| WCIO Nature of Injury Code                   | 1       |\n",
    "| WCIO Part Of Body Code                       | 1       |\n",
    "| Zip Code                                     | 1       |\n",
    "| Medical Fee Region_I                         | 2       |\n",
    "| District Name_BUFFALO                        | 3       |\n",
    "| Medical Fee Region_II                        | 4       |\n",
    "| District Name_ALBANY                         | 5       |\n",
    "| District Name_HAUPPAUGE                      | 6       |\n",
    "| Medical Fee Region_UK                        | 7       |\n",
    "| Medical Fee Region_III                       | 8       |\n",
    "| District Name_STATEWIDE                      | 9       |\n",
    "| District Name_SYRACUSE                       | 10      |\n",
    "| Carrier Type_4A. SELF PRIVATE                | 11      |\n",
    "| Alternative Dispute Resolution_False         | 12      |\n",
    "| District Name_BINGHAMTON                     | 13      |\n",
    "| District Name_ROCHESTER                      | 14      |\n",
    "| Alternative Dispute Resolution_True          | 15      |\n",
    "| Carrier Type_5D. SPECIAL FUND - UNKNOWN      | 16      |\n",
    "| Carrier Type_UNKNOWN                         | 17      |\n",
    "| Gender_U                                     | 18      |\n",
    "| Carrier Type_5A. SPECIAL FUND - CONS. COMM...| 19      |\n",
    "| Has C-2 Date                                 | 20      |\n",
    "| Carrier Type_5C. SPECIAL FUND - POI CARRIE...| 21      |\n",
    "| Has First Hearing Date                       | 22      |\n",
    "| Has C-3 Date                                 | 23      |\n",
    "| Alternative Dispute Resolution_nan           | 24      |\n",
    "| Gender_X                                     | 25      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                                      | Ranking |\n",
    "|----------------------------------------------|---------|\n",
    "| Accident Date                                | 1       |\n",
    "| Age at Injury                                | 1       |\n",
    "| Assembly Date                                | 1       |\n",
    "| Average Weekly Wage                          | 1       |\n",
    "| Birth Year                                   | 1       |\n",
    "| IME-4 Count                                  | 1       |\n",
    "| Number of Dependents                         | 1       |\n",
    "| Attorney/Representative_False               | 1       |\n",
    "| Attorney/Representative_True                | 1       |\n",
    "| Carrier Type_1A. PRIVATE                     | 1       |\n",
    "| Carrier Type_2A. SIF                         | 1       |\n",
    "| Carrier Type_3A. SELF PUBLIC                 | 1       |\n",
    "| COVID-19 Indicator_False                     | 1       |\n",
    "| COVID-19 Indicator_True                      | 1       |\n",
    "| District Name_NYC                            | 1       |\n",
    "| Gender_F                                     | 1       |\n",
    "| Gender_M                                     | 1       |\n",
    "| Medical Fee Region_IV                        | 1       |\n",
    "| Carrier Name                                 | 1       |\n",
    "| County of Injury                             | 1       |\n",
    "| Industry Code                                | 1       |\n",
    "| WCIO Cause of Injury Code                    | 1       |\n",
    "| WCIO Nature of Injury Code                   | 1       |\n",
    "| WCIO Part Of Body Code                       | 1       |\n",
    "| Zip Code                                     | 1       |\n",
    "| Medical Fee Region_I                         | 2       |\n",
    "| District Name_BUFFALO                        | 3       |\n",
    "| Medical Fee Region_II                        | 4       |\n",
    "| District Name_ALBANY                         | 5       |\n",
    "| District Name_HAUPPAUGE                      | 6       |\n",
    "| Medical Fee Region_UK                        | 7       |\n",
    "| Medical Fee Region_III                       | 8       |\n",
    "| District Name_STATEWIDE                      | 9       |\n",
    "| District Name_SYRACUSE                       | 10      |\n",
    "| Carrier Type_4A. SELF PRIVATE                | 11      |\n",
    "| Alternative Dispute Resolution_False         | 12      |\n",
    "| District Name_BINGHAMTON                     | 13      |\n",
    "| District Name_ROCHESTER                      | 14      |\n",
    "| Alternative Dispute Resolution_True          | 15      |\n",
    "| Carrier Type_5D. SPECIAL FUND - UNKNOWN      | 16      |\n",
    "| Carrier Type_UNKNOWN                         | 17      |\n",
    "| Gender_U                                     | 18      |\n",
    "| Carrier Type_5A. SPECIAL FUND - CONS. COMM...| 19      |\n",
    "| Has C-2 Date                                 | 20      |\n",
    "| Carrier Type_5C. SPECIAL FUND - POI CARRIE...| 21      |\n",
    "| Has First Hearing Date                       | 22      |\n",
    "| Has C-3 Date                                 | 23      |\n",
    "| Alternative Dispute Resolution_nan           | 24      |\n",
    "| Gender_X                                     | 25      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| Feature                                      | Ranking |\n",
    "|----------------------------------------------|---------|\n",
    "| Accident Date                                | 1       |\n",
    "| Age at Injury                                | 1       |\n",
    "| Assembly Date                                | 1       |\n",
    "| Average Weekly Wage                          | 1       |\n",
    "| Birth Year                                   | 1       |\n",
    "| IME-4 Count                                  | 1       |\n",
    "| Number of Dependents                         | 1       |\n",
    "| Attorney/Representative_False               | 1       |\n",
    "| Attorney/Representative_True                | 1       |\n",
    "| Carrier Type_1A. PRIVATE                     | 1       |\n",
    "| Carrier Type_2A. SIF                         | 1       |\n",
    "| Carrier Type_3A. SELF PUBLIC                 | 1       |\n",
    "| COVID-19 Indicator_False                     | 1       |\n",
    "| COVID-19 Indicator_True                      | 1       |\n",
    "| District Name_NYC                            | 1       |\n",
    "| Gender_F                                     | 1       |\n",
    "| Gender_M                                     | 1       |\n",
    "| Medical Fee Region_IV                        | 1       |\n",
    "| Carrier Name                                 | 1       |\n",
    "| County of Injury                             | 1       |\n",
    "| Industry Code                                | 1       |\n",
    "| WCIO Cause of Injury Code                    | 1       |\n",
    "| WCIO Nature of Injury Code                   | 1       |\n",
    "| WCIO Part Of Body Code                       | 1       |\n",
    "| Zip Code                                     | 1       |\n",
    "| Medical Fee Region_I                         | 2       |\n",
    "| District Name_BUFFALO                        | 3       |\n",
    "| Medical Fee Region_II                        | 4       |\n",
    "| District Name_ALBANY                         | 5       |\n",
    "| District Name_HAUPPAUGE                      | 6       |\n",
    "| Medical Fee Region_UK                        | 7       |\n",
    "| Medical Fee Region_III                       | 8       |\n",
    "| District Name_STATEWIDE                      | 9       |\n",
    "| District Name_SYRACUSE                       | 10      |\n",
    "| Carrier Type_4A. SELF PRIVATE                | 11      |\n",
    "| Alternative Dispute Resolution_False         | 12      |\n",
    "| District Name_BINGHAMTON                     | 13      |\n",
    "| District Name_ROCHESTER                      | 14      |\n",
    "| Alternative Dispute Resolution_True          | 15      |\n",
    "| Carrier Type_5D. SPECIAL FUND - UNKNOWN      | 16      |\n",
    "| Carrier Type_UNKNOWN                         | 17      |\n",
    "| Gender_U                                     | 18      |\n",
    "| Carrier Type_5A. SPECIAL FUND - CONS. COMM...| 19      |\n",
    "| Has C-2 Date                                 | 20      |\n",
    "| Carrier Type_5C. SPECIAL FUND - POI CARRIE...| 21      |\n",
    "| Has First Hearing Date                       | 22      |\n",
    "| Has C-3 Date                                 | 23      |\n",
    "| Alternative Dispute Resolution_nan           | 24      |\n",
    "| Gender_X                                     | 25      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection report (simple preprocesing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature                                      | Lasso       | RFE | Chi-Square AND Anova |\n",
    "|----------------------------------------------|-------------|-----|----------------------|\n",
    "| Accident Date                                | 0.156352    | 1   | Yes                  |\n",
    "| Age at Injury                                | 0.448413    | 1   | Yes                  |\n",
    "| Assembly Date                                | 0.543958    | 1   | Yes                  |\n",
    "| Average Weekly Wage                          | 3.204603    | 1   | Yes                  |\n",
    "| Birth Year                                   | 0.161018    | 1   | Yes                  |\n",
    "| IME-4 Count                                  | 0.615296    | 1   | Yes                  |\n",
    "| Number of Dependents                         | 0.162521    | 1   | Yes                  |\n",
    "| Attorney/Representative_False               | 1.740615    | 1   | Yes                  |\n",
    "| Attorney/Representative_True                | 0.344442    | 1   | Yes                  |\n",
    "| Carrier Type_1A. PRIVATE                     | 0.495387    | 1   | Yes                  |\n",
    "| Carrier Type_2A. SIF                         | 2.027552    | 1   | Yes                  |\n",
    "| Carrier Type_3A. SELF PUBLIC                 | 0.427759    | 1   | Yes                  |\n",
    "| COVID-19 Indicator_False                     | 0.469610    | 1   | Yes                  |\n",
    "| COVID-19 Indicator_True                      | 1.349827    | 1   | Yes                  |\n",
    "| District Name_NYC                            | 0.706079    | 1   | Yes                  |\n",
    "| Gender_F                                     | 1.027072    | 1   | Yes                  |\n",
    "| Gender_M                                     | 1.498185    | 1   | Yes                  |\n",
    "| Medical Fee Region_IV                        | 0.251852    | 1   | Yes                  |\n",
    "| Carrier Name                                 | 9.174048    | 1   | NAN                  |\n",
    "| County of Injury                             | 1.331568    | 1   | NAN                  |\n",
    "| Industry Code                                | 2.075674    | 1   | NAN                  |\n",
    "| WCIO Cause of Injury Code                    | 6.970056    | 1   | NAN                  |\n",
    "| WCIO Nature of Injury Code                   | 4.186389    | 1   | NAN                  |\n",
    "| WCIO Part Of Body Code                       | 8.713728    | 1   | NAN                  |\n",
    "| Zip Code                                     | 3.625286    | 1   | NAN                   |\n",
    "| Medical Fee Region_I                         | 0.211184    | 2   | Yes                  |\n",
    "| District Name_BUFFALO                        | 0.658296    | 3   | Yes                  |\n",
    "| Medical Fee Region_II                        | 0.218863    | 4   | Yes                  |\n",
    "| District Name_ALBANY                         | 0.709348    | 5   | Yes                  |\n",
    "| District Name_HAUPPAUGE                      | 0.592683    | 6   | Yes                  |\n",
    "| Medical Fee Region_UK                        | 0.199784    | 7   | Yes                  |\n",
    "| Medical Fee Region_III                       | 0.104723    | 8   | Yes                  |\n",
    "| District Name_STATEWIDE                      | 0.814429    | 9   | Yes                  |\n",
    "| District Name_SYRACUSE                       | 0.679366    | 10  | Yes                  |\n",
    "| Carrier Type_4A. SELF PRIVATE                | 0.426216    | 11  | Yes                  |\n",
    "| Alternative Dispute Resolution_False         | 0.955822    | 12  | No                   |\n",
    "| District Name_BINGHAMTON                     | 0.733356    | 13  | Yes                  |\n",
    "| District Name_ROCHESTER                      | 4.952202    | 14  | Yes                  |\n",
    "| Alternative Dispute Resolution_True          | 1.348975    | 15  | Yes                  |\n",
    "| Carrier Type_5D. SPECIAL FUND - UNKNOWN      | 0.721796    | 16  | Yes                  |\n",
    "| Carrier Type_UNKNOWN                         | 2.330205    | 17  | Yes                  |\n",
    "| Gender_U                                     | 2.846922    | 18  | Yes                  |\n",
    "| Carrier Type_5A. SPECIAL FUND - CONS. COMM...| 0.354133    | 19  | Yes                  |\n",
    "| Has C-2 Date                                 | 0.339323    | 20  | No                  |\n",
    "| Carrier Type_5C. SPECIAL FUND - POI CARRIE...| 0.506768    | 21  | Yes                  |\n",
    "| Has First Hearing Date                       | 0.339323    | 22  | No                  |\n",
    "| Has C-3 Date                                 | 0.339323    | 23  | No                  |\n",
    "| Alternative Dispute Resolution_nan           | 0.091208    | 24  | No                   |\n",
    "| Gender_X                                     | 0.459640    | 25  | Yes                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this section we are comparing model the same preprocessing technique\n",
    "- the feature selected are the one selected with the RFECV (preprocessing_scaling_encoding_dum)\n",
    "- we will selecte the model that has the highest f1-score macro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(X, y, model, param_grid, preprocess_steps, n_splits=5):\n",
    "    \"\"\"\n",
    "    Finds the best hyperparameters for a given model using GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Creates a PredefinedSplit object\n",
    "    - Creates a GridSearchCV object\n",
    "    - Fits the GridSearchCV object\n",
    "    - Returns the best hyperparameters and the best score\n",
    "    \"\"\"\n",
    "\n",
    "    scoring = make_scorer(f1_score, average='macro')\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=ps,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_combined, y_combined)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best F1-macro Score:\", grid_search.best_score_)\n",
    "\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'penalty': ['l2', 'elasticnet'],         \n",
    "    'C': [0.01, 0.1, 1, 10],              \n",
    "    'solver': ['lbfgs', 'saga'],            \n",
    "    'class_weight': ['balanced', None],      \n",
    "    'l1_ratio': [0.5]                   \n",
    "}\n",
    "\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticregression_best_param, logisticregression_best_score = get_best_parameters(X, y, model, param_grid, preprocessing_scaling_encoding_dum, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: \n",
    "- 'penalty': l2\n",
    "- 'C': 10\n",
    "- 'solver': 'lbfgs'\n",
    "- 'class_weight': 'balanced' \n",
    "- 'l1_ratio': 0.5 <br>\n",
    "\n",
    "Best F1-macro Score: 0.29291927882029445"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "model=RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomForestClassifier_best_param, RandomForestClassifier_best_score = get_best_parameters(X, y, model, param_grid, preprocessing_scaling_encoding_dum, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: \n",
    "- 'bootstrap': False\n",
    "- 'max_depth': None\n",
    "- 'max_features': 'sqrt'\n",
    "- 'min_samples_leaf': 1\n",
    "- 'min_samples_split': 2\n",
    "-  'n_estimators': 200 <br>\n",
    "\n",
    "Best_NN F1-macro Score: 0.3706281959869002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'hidden_layer_sizes': [\n",
    "        (int(0.75 * len(selected_features)), int(0.5 * len(selected_features))),  # Original configuration\n",
    "        (int(0.5 * len(selected_features)), int(0.25 * len(selected_features)), int(0.125 * len(selected_features))),  # Three layers\n",
    "    ],\n",
    "    'learning_rate_init': [0.01, 0.1],  # Test lower and higher learning rates\n",
    "    'activation': ['relu', 'tanh'],  # Compare relu and tanh\n",
    "    'alpha': [0.001, 0.01],  # Regularization strength\n",
    "    'batch_size': ['auto', 64, 128],  # Test different batch sizes\n",
    "}\n",
    "model = MLPClassifier(solver='adam',max_iter=1000,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnGS_best_params, nnGS_best_score = get_best_parameters(X, y, model, param_grid, preprocessing_scaling_encoding_dum, selected_features, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters:\n",
    "- 'activation': 'tanh'\n",
    "- 'alpha': 0.001\n",
    "- 'batch_size': 'auto' \n",
    "- 'hidden_layer_sizes': (34, 23)\n",
    "- 'learning_rate_init': 0.01<br>\n",
    "\n",
    "Best_NN F1-macro Score: 0.30394956984435917"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [3, 6],\n",
    "    'learning_rate': [0.01, 0.3],\n",
    "    'gamma': [0, 2],\n",
    "    'reg_alpha': [0, 5],\n",
    "    'reg_lambda': [1, 10],\n",
    "    'min_child_weight': [1, 5] \n",
    "}\n",
    "model=XGBClassifier(random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_best_params, xgb_best_score = get_best_parameters(X, y, model, param_grid, preprocessing_scaling_encoding_dum, selected_features, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best Parameters: \n",
    "- 'gamma': 0\n",
    "- 'learning_rate': 0.3\n",
    "- 'max_depth': 6\n",
    "-  'min_child_weight': 1\n",
    "-  'n_estimators': 100\n",
    "-  'reg_alpha': 0\n",
    "-  'reg_lambda': 1<br>\n",
    "\n",
    "Best_Xgboost F1-macro Score: 0.44258821978115226<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform'], # Weight function\n",
    "    'metric': ['minkowski'],\n",
    "    'p': [1, 2], # Power parameter for Minkowski distance\n",
    "    'algorithm': ['auto', 'ball_tree'],  # Algorithm for nearest neighbor search\n",
    "    'leaf_size': [20, 30, 40, 50] \n",
    "}\n",
    "\n",
    "model=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_best_param, knn_best_score = get_best_parameters(X, y, model, param_grid, preprocessing_scaling_encoding_dum, selected_features, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knn_best_parameter:\n",
    "- 'algorithm': 'auto'\n",
    "- 'leaf_size': 20\n",
    "- 'metric': 'minkowski'\n",
    "- 'n_neighbors': 5\n",
    "- 'p': 1\n",
    "- 'weights': 'uniform' <br>\n",
    "\n",
    "Knn_Best F1-macro Score:: 0.3001599658723925"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models_with_overfitting_check(X, y, predefined_split, selected_features, models):\n",
    "    \"\"\"\n",
    "    Evaluates multiple models on a dataset with a predefined split and calculates train-test metric differences.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): Feature dataset.\n",
    "    - y (pd.Series or np.array): Target variable.\n",
    "    - predefined_split (PredefinedSplit): Predefined split object for cross-validation.\n",
    "    - models (dict): Dictionary of models, where keys are model names and values are model instances.\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Summary table with mean, variance, and train-test differences for evaluation metrics.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        fold_metrics = {\n",
    "            'accuracy_train': [],\n",
    "            'accuracy_test': [],\n",
    "            'precision_macro_train': [],\n",
    "            'precision_macro_test': [],\n",
    "            'recall_macro_train': [],\n",
    "            'recall_macro_test': [],\n",
    "            'f1_macro_train': [],\n",
    "            'f1_macro_test': []\n",
    "        }\n",
    "        \n",
    "        # Loop through predefined splits\n",
    "        for train_idx, test_idx in predefined_split.split():\n",
    "            # Split data\n",
    "            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y[train_idx], y[test_idx]\n",
    "            \n",
    "            # Train model\n",
    "            model.fit(X_train[selected_features], y_train)\n",
    "            \n",
    "            # Predict on train and test data\n",
    "            y_train_pred = model.predict(X_train[selected_features])\n",
    "            y_test_pred = model.predict(X_test[selected_features])\n",
    "            \n",
    "            # Calculate metrics for train and test data\n",
    "            fold_metrics['accuracy_train'].append(accuracy_score(y_train, y_train_pred))\n",
    "            fold_metrics['accuracy_test'].append(accuracy_score(y_test, y_test_pred))\n",
    "            fold_metrics['precision_macro_train'].append(precision_score(y_train, y_train_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['precision_macro_test'].append(precision_score(y_test, y_test_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['recall_macro_train'].append(recall_score(y_train, y_train_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['recall_macro_test'].append(recall_score(y_test, y_test_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['f1_macro_train'].append(f1_score(y_train, y_train_pred, average='macro', zero_division=0))\n",
    "            fold_metrics['f1_macro_test'].append(f1_score(y_test, y_test_pred, average='macro', zero_division=0))\n",
    "        \n",
    "        # Calculate mean, variance, and train-test differences for each metric\n",
    "        for metric_name in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
    "            train_metric = np.array(fold_metrics[f'{metric_name}_train'])\n",
    "            test_metric = np.array(fold_metrics[f'{metric_name}_test'])\n",
    "            \n",
    "            mean_train = np.mean(train_metric)\n",
    "            mean_test = np.mean(test_metric)\n",
    "            variance_train = np.var(train_metric)\n",
    "            variance_test = np.var(test_metric)\n",
    "            mean_difference = mean_train - mean_test\n",
    "            \n",
    "            results.append({\n",
    "                'Model': model_name,\n",
    "                'Metric': metric_name,\n",
    "                'Mean_Train': mean_train,\n",
    "                'Mean_Test': mean_test,\n",
    "                'Variance_Train': variance_train,\n",
    "                'Variance_Test': variance_test,\n",
    "                'Train-Test_Difference': mean_difference\n",
    "            })\n",
    "        \n",
    "        print(results)\n",
    "    \n",
    "    # Convert results to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(penalty='l2', C=10, solver='lbfgs', class_weight='balanced', l1_ratio=0.5, max_iter=1000, n_jobs=-1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=3, weights='uniform', metric='minkowski', p=1, algorithm='auto', leaf_size=20, n_jobs=-1),\n",
    "    'MLP': MLPClassifier( solver='adam', max_iter=1000, random_state=42, activation='tanh', alpha=0.001, batch_size='auto', hidden_layer_sizes=(int(0.75 * len(selected_features_RFE_basic)), int(0.5 * len(selected_features_RFE_basic))), learning_rate_init=0.01),\n",
    "    'Decision Tree': DecisionTreeClassifier(max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', random_state=42),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=None, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', bootstrap=False, random_state=42, n_jobs=-1),\n",
    "    'XGBoost': XGBClassifier(gamma = 0, learning_rate = 0.3, max_depth = 6, min_child_weight = 1, n_estimators = 200, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)   \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}, {'Model': 'MLP', 'Metric': 'accuracy', 'Mean_Train': 0.7648826001526843, 'Mean_Test': 0.7642615526308056, 'Variance_Train': 4.956358065795995e-06, 'Variance_Test': 2.358998292495016e-06, 'Train-Test_Difference': 0.0006210475218786371}, {'Model': 'MLP', 'Metric': 'precision_macro', 'Mean_Train': 0.4002431610909952, 'Mean_Test': 0.4109170247531673, 'Variance_Train': 7.107619724525379e-05, 'Variance_Test': 0.0010936824097936206, 'Train-Test_Difference': -0.0106738636621721}, {'Model': 'MLP', 'Metric': 'recall_macro', 'Mean_Train': 0.30991650365407225, 'Mean_Test': 0.3096918087272804, 'Variance_Train': 0.0001660723266943243, 'Variance_Test': 0.0001557380275599381, 'Train-Test_Difference': 0.00022469492679183523}, {'Model': 'MLP', 'Metric': 'f1_macro', 'Mean_Train': 0.3065260622049793, 'Mean_Test': 0.30640756645758416, 'Variance_Train': 0.0002847270361951682, 'Variance_Test': 0.00025894250509786025, 'Train-Test_Difference': 0.00011849574739514201}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}, {'Model': 'MLP', 'Metric': 'accuracy', 'Mean_Train': 0.7648826001526843, 'Mean_Test': 0.7642615526308056, 'Variance_Train': 4.956358065795995e-06, 'Variance_Test': 2.358998292495016e-06, 'Train-Test_Difference': 0.0006210475218786371}, {'Model': 'MLP', 'Metric': 'precision_macro', 'Mean_Train': 0.4002431610909952, 'Mean_Test': 0.4109170247531673, 'Variance_Train': 7.107619724525379e-05, 'Variance_Test': 0.0010936824097936206, 'Train-Test_Difference': -0.0106738636621721}, {'Model': 'MLP', 'Metric': 'recall_macro', 'Mean_Train': 0.30991650365407225, 'Mean_Test': 0.3096918087272804, 'Variance_Train': 0.0001660723266943243, 'Variance_Test': 0.0001557380275599381, 'Train-Test_Difference': 0.00022469492679183523}, {'Model': 'MLP', 'Metric': 'f1_macro', 'Mean_Train': 0.3065260622049793, 'Mean_Test': 0.30640756645758416, 'Variance_Train': 0.0002847270361951682, 'Variance_Test': 0.00025894250509786025, 'Train-Test_Difference': 0.00011849574739514201}, {'Model': 'Decision Tree', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.7200457776280091, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 7.2965412683838725e-06, 'Train-Test_Difference': 0.2799503026896688}, {'Model': 'Decision Tree', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.4615245572698397, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 0.000127724245376472, 'Train-Test_Difference': 0.538452836673462}, {'Model': 'Decision Tree', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.4765612104519021, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00020845492031301236, 'Train-Test_Difference': 0.523437819183959}, {'Model': 'Decision Tree', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.4682465894888965, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0001473811563851997, 'Train-Test_Difference': 0.531741621097205}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}, {'Model': 'MLP', 'Metric': 'accuracy', 'Mean_Train': 0.7648826001526843, 'Mean_Test': 0.7642615526308056, 'Variance_Train': 4.956358065795995e-06, 'Variance_Test': 2.358998292495016e-06, 'Train-Test_Difference': 0.0006210475218786371}, {'Model': 'MLP', 'Metric': 'precision_macro', 'Mean_Train': 0.4002431610909952, 'Mean_Test': 0.4109170247531673, 'Variance_Train': 7.107619724525379e-05, 'Variance_Test': 0.0010936824097936206, 'Train-Test_Difference': -0.0106738636621721}, {'Model': 'MLP', 'Metric': 'recall_macro', 'Mean_Train': 0.30991650365407225, 'Mean_Test': 0.3096918087272804, 'Variance_Train': 0.0001660723266943243, 'Variance_Test': 0.0001557380275599381, 'Train-Test_Difference': 0.00022469492679183523}, {'Model': 'MLP', 'Metric': 'f1_macro', 'Mean_Train': 0.3065260622049793, 'Mean_Test': 0.30640756645758416, 'Variance_Train': 0.0002847270361951682, 'Variance_Test': 0.00025894250509786025, 'Train-Test_Difference': 0.00011849574739514201}, {'Model': 'Decision Tree', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.7200457776280091, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 7.2965412683838725e-06, 'Train-Test_Difference': 0.2799503026896688}, {'Model': 'Decision Tree', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.4615245572698397, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 0.000127724245376472, 'Train-Test_Difference': 0.538452836673462}, {'Model': 'Decision Tree', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.4765612104519021, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00020845492031301236, 'Train-Test_Difference': 0.523437819183959}, {'Model': 'Decision Tree', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.4682465894888965, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0001473811563851997, 'Train-Test_Difference': 0.531741621097205}, {'Model': 'Random Forest', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.8349046898795723, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 1.4609380649261503e-06, 'Train-Test_Difference': 0.1650913904381056}, {'Model': 'Random Forest', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.8718160636000647, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 5.639710050607065e-05, 'Train-Test_Difference': 0.12816133034323707}, {'Model': 'Random Forest', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.5489090744724608, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00025384904196707944, 'Train-Test_Difference': 0.4510899551634002}, {'Model': 'Random Forest', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.6287462535413679, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0003302599950561454, 'Train-Test_Difference': 0.3712419570447336}]\n",
      "[{'Model': 'Logistic Regression', 'Metric': 'accuracy', 'Mean_Train': 0.5648864342759046, 'Mean_Test': 0.5644361071482301, 'Variance_Train': 7.678479870305885e-07, 'Variance_Test': 2.207548016250967e-06, 'Train-Test_Difference': 0.0004503271276744547}, {'Model': 'Logistic Regression', 'Metric': 'precision_macro', 'Mean_Train': 0.30913436712507086, 'Mean_Test': 0.30862585365805, 'Variance_Train': 8.193641802431955e-08, 'Variance_Test': 6.239133540528498e-07, 'Train-Test_Difference': 0.0005085134670208546}, {'Model': 'Logistic Regression', 'Metric': 'recall_macro', 'Mean_Train': 0.52186933893118, 'Mean_Test': 0.5071567441402027, 'Variance_Train': 3.2741888109937693e-06, 'Variance_Test': 7.775047044649272e-05, 'Train-Test_Difference': 0.014712594790977307}, {'Model': 'Logistic Regression', 'Metric': 'f1_macro', 'Mean_Train': 0.2936806660403459, 'Mean_Test': 0.2929949562387949, 'Variance_Train': 2.0410982399121922e-07, 'Variance_Test': 1.2289298748820628e-06, 'Train-Test_Difference': 0.0006857098015509711}, {'Model': 'KNN', 'Metric': 'accuracy', 'Mean_Train': 0.8452766076770185, 'Mean_Test': 0.6969788823585019, 'Variance_Train': 1.1078671323089686e-07, 'Variance_Test': 1.0829339122579351e-06, 'Train-Test_Difference': 0.1482977253185166}, {'Model': 'KNN', 'Metric': 'precision_macro', 'Mean_Train': 0.7754049777462054, 'Mean_Test': 0.3632932235676556, 'Variance_Train': 3.0034872834312836e-05, 'Variance_Test': 0.000306411595544399, 'Train-Test_Difference': 0.41211175417854984}, {'Model': 'KNN', 'Metric': 'recall_macro', 'Mean_Train': 0.5969213790798921, 'Mean_Test': 0.3253189977468709, 'Variance_Train': 7.665585215216992e-05, 'Variance_Test': 3.4745650690932424e-05, 'Train-Test_Difference': 0.27160238133302117}, {'Model': 'KNN', 'Metric': 'f1_macro', 'Mean_Train': 0.6555213417026609, 'Mean_Test': 0.3346903482771938, 'Variance_Train': 6.426811513267771e-05, 'Variance_Test': 7.090788796380748e-05, 'Train-Test_Difference': 0.32083099342546706}, {'Model': 'MLP', 'Metric': 'accuracy', 'Mean_Train': 0.7648826001526843, 'Mean_Test': 0.7642615526308056, 'Variance_Train': 4.956358065795995e-06, 'Variance_Test': 2.358998292495016e-06, 'Train-Test_Difference': 0.0006210475218786371}, {'Model': 'MLP', 'Metric': 'precision_macro', 'Mean_Train': 0.4002431610909952, 'Mean_Test': 0.4109170247531673, 'Variance_Train': 7.107619724525379e-05, 'Variance_Test': 0.0010936824097936206, 'Train-Test_Difference': -0.0106738636621721}, {'Model': 'MLP', 'Metric': 'recall_macro', 'Mean_Train': 0.30991650365407225, 'Mean_Test': 0.3096918087272804, 'Variance_Train': 0.0001660723266943243, 'Variance_Test': 0.0001557380275599381, 'Train-Test_Difference': 0.00022469492679183523}, {'Model': 'MLP', 'Metric': 'f1_macro', 'Mean_Train': 0.3065260622049793, 'Mean_Test': 0.30640756645758416, 'Variance_Train': 0.0002847270361951682, 'Variance_Test': 0.00025894250509786025, 'Train-Test_Difference': 0.00011849574739514201}, {'Model': 'Decision Tree', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.7200457776280091, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 7.2965412683838725e-06, 'Train-Test_Difference': 0.2799503026896688}, {'Model': 'Decision Tree', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.4615245572698397, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 0.000127724245376472, 'Train-Test_Difference': 0.538452836673462}, {'Model': 'Decision Tree', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.4765612104519021, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00020845492031301236, 'Train-Test_Difference': 0.523437819183959}, {'Model': 'Decision Tree', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.4682465894888965, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0001473811563851997, 'Train-Test_Difference': 0.531741621097205}, {'Model': 'Random Forest', 'Metric': 'accuracy', 'Mean_Train': 0.999996080317678, 'Mean_Test': 0.8349046898795723, 'Variance_Train': 2.6554859422297235e-12, 'Variance_Test': 1.4609380649261503e-06, 'Train-Test_Difference': 0.1650913904381056}, {'Model': 'Random Forest', 'Metric': 'precision_macro', 'Mean_Train': 0.9999773939433018, 'Mean_Test': 0.8718160636000647, 'Variance_Train': 8.953025670874344e-11, 'Variance_Test': 5.639710050607065e-05, 'Train-Test_Difference': 0.12816133034323707}, {'Model': 'Random Forest', 'Metric': 'recall_macro', 'Mean_Train': 0.9999990296358611, 'Mean_Test': 0.5489090744724608, 'Variance_Train': 1.625215517261615e-13, 'Variance_Test': 0.00025384904196707944, 'Train-Test_Difference': 0.4510899551634002}, {'Model': 'Random Forest', 'Metric': 'f1_macro', 'Mean_Train': 0.9999882105861015, 'Mean_Test': 0.6287462535413679, 'Variance_Train': 2.433948321976538e-11, 'Variance_Test': 0.0003302599950561454, 'Train-Test_Difference': 0.3712419570447336}, {'Model': 'XGBoost', 'Metric': 'accuracy', 'Mean_Train': 0.8191453871807308, 'Mean_Test': 0.79444310934698, 'Variance_Train': 1.2222486025748864e-07, 'Variance_Test': 8.284927068121797e-07, 'Train-Test_Difference': 0.024702277833750785}, {'Model': 'XGBoost', 'Metric': 'precision_macro', 'Mean_Train': 0.865285079747261, 'Mean_Test': 0.7572305265678835, 'Variance_Train': 2.881964700788584e-07, 'Variance_Test': 1.7124830365727337e-05, 'Train-Test_Difference': 0.10805455317937751}, {'Model': 'XGBoost', 'Metric': 'recall_macro', 'Mean_Train': 0.6934437071428775, 'Mean_Test': 0.46091863984035364, 'Variance_Train': 2.1266742727174523e-06, 'Variance_Test': 0.00014882553499047884, 'Train-Test_Difference': 0.23252506730252387}, {'Model': 'XGBoost', 'Metric': 'f1_macro', 'Mean_Train': 0.7206959213073542, 'Mean_Test': 0.5048867328424411, 'Variance_Train': 2.1608910001337583e-06, 'Variance_Test': 0.000274272978841161, 'Train-Test_Difference': 0.21580918846491304}]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "performance_results = evaluate_models_with_overfitting_check(X_combined, y_combined, ps, selected_features_RFE_basic, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean_Train</th>\n",
       "      <th>Mean_Test</th>\n",
       "      <th>Variance_Train</th>\n",
       "      <th>Variance_Test</th>\n",
       "      <th>Train-Test_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.564886</td>\n",
       "      <td>0.564436</td>\n",
       "      <td>7.678480e-07</td>\n",
       "      <td>2.207548e-06</td>\n",
       "      <td>0.000450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.309134</td>\n",
       "      <td>0.308626</td>\n",
       "      <td>8.193642e-08</td>\n",
       "      <td>6.239134e-07</td>\n",
       "      <td>0.000509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.521869</td>\n",
       "      <td>0.507157</td>\n",
       "      <td>3.274189e-06</td>\n",
       "      <td>7.775047e-05</td>\n",
       "      <td>0.014713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.293681</td>\n",
       "      <td>0.292995</td>\n",
       "      <td>2.041098e-07</td>\n",
       "      <td>1.228930e-06</td>\n",
       "      <td>0.000686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KNN</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.845277</td>\n",
       "      <td>0.696979</td>\n",
       "      <td>1.107867e-07</td>\n",
       "      <td>1.082934e-06</td>\n",
       "      <td>0.148298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>KNN</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.775405</td>\n",
       "      <td>0.363293</td>\n",
       "      <td>3.003487e-05</td>\n",
       "      <td>3.064116e-04</td>\n",
       "      <td>0.412112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.596921</td>\n",
       "      <td>0.325319</td>\n",
       "      <td>7.665585e-05</td>\n",
       "      <td>3.474565e-05</td>\n",
       "      <td>0.271602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNN</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.655521</td>\n",
       "      <td>0.334690</td>\n",
       "      <td>6.426812e-05</td>\n",
       "      <td>7.090789e-05</td>\n",
       "      <td>0.320831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>MLP</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.764883</td>\n",
       "      <td>0.764262</td>\n",
       "      <td>4.956358e-06</td>\n",
       "      <td>2.358998e-06</td>\n",
       "      <td>0.000621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MLP</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.400243</td>\n",
       "      <td>0.410917</td>\n",
       "      <td>7.107620e-05</td>\n",
       "      <td>1.093682e-03</td>\n",
       "      <td>-0.010674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>MLP</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.309917</td>\n",
       "      <td>0.309692</td>\n",
       "      <td>1.660723e-04</td>\n",
       "      <td>1.557380e-04</td>\n",
       "      <td>0.000225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MLP</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.306526</td>\n",
       "      <td>0.306408</td>\n",
       "      <td>2.847270e-04</td>\n",
       "      <td>2.589425e-04</td>\n",
       "      <td>0.000118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.720046</td>\n",
       "      <td>2.655486e-12</td>\n",
       "      <td>7.296541e-06</td>\n",
       "      <td>0.279950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.461525</td>\n",
       "      <td>8.953026e-11</td>\n",
       "      <td>1.277242e-04</td>\n",
       "      <td>0.538453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.476561</td>\n",
       "      <td>1.625216e-13</td>\n",
       "      <td>2.084549e-04</td>\n",
       "      <td>0.523438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.468247</td>\n",
       "      <td>2.433948e-11</td>\n",
       "      <td>1.473812e-04</td>\n",
       "      <td>0.531742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.999996</td>\n",
       "      <td>0.834905</td>\n",
       "      <td>2.655486e-12</td>\n",
       "      <td>1.460938e-06</td>\n",
       "      <td>0.165091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.999977</td>\n",
       "      <td>0.871816</td>\n",
       "      <td>8.953026e-11</td>\n",
       "      <td>5.639710e-05</td>\n",
       "      <td>0.128161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.999999</td>\n",
       "      <td>0.548909</td>\n",
       "      <td>1.625216e-13</td>\n",
       "      <td>2.538490e-04</td>\n",
       "      <td>0.451090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.628746</td>\n",
       "      <td>2.433948e-11</td>\n",
       "      <td>3.302600e-04</td>\n",
       "      <td>0.371242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.819145</td>\n",
       "      <td>0.794443</td>\n",
       "      <td>1.222249e-07</td>\n",
       "      <td>8.284927e-07</td>\n",
       "      <td>0.024702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.865285</td>\n",
       "      <td>0.757231</td>\n",
       "      <td>2.881965e-07</td>\n",
       "      <td>1.712483e-05</td>\n",
       "      <td>0.108055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.693444</td>\n",
       "      <td>0.460919</td>\n",
       "      <td>2.126674e-06</td>\n",
       "      <td>1.488255e-04</td>\n",
       "      <td>0.232525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.720696</td>\n",
       "      <td>0.504887</td>\n",
       "      <td>2.160891e-06</td>\n",
       "      <td>2.742730e-04</td>\n",
       "      <td>0.215809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model           Metric  Mean_Train  Mean_Test  \\\n",
       "0   Logistic Regression         accuracy    0.564886   0.564436   \n",
       "1   Logistic Regression  precision_macro    0.309134   0.308626   \n",
       "2   Logistic Regression     recall_macro    0.521869   0.507157   \n",
       "3   Logistic Regression         f1_macro    0.293681   0.292995   \n",
       "4                   KNN         accuracy    0.845277   0.696979   \n",
       "5                   KNN  precision_macro    0.775405   0.363293   \n",
       "6                   KNN     recall_macro    0.596921   0.325319   \n",
       "7                   KNN         f1_macro    0.655521   0.334690   \n",
       "8                   MLP         accuracy    0.764883   0.764262   \n",
       "9                   MLP  precision_macro    0.400243   0.410917   \n",
       "10                  MLP     recall_macro    0.309917   0.309692   \n",
       "11                  MLP         f1_macro    0.306526   0.306408   \n",
       "12        Decision Tree         accuracy    0.999996   0.720046   \n",
       "13        Decision Tree  precision_macro    0.999977   0.461525   \n",
       "14        Decision Tree     recall_macro    0.999999   0.476561   \n",
       "15        Decision Tree         f1_macro    0.999988   0.468247   \n",
       "16        Random Forest         accuracy    0.999996   0.834905   \n",
       "17        Random Forest  precision_macro    0.999977   0.871816   \n",
       "18        Random Forest     recall_macro    0.999999   0.548909   \n",
       "19        Random Forest         f1_macro    0.999988   0.628746   \n",
       "20              XGBoost         accuracy    0.819145   0.794443   \n",
       "21              XGBoost  precision_macro    0.865285   0.757231   \n",
       "22              XGBoost     recall_macro    0.693444   0.460919   \n",
       "23              XGBoost         f1_macro    0.720696   0.504887   \n",
       "\n",
       "    Variance_Train  Variance_Test  Train-Test_Difference  \n",
       "0     7.678480e-07   2.207548e-06               0.000450  \n",
       "1     8.193642e-08   6.239134e-07               0.000509  \n",
       "2     3.274189e-06   7.775047e-05               0.014713  \n",
       "3     2.041098e-07   1.228930e-06               0.000686  \n",
       "4     1.107867e-07   1.082934e-06               0.148298  \n",
       "5     3.003487e-05   3.064116e-04               0.412112  \n",
       "6     7.665585e-05   3.474565e-05               0.271602  \n",
       "7     6.426812e-05   7.090789e-05               0.320831  \n",
       "8     4.956358e-06   2.358998e-06               0.000621  \n",
       "9     7.107620e-05   1.093682e-03              -0.010674  \n",
       "10    1.660723e-04   1.557380e-04               0.000225  \n",
       "11    2.847270e-04   2.589425e-04               0.000118  \n",
       "12    2.655486e-12   7.296541e-06               0.279950  \n",
       "13    8.953026e-11   1.277242e-04               0.538453  \n",
       "14    1.625216e-13   2.084549e-04               0.523438  \n",
       "15    2.433948e-11   1.473812e-04               0.531742  \n",
       "16    2.655486e-12   1.460938e-06               0.165091  \n",
       "17    8.953026e-11   5.639710e-05               0.128161  \n",
       "18    1.625216e-13   2.538490e-04               0.451090  \n",
       "19    2.433948e-11   3.302600e-04               0.371242  \n",
       "20    1.222249e-07   8.284927e-07               0.024702  \n",
       "21    2.881965e-07   1.712483e-05               0.108055  \n",
       "22    2.126674e-06   1.488255e-04               0.232525  \n",
       "23    2.160891e-06   2.742730e-04               0.215809  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_results.to_csv('performance_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble Models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_stacking_with_predefined_split(X, y, predefined_split, base_model, meta_model):\n",
    "    \"\"\"\n",
    "    Creates and evaluates a stacking ensemble with one base model and a meta model using a predefined split.\n",
    "    \n",
    "    Parameters:\n",
    "    - X (pd.DataFrame): Feature dataset.\n",
    "    - y (pd.Series or np.array): Target variable.\n",
    "    - predefined_split (PredefinedSplit): Predefined split object for cross-validation.\n",
    "    - base_model: Base model instance (e.g., XGBoost, Random Forest).\n",
    "    - meta_model: Meta-model instance (e.g., Logistic Regression).\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: Summary table with mean, variance, and train-test differences for evaluation metrics.\n",
    "    \"\"\"\n",
    "    # Initialize storage for predictions and metrics\n",
    "    base_predictions = np.zeros((len(y),))  # For storing base model predictions\n",
    "    fold_metrics = {\n",
    "        'accuracy_train': [],\n",
    "        'accuracy_test': [],\n",
    "        'precision_macro_train': [],\n",
    "        'precision_macro_test': [],\n",
    "        'recall_macro_train': [],\n",
    "        'recall_macro_test': [],\n",
    "        'f1_macro_train': [],\n",
    "        'f1_macro_test': []\n",
    "    }\n",
    "    \n",
    "    # Split data based on predefined split\n",
    "    for train_idx, test_idx in predefined_split.split():\n",
    "        # Split into train and test\n",
    "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        # Train the base model on training data\n",
    "        base_model.fit(X_train, y_train)\n",
    "        # Make predictions with the base model on training data\n",
    "        base_train_pred = base_model.predict(X_train)\n",
    "        base_test_pred = base_model.predict(X_test)\n",
    "        \n",
    "        # Store base model predictions as features for the meta model\n",
    "        base_predictions[train_idx] = base_train_pred  # Predictions on training set only\n",
    "        \n",
    "        # Train the meta-model on the stacked features\n",
    "        meta_model.fit(base_predictions[train_idx].reshape(-1, 1), y_train)\n",
    "        \n",
    "        # Meta-model predictions on training and test sets\n",
    "        meta_train_pred = meta_model.predict(base_predictions[train_idx].reshape(-1, 1))\n",
    "        meta_test_pred = meta_model.predict(base_test_pred.reshape(-1, 1))\n",
    "        \n",
    "        # Evaluate metrics on both training and test sets\n",
    "        fold_metrics['accuracy_train'].append(accuracy_score(y_train, meta_train_pred))\n",
    "        fold_metrics['accuracy_test'].append(accuracy_score(y_test, meta_test_pred))\n",
    "        fold_metrics['precision_macro_train'].append(precision_score(y_train, meta_train_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['precision_macro_test'].append(precision_score(y_test, meta_test_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['recall_macro_train'].append(recall_score(y_train, meta_train_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['recall_macro_test'].append(recall_score(y_test, meta_test_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['f1_macro_train'].append(f1_score(y_train, meta_train_pred, average='macro', zero_division=0))\n",
    "        fold_metrics['f1_macro_test'].append(f1_score(y_test, meta_test_pred, average='macro', zero_division=0))\n",
    "    \n",
    "    # Compute mean, variance, and train-test differences\n",
    "    results = []\n",
    "    for metric_name in ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']:\n",
    "        train_metric = np.array(fold_metrics[f'{metric_name}_train'])\n",
    "        test_metric = np.array(fold_metrics[f'{metric_name}_test'])\n",
    "        \n",
    "        mean_train = np.mean(train_metric)\n",
    "        mean_test = np.mean(test_metric)\n",
    "        variance_train = np.var(train_metric)\n",
    "        variance_test = np.var(test_metric)\n",
    "        mean_difference = mean_train - mean_test\n",
    "        \n",
    "        results.append({\n",
    "            'Metric': metric_name,\n",
    "            'Mean_Train': mean_train,\n",
    "            'Mean_Test': mean_test,\n",
    "            'Variance_Train': variance_train,\n",
    "            'Variance_Test': variance_test,\n",
    "            'Train-Test_Difference': mean_difference\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = XGBClassifier(gamma = 0, learning_rate = 0.3, max_depth = 6, min_child_weight = 1, n_estimators = 200, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)\n",
    "meta_model = LogisticRegression(penalty='l2', C=10, solver='lbfgs', class_weight='balanced', l1_ratio=0.5, max_iter=2000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = XGBClassifier(gamma = 0, learning_rate = 0.3, max_depth = 6, min_child_weight = 1, n_estimators = 200, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)\n",
    "meta_model = LogisticRegression(penalty='l2', C=10, solver='lbfgs', class_weight='balanced', l1_ratio=0.5, max_iter=2000, n_jobs=-1),\n",
    "\n",
    "stacking_results = evaluate_stacking_with_predefined_split(X_combined, y_combined, ps, base_model, meta_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Mean_Train</th>\n",
       "      <th>Mean_Test</th>\n",
       "      <th>Variance_Train</th>\n",
       "      <th>Variance_Test</th>\n",
       "      <th>Train-Test_Difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.818854</td>\n",
       "      <td>0.794342</td>\n",
       "      <td>2.091752e-07</td>\n",
       "      <td>5.559157e-07</td>\n",
       "      <td>0.024512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precision_macro</td>\n",
       "      <td>0.863878</td>\n",
       "      <td>0.756329</td>\n",
       "      <td>9.650562e-07</td>\n",
       "      <td>1.466552e-04</td>\n",
       "      <td>0.107549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recall_macro</td>\n",
       "      <td>0.694795</td>\n",
       "      <td>0.459673</td>\n",
       "      <td>2.481437e-06</td>\n",
       "      <td>1.284234e-04</td>\n",
       "      <td>0.235122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1_macro</td>\n",
       "      <td>0.721205</td>\n",
       "      <td>0.502512</td>\n",
       "      <td>3.229257e-06</td>\n",
       "      <td>2.470566e-04</td>\n",
       "      <td>0.218693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Metric  Mean_Train  Mean_Test  Variance_Train  Variance_Test  \\\n",
       "0         accuracy    0.818854   0.794342    2.091752e-07   5.559157e-07   \n",
       "1  precision_macro    0.863878   0.756329    9.650562e-07   1.466552e-04   \n",
       "2     recall_macro    0.694795   0.459673    2.481437e-06   1.284234e-04   \n",
       "3         f1_macro    0.721205   0.502512    3.229257e-06   2.470566e-04   \n",
       "\n",
       "   Train-Test_Difference  \n",
       "0               0.024512  \n",
       "1               0.107549  \n",
       "2               0.235122  \n",
       "3               0.218693  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacking_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_predict_stacking_multiclass(train_X, train_y, test_X, base_model, meta_model, selected_features):\n",
    "    \"\"\"\n",
    "    Fits a stacking ensemble for multiclass classification using XGBoost as the base model\n",
    "    and Logistic Regression as the meta-model.\n",
    "\n",
    "    Parameters:\n",
    "    - train_X (pd.DataFrame): Training features.\n",
    "    - train_y (pd.Series or np.array): Training labels (multiclass).\n",
    "    - test_X (pd.DataFrame): Test features.\n",
    "    - base_model: Base model instance (XGBoost).\n",
    "    - meta_model: Meta-model instance (Logistic Regression).\n",
    "    - selected_features (list): List of feature names to use for training.\n",
    "\n",
    "    Returns:\n",
    "    - np.array: Predicted labels for the test data.\n",
    "    \"\"\"\n",
    "    # Step 1: Train the base model on the training data\n",
    "    base_model.fit(train_X[selected_features], train_y)\n",
    "\n",
    "    # Step 2: Generate base model predictions for train and test sets (probabilities for all classes)\n",
    "    base_train_predictions = base_model.predict_proba(train_X[selected_features])  # Probabilities for all classes\n",
    "    base_test_predictions = base_model.predict_proba(test_X[selected_features])\n",
    "\n",
    "    # Step 3: Train the meta-model on the base model's train predictions\n",
    "    meta_model.fit(base_train_predictions, train_y)\n",
    "\n",
    "    # Step 4: Use the meta-model to predict test labels based on base model's test predictions\n",
    "    meta_test_predictions = meta_model.predict(base_test_predictions)\n",
    "\n",
    "    return meta_test_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, test_X = preprocessing_newFeatures_advanced(X, test_data)\n",
    "le  = LabelEncoder()\n",
    "train_y = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictions = fit_and_predict_stacking_multiclass(train_x, train_y, test_X, base_model, meta_model, selected_features_RFE_advanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_predictions = le.inverse_transform(ensemble_predictions)\n",
    "ensemble_predictions = pd.DataFrame(ensemble_predictions, columns=['Claim Injury Type'], index=test_data.index)\n",
    "ensemble_predictions.to_csv('ensemble_predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim Injury Type\n",
       "2. NON-COMP          79.202010\n",
       "4. TEMPORARY         13.737999\n",
       "3. MED ONLY           5.635157\n",
       "1. CANCELLED          1.145950\n",
       "5. PPD SCH LOSS       0.277337\n",
       "8. DEATH              0.001031\n",
       "6. PPD NSL            0.000515\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_predictions.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Claim Injury Type\n",
       "2. NON-COMP        50.708156\n",
       "4. TEMPORARY       25.871128\n",
       "3. MED ONLY        12.003986\n",
       "5. PPD SCH LOSS     8.410769\n",
       "1. CANCELLED        2.173595\n",
       "6. PPD NSL          0.733590\n",
       "8. DEATH            0.081878\n",
       "7. PTD              0.016898\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV with preprocessing_newFeatures_advanced (All features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_adv, X_combined, y_combined = create_predifined_split(X, y, preprocessing_newFeatures_advanced, n_splits=5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 49\n",
      "Feature Ranking: [ 1  1  1  1  1  1  1 13 18 17 20  4  1  1  1  1  1  1  1  1  1  3  5  1\n",
      "  1  1  1  1 24 26 28 31 30 29 27 14 21 23 22 32 34 36 38 40 42 44 43 41\n",
      " 39 37 35 33 12  6  8 25  1  1  1  1  1  1 19 15  9 11  1  1  1  7  1  1\n",
      "  1  2  1  1  1  1 10 16  1  1  1  1  1  1  1  1  1  1  1  1]\n",
      "Selected Features: ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Age at Injury 1', 'Age at Injury 2', 'Age at Injury 3', 'Age at Injury 4', 'Age at Injury 5', 'Birth Year 0', 'Birth Year 1', 'Birth Year 2', 'Birth Year 3', 'Average Weekly Wage 0', 'Average Weekly Wage 1', 'Average Weekly Wage 2', 'IME-4 Count 0', 'IME-4 Count 1', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'Carrier Type_4A. SELF PRIVATE', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_ALBANY', 'District Name_BUFFALO', 'District Name_HAUPPAUGE', 'District Name_NYC', 'District Name_STATEWIDE', 'District Name_SYRACUSE', 'Gender_F', 'Gender_M', 'Medical Fee Region_I', 'Medical Fee Region_II', 'Medical Fee Region_III', 'Medical Fee Region_IV', 'Medical Fee Region_UK', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']\n"
     ]
    }
   ],
   "source": [
    " # Initialize RandomForest model\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=100,            # Number of trees\n",
    "    max_depth=15,                # Limit tree depth\n",
    "    min_samples_split=50,        # Minimum samples for a split\n",
    "    min_samples_leaf=20,         # Minimum samples per leaf\n",
    "    max_features='sqrt',         # Features to consider per split\n",
    "    class_weight='balanced',     # Handle class imbalance\n",
    "    bootstrap=True,              # Use bootstrapping\n",
    "    random_state=42,             # Ensure reproducibility\n",
    "    n_jobs=-1                    # Use all CPU cores\n",
    ")\n",
    "\n",
    "# Set up RFECV with RandomForest and cross-validation\n",
    "rfecv = RFECV(estimator=rf_model, step=1, cv=ps_adv, scoring='f1_macro', n_jobs=-1) \n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_combined, y_combined)\n",
    "\n",
    "#Get the selected features\n",
    "selected_features_RFE_advanced = X_combined.columns[rfecv.support_].tolist()\n",
    "feature_ranking = rfecv.ranking_\n",
    "optimal_num_features = rfecv.n_features_\n",
    "\n",
    "print(\"Optimal number of features:\", optimal_num_features)\n",
    "print(\"Feature Ranking:\", feature_ranking)\n",
    "print(\"Selected Features:\", selected_features_RFE_advanced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimal number of features: 49 <br>\n",
    "Selected Features: <br>['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'Number of Dependents', 'Age at Injury 1', 'Age at Injury 2', 'Age at Injury 3', 'Age at Injury 4', 'Age at Injury 5', 'Birth Year 0', 'Birth Year 1', 'Birth Year 2', 'Birth Year 3', 'Average Weekly Wage 0', 'Average Weekly Wage 1', 'Average Weekly Wage 2', 'IME-4 Count 0', 'IME-4 Count 1', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'Carrier Type_4A. SELF PRIVATE', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_ALBANY', 'District Name_BUFFALO', 'District Name_HAUPPAUGE', 'District Name_NYC', 'District Name_STATEWIDE', 'District Name_SYRACUSE', 'Gender_F', 'Gender_M', 'Medical Fee Region_I', 'Medical Fee Region_II', 'Medical Fee Region_III', 'Medical Fee Region_IV', 'Medical Fee Region_UK', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_RFE_advanced = ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'IME-4 Count', 'IME-4 Count 1', 'Attorney/Representative_False', 'Attorney/Representative_True', 'COVID-19 Indicator_True', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimising the final selected model: XGBoost Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in this section we try to optimise the performance of the classifier\n",
    "- feature selection varies across different try (some with none)\n",
    "- we use different preprocessing techniques\n",
    "- again we select the model with the highest f1_score macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "ps_newF_dum, X_combined2, y_combined2 = create_predifined_split_with_features(X, y, preprocessing_newFeatures_dum, selected_features_RFE_advanced, n_splits=5)\n",
    "ps_adv, X_combined3, y_combined3 = create_predifined_split_with_features(X, y, preprocessing_scaling_encoding_advanced, selected_features_RFE_basic, n_splits=5)\n",
    "ps_newF_adv, X_combined4, y_combined4 = create_predifined_split_with_features(X, y, preprocessing_newFeatures_advanced, selected_features_RFE_advanced, n_splits=5)\n",
    "ps_dum, X_combined1, y_combined1 = create_predifined_split_with_features(X, y, preprocessing_scaling_encoding_dum, selected_features_RFE_basic, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def evaluate_model_with_multiple_splits(splits_data, model):\n",
    "    \"\"\"\n",
    "    Evaluates a model on multiple predefined splits and stores performance metrics, \n",
    "    predictions on train/validation, and train-validation differences.\n",
    "\n",
    "    Parameters:\n",
    "    - splits_data (dict): Dictionary where each key is the split name, and the value is a dictionary with:\n",
    "                          'predefined_split': PredefinedSplit object,\n",
    "                          'X': Feature dataset (pd.DataFrame),\n",
    "                          'y': Target variable (pd.Series or np.array).\n",
    "    - model: Machine learning model instance (e.g., XGBClassifier, RandomForestClassifier).\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A DataFrame with mean accuracy, F1 scores, and train-validation differences for each split.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "\n",
    "    for split_name, split_info in splits_data.items():\n",
    "        print(f\"Evaluating model on split: {split_name}\")\n",
    "\n",
    "        predefined_split = split_info['predefined_split']\n",
    "        X = split_info['X']\n",
    "        y = split_info['y']\n",
    "\n",
    "        train_accuracies = []\n",
    "        val_accuracies = []\n",
    "        train_f1_scores = []\n",
    "        val_f1_scores = []\n",
    "\n",
    "        # Iterate through each fold in the predefined split\n",
    "        for train_idx, test_idx in predefined_split.split():\n",
    "            # Split data into train and validation sets\n",
    "            X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_val = y[train_idx], y[test_idx]\n",
    "\n",
    "            # Apply SMOTE for balancing\n",
    "            smote = SMOTE(random_state=42)\n",
    "            X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "            # Train the model\n",
    "            model.fit(X_train, y_train)\n",
    "\n",
    "            # Predictions and evaluation\n",
    "            y_train_pred = model.predict(X_train)\n",
    "            y_val_pred = model.predict(X_val)\n",
    "\n",
    "            # Calculate performance metrics\n",
    "            train_accuracies.append(accuracy_score(y_train, y_train_pred))\n",
    "            val_accuracies.append(accuracy_score(y_val, y_val_pred))\n",
    "            train_f1_scores.append(f1_score(y_train, y_train_pred, average='macro'))\n",
    "            val_f1_scores.append(f1_score(y_val, y_val_pred, average='macro'))\n",
    "\n",
    "        # Compute mean accuracy and F1 score for training and validation\n",
    "        mean_train_accuracy = np.mean(train_accuracies)\n",
    "        mean_val_accuracy = np.mean(val_accuracies)\n",
    "        mean_train_f1 = np.mean(train_f1_scores)\n",
    "        mean_val_f1 = np.mean(val_f1_scores)\n",
    "\n",
    "        # Calculate train-validation differences\n",
    "        accuracy_difference = mean_train_accuracy - mean_val_accuracy\n",
    "        f1_difference = mean_train_f1 - mean_val_f1\n",
    "\n",
    "        # Store results\n",
    "        results.append({\n",
    "            'Split': split_name,\n",
    "            'Mean_Train_Accuracy': mean_train_accuracy,\n",
    "            'Mean_Val_Accuracy': mean_val_accuracy,\n",
    "            'Accuracy_Difference': accuracy_difference,\n",
    "            'Mean_Train_F1_Macro': mean_train_f1,\n",
    "            'Mean_Val_F1_Macro': mean_val_f1,\n",
    "            'F1_Difference': f1_difference\n",
    "        })\n",
    "\n",
    "    # Create a DataFrame with split names as index\n",
    "    results_df = pd.DataFrame(results).set_index('Split')\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits_data = {\n",
    "    'Split_dum': {\n",
    "        'predefined_split': ps_dum,\n",
    "        'X': X_combined1,\n",
    "        'y': y_combined1\n",
    "    },\n",
    "    'Split_newF_dum': {\n",
    "        'predefined_split': ps_newF_dum,\n",
    "        'X': X_combined2,\n",
    "        'y': y_combined2\n",
    "    },\n",
    "    'Split_adv': {\n",
    "        'predefined_split': ps_adv,\n",
    "        'X': X_combined3,\n",
    "        'y': y_combined3\n",
    "    },\n",
    "    'Split_newF_adv': {\n",
    "        'predefined_split': ps_newF_adv,\n",
    "        'X': X_combined4,\n",
    "        'y': y_combined4\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on split: Split_dum\n",
      "Evaluating model on split: Split_newF_dum\n",
      "Evaluating model on split: Split_adv\n",
      "Evaluating model on split: Split_newF_adv\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(gamma = 0, learning_rate = 0.3, max_depth = 6, min_child_weight = 1, n_estimators = 200, reg_alpha = 0, reg_lambda = 1,random_state=42, n_jobs=-1)\n",
    "results_optimized_xgb = evaluate_model_with_multiple_splits(splits_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Train_Accuracy</th>\n",
       "      <th>Mean_Val_Accuracy</th>\n",
       "      <th>Accuracy_Difference</th>\n",
       "      <th>Mean_Train_F1_Macro</th>\n",
       "      <th>Mean_Val_F1_Macro</th>\n",
       "      <th>F1_Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Split_dum</th>\n",
       "      <td>0.861293</td>\n",
       "      <td>0.785060</td>\n",
       "      <td>0.076232</td>\n",
       "      <td>0.856758</td>\n",
       "      <td>0.505903</td>\n",
       "      <td>0.350855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_newF_dum</th>\n",
       "      <td>0.853341</td>\n",
       "      <td>0.783344</td>\n",
       "      <td>0.069996</td>\n",
       "      <td>0.848500</td>\n",
       "      <td>0.476951</td>\n",
       "      <td>0.371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_adv</th>\n",
       "      <td>0.857559</td>\n",
       "      <td>0.775956</td>\n",
       "      <td>0.081603</td>\n",
       "      <td>0.853279</td>\n",
       "      <td>0.499664</td>\n",
       "      <td>0.353615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_newF_adv</th>\n",
       "      <td>0.849146</td>\n",
       "      <td>0.774186</td>\n",
       "      <td>0.074960</td>\n",
       "      <td>0.844596</td>\n",
       "      <td>0.480692</td>\n",
       "      <td>0.363904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Mean_Train_Accuracy  Mean_Val_Accuracy  Accuracy_Difference  \\\n",
       "Split                                                                         \n",
       "Split_dum                  0.861293           0.785060             0.076232   \n",
       "Split_newF_dum             0.853341           0.783344             0.069996   \n",
       "Split_adv                  0.857559           0.775956             0.081603   \n",
       "Split_newF_adv             0.849146           0.774186             0.074960   \n",
       "\n",
       "                Mean_Train_F1_Macro  Mean_Val_F1_Macro  F1_Difference  \n",
       "Split                                                                  \n",
       "Split_dum                  0.856758           0.505903       0.350855  \n",
       "Split_newF_dum             0.848500           0.476951       0.371550  \n",
       "Split_adv                  0.853279           0.499664       0.353615  \n",
       "Split_newF_adv             0.844596           0.480692       0.363904  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_optimized_xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on split: Split_dum\n",
      "Evaluating model on split: Split_newF_dum\n",
      "Evaluating model on split: Split_adv\n",
      "Evaluating model on split: Split_newF_adv\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=2, min_samples_leaf=1, max_features='sqrt', bootstrap=False, random_state=42, n_jobs=-1)\n",
    "results_optimized_rf = evaluate_model_with_multiple_splits(splits_data, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean_Train_Accuracy</th>\n",
       "      <th>Mean_Val_Accuracy</th>\n",
       "      <th>Accuracy_Difference</th>\n",
       "      <th>Mean_Train_F1_Macro</th>\n",
       "      <th>Mean_Val_F1_Macro</th>\n",
       "      <th>F1_Difference</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Split_dum</th>\n",
       "      <td>0.820097</td>\n",
       "      <td>0.728984</td>\n",
       "      <td>0.091113</td>\n",
       "      <td>0.811131</td>\n",
       "      <td>0.407825</td>\n",
       "      <td>0.403306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_newF_dum</th>\n",
       "      <td>0.820572</td>\n",
       "      <td>0.736770</td>\n",
       "      <td>0.083802</td>\n",
       "      <td>0.810234</td>\n",
       "      <td>0.406703</td>\n",
       "      <td>0.403531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_adv</th>\n",
       "      <td>0.817936</td>\n",
       "      <td>0.713905</td>\n",
       "      <td>0.104031</td>\n",
       "      <td>0.809447</td>\n",
       "      <td>0.402926</td>\n",
       "      <td>0.406521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Split_newF_adv</th>\n",
       "      <td>0.818748</td>\n",
       "      <td>0.721570</td>\n",
       "      <td>0.097178</td>\n",
       "      <td>0.809441</td>\n",
       "      <td>0.402541</td>\n",
       "      <td>0.406901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Mean_Train_Accuracy  Mean_Val_Accuracy  Accuracy_Difference  \\\n",
       "Split                                                                         \n",
       "Split_dum                  0.820097           0.728984             0.091113   \n",
       "Split_newF_dum             0.820572           0.736770             0.083802   \n",
       "Split_adv                  0.817936           0.713905             0.104031   \n",
       "Split_newF_adv             0.818748           0.721570             0.097178   \n",
       "\n",
       "                Mean_Train_F1_Macro  Mean_Val_F1_Macro  F1_Difference  \n",
       "Split                                                                  \n",
       "Split_dum                  0.811131           0.407825       0.403306  \n",
       "Split_newF_dum             0.810234           0.406703       0.403531  \n",
       "Split_adv                  0.809447           0.402926       0.406521  \n",
       "Split_newF_adv             0.809441           0.402541       0.406901  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_optimized_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on split: Split_dum\n",
      "Evaluating model on split: Split_newF_dum\n",
      "Evaluating model on split: Split_adv\n",
      "Evaluating model on split: Split_newF_adv\n"
     ]
    }
   ],
   "source": [
    "model = MLPClassifier(solver='adam',max_iter=1000,random_state=42, hidden_layer_sizes=(int(0.75 * len(selected_features_RFE_basic)), int(0.5 * len(selected_features_RFE_basic)), int(0.25 * len(selected_features_RFE_basic)), int(0.125 * len(selected_features_RFE_basic)),), learning_rate_init=0.01, activation='tanh', alpha=0.001, batch_size='auto')\n",
    "results_optimized_mlp = evaluate_model_with_multiple_splits(splits_data, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425_20241209",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
