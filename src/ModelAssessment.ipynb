{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import time\n",
    "from sklearn.model_selection import PredefinedSplit\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, make_scorer\n",
    ")\n",
    "from sklearn.feature_selection import RFE\n",
    "from Preprocessing_functions2 import *\n",
    "\n",
    "# pandas max columns display\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\inesm\\AppData\\Local\\Temp\\ipykernel_8780\\3470921380.py:1: DtypeWarning: Columns (29) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv('train_data.csv', index_col='Claim Identifier')\n",
    "test_data = pd.read_csv('test_data.csv', index_col='Claim Identifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[~(train_data.drop(columns=['Assembly Date']).isna().all(axis=1) & train_data['Assembly Date'].notna())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_data.drop(columns=['Claim Injury Type', 'WCB Decision', 'Agreement Reached','OIICS Nature of Injury Description'])\n",
    "y = train_data['Claim Injury Type']\n",
    "\n",
    "test_data = test_data.drop(columns=['OIICS Nature of Injury Description'])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auxiliary Functions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CODE_COLUMNS = ['Industry Code', 'WCIO Cause of Injury Code',\n",
    "       'WCIO Nature of Injury Code', 'WCIO Part Of Body Code']\n",
    "\n",
    "DESCRIPTION_COLUMNS = ['WCIO Cause of Injury Description','WCIO Nature of Injury Description','WCIO Part Of Body Description','Industry Code Description']\n",
    "\n",
    "BOOLEAN_COLUMNS = ['Alternative Dispute Resolution', 'Attorney/Representative','COVID-19 Indicator']\n",
    "\n",
    "date_order = ['Accident Date', 'C-2 Date','C-3 Date','Assembly Date', 'First Hearing Date']\n",
    "\n",
    "numerical_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year', \n",
    "    'C-2 Date', \n",
    "    'C-3 Date', \n",
    "    'First Hearing Date', \n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "outliers_columns = [\n",
    "    'Accident Date', \n",
    "    'Age at Injury', \n",
    "    'Assembly Date', \n",
    "    'Average Weekly Wage', \n",
    "    'Birth Year',\n",
    "    'IME-4 Count', \n",
    "]\n",
    "\n",
    "categorical_features = ['Alternative Dispute Resolution',\n",
    " 'Attorney/Representative',\n",
    " 'Carrier Name',\n",
    " 'Carrier Type',\n",
    " 'County of Injury',\n",
    " 'COVID-19 Indicator',\n",
    " 'District Name',\n",
    " 'Gender',\n",
    " 'Industry Code',\n",
    " 'Medical Fee Region',\n",
    " 'WCIO Cause of Injury Code',\n",
    " 'WCIO Nature of Injury Code',\n",
    " 'WCIO Part Of Body Code',\n",
    " 'Zip Code']\n",
    "\n",
    "\n",
    "columns_to_scale = ['Accident Date',\n",
    "                'Assembly Date',\n",
    "                'Average Weekly Wage',\n",
    "                'Age at Injury',\n",
    "                'Birth Year', \n",
    "                'Number of Dependents',\n",
    "                'IME-4 Count']\n",
    "\n",
    "date_columns = ['Accident Date', 'Assembly Date']\n",
    "\n",
    "columns_to_drop = ['C-2 Date', 'C-3 Date', 'First Hearing Date']\n",
    "\n",
    "low_cardinality_cols = [col for col in categorical_features if X[col].nunique() < 10]\n",
    "high_cardinality_cols = [col for col in categorical_features if X[col].nunique() > 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_scaling_encoding_dum(X_train, X_val):\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val,categorical_features)\n",
    "    X_train, X_val = drop_description_columns(X_train, X_val)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "    X_train, X_val = impute_mean_numerical(X_train, X_val, numerical_columns)\n",
    "    X_train, X_val = fill_missing_with_mode(X_train, X_val)\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = winsorize_outliers(X_train, X_val, outliers_columns)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, columns_to_scale)\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_newFeatures_advanced(X_train, X_val):\n",
    "\n",
    "    # Type conversion\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val, categorical_features)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_order)\n",
    "    X_train, X_val = convert_to_bool(X_train, X_val, col_names=BOOLEAN_COLUMNS)\n",
    "\n",
    "    # Knowledge-based imputation of features\n",
    "    X_train, X_val = fill_missing_codes_description_based(X_train, X_val)\n",
    "    X_train, X_val = fillna_zip_code(X_train, X_val)\n",
    "    X_train, X_val = fillnan_accident_date(X_train, X_val)\n",
    "    X_train, X_val = fillnan_birth_year(X_train, X_val)\n",
    "    X_train, X_val = impute_weekly_wage_with_zipIndustryCode(X_train, X_val)\n",
    "\n",
    "    # Feature creation\n",
    "    X_train, X_val = feature_creation_has_Cdate(X_train, X_val)\n",
    "    X_train, X_val = drop_unwanted_columns(X_train, X_val, columns_to_drop)\n",
    "    X_train, X_val = newFeature_hasIME4(X_train, X_val)\n",
    "    X_train, X_val = convert_to_datetime(X_train, X_val, date_columns)\n",
    "    #print dtype of birth year\n",
    "\n",
    "\n",
    "    X_train, X_val, c_features, n_features= create_groupingFeatures(X_train, X_val)\n",
    "    categorical_features.append(c_features)\n",
    "    numerical_columns.append(n_features)\n",
    "\n",
    "    # Redo type conversion\n",
    "    X_train, X_val = type_conversion_categorical(X_train, X_val, categorical_features)\n",
    "    X_train, X_val = convert_to_timestamp(X_train, X_val, date_columns)\n",
    "\n",
    "    # Treating outliers\n",
    "    X_train, X_val = winsorize_outliers(X_train, X_val, outliers_columns)\n",
    "\n",
    "    # Scaling\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, categorical_features)\n",
    "    X_train, X_val = scaling_robust(X_train, X_val, numerical_columns)\n",
    "\n",
    "    # Ensure categorical_features contains unique column names\n",
    "    valid_categorical_features = list(set(categorical_features))\n",
    "\n",
    "    # Verify all columns in categorical_features exist in X_train\n",
    "    valid_categorical_features = [col for col in valid_categorical_features if col in X_train.columns]\n",
    "    print(f'Valid categorical features: {valid_categorical_features}')\n",
    "\n",
    "\n",
    "    low_cardinality_cols = [col for col in valid_categorical_features if X_train[col].nunique() < 15]\n",
    "    high_cardinality_cols = [col for col in valid_categorical_features if X_train[col].nunique() > 15]\n",
    "\n",
    "    X_train, X_val = encoding_onehot(X_train, X_val, low_cardinality_cols)\n",
    "    X_train, X_val = encoding_frequency1(X_train, X_val, high_cardinality_cols)\n",
    "\n",
    "    return X_train, X_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV with preprocessing_scaling_encoding_dum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\isa\\Documents\\Github\\ML_Group36\\src\\Preprocessing_functions2.py:388: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train[col].fillna(mean_value, inplace=True)\n",
      "c:\\Users\\isa\\Documents\\Github\\ML_Group36\\src\\Preprocessing_functions2.py:389: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val[col].fillna(mean_value, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "X_enconded, X_val = preprocessing_scaling_encoding_dum(X, X_val)\n",
    "y_encoded, y_val = encoding_label(y, y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 46\n",
      "Selected Features: ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'Number of Dependents', 'Has First Hearing Date', 'Alternative Dispute Resolution_False', 'Alternative Dispute Resolution_True', 'Alternative Dispute Resolution_nan', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'Carrier Type_4A. SELF PRIVATE', 'Carrier Type_5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)', 'Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS', 'Carrier Type_5D. SPECIAL FUND - UNKNOWN', 'Carrier Type_UNKNOWN', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_ALBANY', 'District Name_BINGHAMTON', 'District Name_BUFFALO', 'District Name_HAUPPAUGE', 'District Name_NYC', 'District Name_ROCHESTER', 'District Name_STATEWIDE', 'District Name_SYRACUSE', 'Gender_F', 'Gender_M', 'Gender_U', 'Gender_X', 'Medical Fee Region_I', 'Medical Fee Region_II', 'Medical Fee Region_III', 'Medical Fee Region_IV', 'Medical Fee Region_UK', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']\n"
     ]
    }
   ],
   "source": [
    " # Initialize RandomForest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up cross-validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Set up RFECV with RandomForest and cross-validation\n",
    "rfecv = RFECV(estimator=rf_model, step=1, cv=cv_strategy, scoring='f1_macro') \n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_enconded, y_encoded)\n",
    "\n",
    "#Get the selected features\n",
    "selected_features_RF = X_enconded.columns[rfecv.support_].tolist()\n",
    "optimal_num_features = rfecv.n_features_\n",
    "\n",
    "print(\"Optimal number of features:\", optimal_num_features)\n",
    "print(\"Selected Features:\", selected_features_RF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['Accident Date', 'Age at Injury', 'Assembly Date', 'Average Weekly Wage', 'Birth Year', 'Number of Dependents', 'Has First Hearing Date', 'Alternative Dispute Resolution_False', 'Alternative Dispute Resolution_True', 'Alternative Dispute Resolution_nan', 'Attorney/Representative_False', 'Attorney/Representative_True', 'Carrier Type_1A. PRIVATE', 'Carrier Type_2A. SIF', 'Carrier Type_3A. SELF PUBLIC', 'Carrier Type_4A. SELF PRIVATE', 'Carrier Type_5A. SPECIAL FUND - CONS. COMM. (SECT. 25-A)', 'Carrier Type_5C. SPECIAL FUND - POI CARRIER WCB MENANDS', 'Carrier Type_5D. SPECIAL FUND - UNKNOWN', 'Carrier Type_UNKNOWN', 'COVID-19 Indicator_False', 'COVID-19 Indicator_True', 'District Name_ALBANY', 'District Name_BINGHAMTON', 'District Name_BUFFALO', 'District Name_HAUPPAUGE', 'District Name_NYC', 'District Name_ROCHESTER', 'District Name_STATEWIDE', 'District Name_SYRACUSE', 'Gender_F', 'Gender_M', 'Gender_U', 'Gender_X', 'Medical Fee Region_I', 'Medical Fee Region_II', 'Medical Fee Region_III', 'Medical Fee Region_IV', 'Medical Fee Region_UK', 'Carrier Name', 'County of Injury', 'Industry Code', 'WCIO Cause of Injury Code', 'WCIO Nature of Injury Code', 'WCIO Part Of Body Code', 'Zip Code']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV with preprocessing_newFeatures_advanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\timst\\OneDrive\\Desktop\\NOVA IMS\\Semester 1\\MachineLearning\\Project\\ML_Group36-1\\src\\Preprocessing_functions2.py:641: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_train['Accident Date'].fillna(X_train['C-2 Date'] - mean_difference_c2_accident, inplace=True)\n",
      "c:\\Users\\timst\\OneDrive\\Desktop\\NOVA IMS\\Semester 1\\MachineLearning\\Project\\ML_Group36-1\\src\\Preprocessing_functions2.py:642: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  X_val['Accident Date'].fillna(X_val['C-2 Date'] - mean_difference_c2_accident, inplace=True)\n",
      "c:\\Users\\timst\\OneDrive\\Desktop\\NOVA IMS\\Semester 1\\MachineLearning\\Project\\ML_Group36-1\\src\\Preprocessing_functions2.py:663: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Birth Year'].fillna(calculated_birth_years.dt.year, inplace=True)\n",
      "c:\\Users\\timst\\OneDrive\\Desktop\\NOVA IMS\\Semester 1\\MachineLearning\\Project\\ML_Group36-1\\src\\Preprocessing_functions2.py:663: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Birth Year'].fillna(calculated_birth_years.dt.year, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_preprocessed, X_val \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessing_newFeatures_advanced\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m y_encoded, y_val \u001b[38;5;241m=\u001b[39m encoding_label(y, y_val) \n",
      "Cell \u001b[1;32mIn[12], line 23\u001b[0m, in \u001b[0;36mpreprocessing_newFeatures_advanced\u001b[1;34m(X_train, X_val)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m#print dtype of birth year\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBirth Year\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m---> 23\u001b[0m X_train, X_val, c_features, n_features\u001b[38;5;241m=\u001b[39m \u001b[43mcreate_groupingFeatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m categorical_features\u001b[38;5;241m.\u001b[39mappend(c_features)\n\u001b[0;32m     25\u001b[0m numerical_columns\u001b[38;5;241m.\u001b[39mappend(n_features)\n",
      "File \u001b[1;32mc:\\Users\\timst\\OneDrive\\Desktop\\NOVA IMS\\Semester 1\\MachineLearning\\Project\\ML_Group36-1\\src\\Preprocessing_functions2.py:161\u001b[0m, in \u001b[0;36mcreate_groupingFeatures\u001b[1;34m(X_train, X_val)\u001b[0m\n\u001b[0;32m    159\u001b[0m categorical_features \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    160\u001b[0m numerical_features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 161\u001b[0m X_train, X_val\u001b[38;5;241m=\u001b[39m \u001b[43mnewFeature_binnedGroups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbinning_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Add all names of the binning_column + 'Group' to the list of categorical_features\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m binning_columns:\n",
      "File \u001b[1;32mc:\\Users\\timst\\OneDrive\\Desktop\\NOVA IMS\\Semester 1\\MachineLearning\\Project\\ML_Group36-1\\src\\Preprocessing_functions2.py:102\u001b[0m, in \u001b[0;36mnewFeature_binnedGroups\u001b[1;34m(X_train, X_val, X_test, columns, bins)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnewFeature_binnedGroups\u001b[39m(X_train, X_val, X_test, columns, bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m):\n\u001b[0;32m     91\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;124;03m    Create new features based on the binned groups of the original features\u001b[39;00m\n\u001b[0;32m     93\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    bins: int default: 4\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m--> 102\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Define bins based on training data\u001b[39;49;00m\n\u001b[0;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_bins\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqcut\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretbins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Get bin edges\u001b[39;49;00m\n\u001b[0;32m    106\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Apply the bins to all datasets\u001b[39;49;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "X_preprocessed, X_val = preprocessing_newFeatures_advanced(X, X_val)\n",
    "y_encoded, y_val = encoding_label(y, y_val) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize RandomForest model\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up cross-validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# Set up RFECV with RandomForest and cross-validation\n",
    "rfecv = RFECV(estimator=rf_model, step=1, cv=cv_strategy, scoring='f1_macro') \n",
    "\n",
    "# Fit RFECV\n",
    "rfecv.fit(X_enconded, y_encoded)\n",
    "\n",
    "#Get the selected features\n",
    "selected_features_RF = X_enconded.columns[rfecv.support_].tolist()\n",
    "optimal_num_features = rfecv.n_features_\n",
    "\n",
    "print(\"Optimal number of features:\", optimal_num_features)\n",
    "print(\"Selected Features:\", selected_features_RF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV Performance Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_predifined_split(X, y, preprocess_steps,selected_features, n_splits = 5):\n",
    "    \"\"\"\n",
    "    Creates a PredefinedSplit object to be used in cross-validation, more specifically in GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Defines the number of splits\n",
    "    - Splits the data into training and validation sets\n",
    "    - Applies the preprocessing steps to the training and validation sets\n",
    "    - Returns the PredefinedSplit object and the preprocessed data\n",
    "    \"\"\"\n",
    "\n",
    "    X_combined_list = []\n",
    "    y_combined_list = []\n",
    "\n",
    "    kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    test_data = np.zeros(len(X), dtype=int) - 1\n",
    "\n",
    "    for fold_idx, (_, test_idx) in enumerate(kf.split(X, y)):\n",
    "        test_data[test_idx] = fold_idx\n",
    "\n",
    "    ps = PredefinedSplit(test_fold=test_data)\n",
    "\n",
    "    for train_index, test_index in ps.split():\n",
    "\n",
    "        # Get fold\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # Preprocess and encode data    \n",
    "        X_train, X_val = preprocess_steps(X_train, X_val)\n",
    "        y_train, y_val = encoding_label(y_train, y_val)\n",
    "\n",
    "        X_combined_list.append(X_train[selected_features])\n",
    "        y_combined_list.append(y_train)\n",
    "\n",
    "    X_combined = pd.concat(X_combined_list, axis=0)\n",
    "    y_combined = np.concatenate(y_combined_list, axis=0)\n",
    "\n",
    "    return ps, X_combined, y_combined\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_parameters(X, y, model, param_grid, preprocess_steps, n_splits=5):\n",
    "    \"\"\"\n",
    "    Finds the best hyperparameters for a given model using GridSearchCV.\n",
    "\n",
    "    Steps:\n",
    "    - Creates a PredefinedSplit object\n",
    "    - Creates a GridSearchCV object\n",
    "    - Fits the GridSearchCV object\n",
    "    - Returns the best hyperparameters and the best score\n",
    "    \"\"\"\n",
    "    predefined_split, X_combined, y_combined = create_predifined_split(X, y, preprocess_steps,selected_features, n_splits=n_splits)\n",
    "\n",
    "    scoring = make_scorer(f1_score, average='macro')\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        model,\n",
    "        param_grid,\n",
    "        cv=predefined_split,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    grid_search.fit(X_combined, y_combined)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    print(\"Best F1-macro Score:\", grid_search.best_score_)\n",
    "\n",
    "    return grid_search.best_params_, grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 1, 5],\n",
    "    'reg_alpha': [0, 1, 10],\n",
    "    'reg_lambda': [1, 10, 100]\n",
    "}\n",
    "model=XGBClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_parameters(X, y, model, param_grid, preprocessing_scaling_encoding_dum, n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_neighbors': [3, 5, 7, 9],\n",
    "    'weights': ['uniform', 'distance'], # Weight function\n",
    "    'metric': ['minkowski', 'chebyshev'],  # Distance metrics\n",
    "    'p': [1, 2], # Power parameter for Minkowski distance\n",
    "    'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute'],  # Algorithm for nearest neighbor search\n",
    "    'leaf_size': [10, 20, 30, 40, 50] \n",
    "}\n",
    "model=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_best_parameters(X, y, model, param_grid, preprocessing_scaling_encoding_dum[selected_features], n_splits=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensamble Models\n",
    "look for last year project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DM2425",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
